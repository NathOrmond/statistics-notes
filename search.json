[
  {
    "objectID": "src/teaching-stats/core-concepts/central-limit-theorem.html",
    "href": "src/teaching-stats/core-concepts/central-limit-theorem.html",
    "title": "Central Limit Theorem",
    "section": "",
    "text": "Show the code\n# Installation and Setup\nrequired_packages &lt;- c(\"ggplot2\", \"dplyr\", \"gridExtra\", \"moments\", \"nortest\")\n\n# Load required packages\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(gridExtra)\nlibrary(moments)\nlibrary(nortest)\n\nset.seed(123)\nShow the code\ngenerate_distribution &lt;- function(dist_type, n = 10000, params = list()) {\n  switch(dist_type,\n         \"exponential\" = rexp(n, rate = params$rate %||% 0.5),\n         \"normal\" = rnorm(n, mean = params$mean %||% 0, sd = params$sd %||% 1),\n         \"uniform\" = runif(n, min = params$min %||% 0, max = params$max %||% 10),\n         \"gamma\" = rgamma(n, shape = params$shape %||% 2, rate = params$rate %||% 0.5),\n         \"beta\" = rbeta(n, shape1 = params$shape1 %||% 2, shape2 = params$shape2 %||% 5),\n         \"lognormal\" = rlnorm(n, meanlog = params$meanlog %||% 0, sdlog = params$sdlog %||% 1),\n         \"chi_squared\" = rchisq(n, df = params$df %||% 3),\n         \"weibull\" = rweibull(n, shape = params$shape %||% 2, scale = params$scale %||% 1),\n         rexp(n, rate = 0.5)  # default to exponential\n  )\n}\n# Helper function for default parameters\n`%||%` &lt;- function(x, y) if (is.null(x)) y else x\n# Global parameters\nn_population &lt;- 10000\nsample_size &lt;- 30  # Size of each sample\nn_samples &lt;- 1000  # Number of samples to take"
  },
  {
    "objectID": "src/teaching-stats/core-concepts/central-limit-theorem.html#introduction",
    "href": "src/teaching-stats/core-concepts/central-limit-theorem.html#introduction",
    "title": "Central Limit Theorem",
    "section": "Introduction",
    "text": "Introduction\nThe Central Limit Theorem (CLT) is one of the most important concepts in statistics. It states that when we take repeated random samples from any population (regardless of the shape of the original distribution), the sampling distribution of the sample mean will approach a normal distribution as the sample size increases."
  },
  {
    "objectID": "src/teaching-stats/core-concepts/central-limit-theorem.html#simulation-1-relating-population-distributions-to-sample-distributions",
    "href": "src/teaching-stats/core-concepts/central-limit-theorem.html#simulation-1-relating-population-distributions-to-sample-distributions",
    "title": "Central Limit Theorem",
    "section": "Simulation 1: Relating Population Distributions to Sample Distributions",
    "text": "Simulation 1: Relating Population Distributions to Sample Distributions\n\n\nShow the code\n# Distributions\n# \"exponential\", \"normal\", \"uniform\", \"gamma\", \"beta\", \"lognormal\", \"chi_squared\", \"weibull\"\noriginal_distribution &lt;- generate_distribution(\"exponential\")  \n\n\n\n\nShow the code\n# Create distribution with default parameters\noriginal_distribution &lt;- generate_distribution(\"exponential\")\n# Create a data frame for plotting\ndf_original &lt;- data.frame(values = original_distribution)\n# Plot the original distribution\nggplot(df_original, aes(x = values)) +\n  geom_histogram(bins = 50, fill = \"steelblue\", alpha = 0.7, color = \"black\") +\n  geom_density(aes(y = after_stat(count) * max(after_stat(count)) / max(after_stat(density))), \n               color = \"red\", linewidth = 1) +\n  labs(title = \"Original Distribution (Exponential)\",\n       subtitle = paste(\"Mean =\", round(mean(original_distribution), 2), \n                       \", SD =\", round(sd(original_distribution), 2)),\n       x = \"Values\", y = \"Frequency\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Step 1: Generate random samples from the distribution\nsample_means &lt;- numeric(n_samples)\nsample_sds &lt;- numeric(n_samples)\nsample_data_list &lt;- list()\nfor(i in 1:n_samples) {\n  sample_data &lt;- sample(original_distribution, size = sample_size, replace = TRUE)\n  sample_means[i] &lt;- mean(sample_data)\n  sample_sds[i] &lt;- sd(sample_data)\n  sample_data_list[[i]] &lt;- sample_data\n}\ncat(\"Generated\", n_samples, \"samples of size\", sample_size, \"\\n\")\n\n\nGenerated 1000 samples of size 30 \n\n\nShow the code\ncat(\"First few sample means:\", round(sample_means[1:5], 3), \"\\n\")\n\n\nFirst few sample means: 1.691 2.024 2.07 1.544 2.131 \n\n\n\n\nShow the code\n# Visualize where samples are drawn from the population\n# Show first 3 samples as points on the population distribution\nsample_points &lt;- data.frame()\nfor(i in 1:3) {\n  sample_data &lt;- sample_data_list[[i]]\n  sample_points &lt;- rbind(sample_points, \n                        data.frame(values = sample_data, \n                                  sample = paste(\"Sample\", i),\n                                  mean = rep(mean(sample_data), length(sample_data))))\n}\n\n# Plot population with sample points overlaid\nggplot() +\n  geom_histogram(data = df_original, aes(x = values), \n                bins = 50, fill = \"steelblue\", alpha = 0.7, color = \"black\") +\n  geom_density(data = df_original, aes(x = values, y = after_stat(count) * max(after_stat(count)) / max(after_stat(density))), \n               color = \"red\", linewidth = 1) +\n  geom_point(data = sample_points, aes(x = values, y = 0, color = sample), \n             size = 2, alpha = 0.8, position = position_jitter(height = 50)) +\n  geom_vline(data = sample_points, aes(xintercept = mean, color = sample), \n             linewidth = 1, linetype = \"dashed\") +\n  labs(title = \"Population Distribution with Sample Points\",\n       subtitle = \"Points show individual values from first 3 samples\\nDashed lines show sample means\",\n       x = \"Values\", y = \"Frequency\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5)) +\n  scale_color_manual(values = c(\"Sample 1\" = \"orange\", \"Sample 2\" = \"purple\", \"Sample 3\" = \"green\"))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Step 2: Create data frame for the sampling distribution\ndf_sample_means &lt;- data.frame(sample_mean = sample_means)\ncat(\"Created data frame with\", nrow(df_sample_means), \"sample means\\n\")\n\n\nCreated data frame with 1000 sample means\n\n\nImportant Note: The samples are drawn from the original population distribution (exponential in this case). What you’re seeing is the sampling distribution of the means, which is different from the original population distribution. This is exactly what the Central Limit Theorem predicts - even though we’re sampling from a skewed exponential distribution, the distribution of sample means becomes approximately normal!\n\n\nShow the code\n# Step 3a: Calculate key statistics for the sampling distribution\nsampling_mean &lt;- mean(sample_means)\nsampling_sd &lt;- sd(sample_means)\npopulation_mean &lt;- mean(original_distribution)\ntheoretical_se &lt;- sd(original_distribution) / sqrt(sample_size)\n\ncat(\"=== Sampling Distribution Statistics ===\\n\")\n\n\n=== Sampling Distribution Statistics ===\n\n\nShow the code\ncat(\"Mean of sample means:\", round(sampling_mean, 3), \"\\n\")\n\n\nMean of sample means: 2.024 \n\n\nShow the code\ncat(\"SD of sample means (observed SE):\", round(sampling_sd, 3), \"\\n\")\n\n\nSD of sample means (observed SE): 0.366 \n\n\nShow the code\ncat(\"Population mean:\", round(population_mean, 3), \"\\n\")\n\n\nPopulation mean: 2.006 \n\n\nShow the code\ncat(\"Theoretical standard error:\", round(theoretical_se, 3), \"\\n\")\n\n\nTheoretical standard error: 0.365 \n\n\nShow the code\ncat(\"Difference (observed - theoretical):\", round(sampling_sd - theoretical_se, 3), \"\\n\")\n\n\nDifference (observed - theoretical): 0.001 \n\n\n\n\nShow the code\n# Step 3b: Create the histogram of sample means\nhist_plot &lt;- ggplot(df_sample_means, aes(x = sample_mean)) +\n  geom_histogram(bins = 30, fill = \"lightgreen\", alpha = 0.7, color = \"black\") +\n  labs(title = \"Histogram of Sample Means\",\n       subtitle = paste(\"1000 samples of size\", sample_size),\n       x = \"Sample Mean\", y = \"Frequency\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5))\n\nprint(hist_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Step 3c: Add density curve to show the shape\n# Calculate density separately to get proper scaling\ndensity_data &lt;- density(df_sample_means$sample_mean, adjust = 1.5)\n# Scale density to match histogram scale\nmax_freq &lt;- max(hist(df_sample_means$sample_mean, breaks = 30, plot = FALSE)$counts)\ndensity_scaled &lt;- density_data$y * max_freq / max(density_data$y)\n\ndensity_plot &lt;- ggplot(df_sample_means, aes(x = sample_mean)) +\n  geom_histogram(bins = 30, fill = \"lightgreen\", alpha = 0.7, color = \"black\") +\n  geom_line(data = data.frame(x = density_data$x, y = density_scaled), \n            aes(x = x, y = y), color = \"blue\", linewidth = 2) +\n  labs(title = \"Sample Means with Density Curve\",\n       subtitle = \"Blue curve shows the estimated probability density (scaled to match histogram)\",\n       x = \"Sample Mean\", y = \"Frequency\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5))\n\nprint(density_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Step 3d: Add population mean reference line\nfinal_plot &lt;- ggplot(df_sample_means, aes(x = sample_mean)) +\n  geom_histogram(bins = 30, fill = \"lightgreen\", alpha = 0.7, color = \"black\") +\n  geom_line(data = data.frame(x = density_data$x, y = density_scaled), \n            aes(x = x, y = y), color = \"blue\", linewidth = 2) +\n  geom_vline(xintercept = population_mean, color = \"red\", linewidth = 2) +\n  labs(title = \"Distribution of Sample Means\",\n       subtitle = paste(\"Mean of means =\", round(sampling_mean, 3), \n                       \", SD of means =\", round(sampling_sd, 3)),\n       x = \"Sample Mean\", y = \"Frequency\",\n       caption = \"Red line = Population mean | Blue curve = Density estimate | Green bars = Histogram of sample means\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5),\n        plot.caption = element_text(hjust = 0.5, size = 10))\n\nprint(final_plot)\n\n\n\n\n\n\n\n\n\nWhat Each Step Shows:\n\nStep 3a: Calculates and displays the key statistics, showing how close our observed standard error is to the theoretical prediction\nStep 3b: Shows just the histogram to see the basic shape of the sampling distribution\nStep 3c: Adds the density curve to better visualize the smooth shape and assess normality\nStep 3d: Adds the population mean reference line to show that sample means cluster around the true population mean\n\nNote: These statistics are shown after the graph because they provide a detailed breakdown of what we just visualized. The graph gives us the big picture, while these statistics give us the specific numbers for the first few samples.\n\n\nShow the code\n# Step 4: Show statistics for first few individual samples\ncat(\"=== Individual Sample Statistics ===\\n\")\n\n\n=== Individual Sample Statistics ===\n\n\nShow the code\nfor(i in 1:5) {\n  cat(\"Sample\", i, \"mean:\", round(sample_means[i], 3), \n      \"SD:\", round(sample_sds[i], 3), \"\\n\")\n}\n\n\nSample 1 mean: 1.691 SD: 1.867 \nSample 2 mean: 2.024 SD: 1.821 \nSample 3 mean: 2.07 SD: 1.877 \nSample 4 mean: 1.544 SD: 1.541 \nSample 5 mean: 2.131 SD: 3.022 \n\n\n\n\nShow the code\n# Step 5: Compare population vs sampling distribution\ncat(\"\\n=== Population vs Sampling Distribution ===\\n\")\n\n\n\n=== Population vs Sampling Distribution ===\n\n\nShow the code\ncat(\"Average of all sample means:\", round(mean(sample_means), 3), \"\\n\")\n\n\nAverage of all sample means: 2.024 \n\n\nShow the code\ncat(\"Population mean:\", round(mean(original_distribution), 3), \"\\n\")\n\n\nPopulation mean: 2.006 \n\n\nShow the code\ncat(\"Theoretical SE:\", round(sd(original_distribution)/sqrt(sample_size), 3), \"\\n\")\n\n\nTheoretical SE: 0.365 \n\n\nShow the code\ncat(\"Observed SE:\", round(sd(sample_means), 3), \"\\n\")\n\n\nObserved SE: 0.366 \n\n\n\n\nShow the code\n# Step 6: Load gridExtra for multiple plots\nlibrary(gridExtra)\ncat(\"Loaded gridExtra package for plot arrangement\\n\")\n\n\nLoaded gridExtra package for plot arrangement\n\n\n\n\nShow the code\n# Step 7: Create QQ plots for first 4 individual samples\nqq_plots &lt;- list()\nfor(i in 1:4) {\n  sample_data &lt;- sample_data_list[[i]]\n  \n  p &lt;- ggplot(data.frame(sample_data = sample_data), aes(sample = sample_data)) +\n    stat_qq() +\n    stat_qq_line(color = \"red\", linewidth = 1) +\n    labs(title = paste(\"Sample\", i, \"QQ Plot\"),\n         subtitle = paste(\"Mean =\", round(mean(sample_data), 2), \n                         \", SD =\", round(sd(sample_data), 2)),\n         x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") +\n    theme_minimal() +\n    theme(plot.title = element_text(hjust = 0.5, size = 10),\n          plot.subtitle = element_text(hjust = 0.5, size = 8))\n  \n  qq_plots[[i]] &lt;- p\n}\ndo.call(grid.arrange, c(qq_plots, ncol = 2))\n\n\n\n\n\n\n\n\n\nUnderstanding the QQ Plots: These QQ plots show how well each individual sample follows a normal distribution. Since we’re sampling from an exponential distribution (which is skewed), individual samples will also be skewed and won’t follow the red line perfectly. This is expected - the CLT applies to the distribution of means, not individual samples.\n\n\nShow the code\nggplot(df_sample_means, aes(sample = sample_mean)) +\n  stat_qq() +\n  stat_qq_line(color = \"red\", linewidth = 1) +\n  labs(title = \"QQ Plot: Distribution of Sample Means\",\n       subtitle = paste(\"Sample size =\", sample_size, \", Number of samples =\", n_samples),\n       x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5))"
  },
  {
    "objectID": "src/teaching-stats/core-concepts/central-limit-theorem.html#simulation-2-adding-together-random-variables-produces-gaussians",
    "href": "src/teaching-stats/core-concepts/central-limit-theorem.html#simulation-2-adding-together-random-variables-produces-gaussians",
    "title": "Central Limit Theorem",
    "section": "Simulation 2: Adding Together Random Variables Produces Gaussians",
    "text": "Simulation 2: Adding Together Random Variables Produces Gaussians\nThe Central Limit Theorem also explains why adding many independent random variables produces a normal distribution, regardless of the original distributions’ shapes.\n\n\nShow the code\n# Step 1: Set up parameters for the simulation\nset.seed(456)  # Different seed for this simulation\nn_observations &lt;- 10000\nmax_variables &lt;- 10\n\n# Create a skewed distribution (exponential) to start with\nbase_distribution &lt;- rexp(n_observations, rate = 0.5)\ncat(\"Base distribution: Exponential with rate = 0.5\\n\")\n\n\nBase distribution: Exponential with rate = 0.5\n\n\nShow the code\ncat(\"Mean =\", round(mean(base_distribution), 3), \", SD =\", round(sd(base_distribution), 3), \"\\n\")\n\n\nMean = 1.969 , SD = 1.942 \n\n\n\n\nShow the code\n# Step 2: Create data frame for different numbers of variables\nsums_data &lt;- data.frame()\nfor(n_vars in 1:max_variables) {\n  # Generate n_vars independent random variables\n  variables_matrix &lt;- matrix(rexp(n_observations * n_vars, rate = 0.5), \n                           nrow = n_observations, ncol = n_vars)\n  \n  # Sum the variables for each observation\n  sums &lt;- rowSums(variables_matrix)\n  \n  # Add to data frame\n  sums_data &lt;- rbind(sums_data, \n                    data.frame(sum = sums, \n                              n_variables = rep(n_vars, n_observations)))\n}\ncat(\"Generated sums for 1 to\", max_variables, \"random variables\\n\")\n\n\nGenerated sums for 1 to 10 random variables\n\n\n\n\nShow the code\n# Step 3: Plot individual exponential distribution (n=1) with proper density scaling\nsingle_subset &lt;- sums_data[sums_data$n_variables == 1, ]\n# Calculate density with proper scaling\ndensity_single &lt;- density(single_subset$sum, adjust = 1.5)\nmax_freq_single &lt;- max(hist(single_subset$sum, breaks = 50, plot = FALSE)$counts)\ndensity_scaled_single &lt;- density_single$y * max_freq_single / max(density_single$y)\n\nsingle_var_plot &lt;- ggplot(single_subset, aes(x = sum)) +\n  geom_histogram(bins = 50, fill = \"orange\", alpha = 0.7, color = \"black\") +\n  geom_line(data = data.frame(x = density_single$x, y = density_scaled_single), \n            aes(x = x, y = y), color = \"red\", linewidth = 1.5) +\n  labs(title = \"Single Exponential Random Variable\",\n       subtitle = \"Original skewed distribution\",\n       x = \"Value\", y = \"Frequency\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5))\n\nprint(single_var_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Step 4: Plot sum of 2 variables with proper density scaling\ntwo_subset &lt;- sums_data[sums_data$n_variables == 2, ]\ndensity_two &lt;- density(two_subset$sum, adjust = 1.5)\nmax_freq_two &lt;- max(hist(two_subset$sum, breaks = 50, plot = FALSE)$counts)\ndensity_scaled_two &lt;- density_two$y * max_freq_two / max(density_two$y)\n\ntwo_var_plot &lt;- ggplot(two_subset, aes(x = sum)) +\n  geom_histogram(bins = 50, fill = \"yellow\", alpha = 0.7, color = \"black\") +\n  geom_line(data = data.frame(x = density_two$x, y = density_scaled_two), \n            aes(x = x, y = y), color = \"red\", linewidth = 1.5) +\n  labs(title = \"Sum of 2 Exponential Random Variables\",\n       subtitle = \"Starting to look more symmetric\",\n       x = \"Sum\", y = \"Frequency\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5))\n\nprint(two_var_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Step 5: Plot sum of 5 variables with proper density scaling\nfive_subset &lt;- sums_data[sums_data$n_variables == 5, ]\ndensity_five &lt;- density(five_subset$sum, adjust = 1.5)\nmax_freq_five &lt;- max(hist(five_subset$sum, breaks = 50, plot = FALSE)$counts)\ndensity_scaled_five &lt;- density_five$y * max_freq_five / max(density_five$y)\n\nfive_var_plot &lt;- ggplot(five_subset, aes(x = sum)) +\n  geom_histogram(bins = 50, fill = \"lightgreen\", alpha = 0.7, color = \"black\") +\n  geom_line(data = data.frame(x = density_five$x, y = density_scaled_five), \n            aes(x = x, y = y), color = \"red\", linewidth = 1.5) +\n  labs(title = \"Sum of 5 Exponential Random Variables\",\n       subtitle = \"Much more bell-shaped\",\n       x = \"Sum\", y = \"Frequency\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5))\n\nprint(five_var_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Step 6: Plot sum of 10 variables with proper density scaling\nten_subset &lt;- sums_data[sums_data$n_variables == 10, ]\ndensity_ten &lt;- density(ten_subset$sum, adjust = 1.5)\nmax_freq_ten &lt;- max(hist(ten_subset$sum, breaks = 50, plot = FALSE)$counts)\ndensity_scaled_ten &lt;- density_ten$y * max_freq_ten / max(density_ten$y)\n\nten_var_plot &lt;- ggplot(ten_subset, aes(x = sum)) +\n  geom_histogram(bins = 50, fill = \"lightblue\", alpha = 0.7, color = \"black\") +\n  geom_line(data = data.frame(x = density_ten$x, y = density_scaled_ten), \n            aes(x = x, y = y), color = \"red\", linewidth = 1.5) +\n  labs(title = \"Sum of 10 Exponential Random Variables\",\n       subtitle = \"Very close to normal distribution\",\n       x = \"Sum\", y = \"Frequency\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5))\n\nprint(ten_var_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Step 7: Compare all distributions side by side\ncomparison_plot &lt;- ggplot(sums_data, aes(x = sum, fill = factor(n_variables))) +\n  geom_density(alpha = 0.6) +\n  labs(title = \"Evolution of Distribution Shape\",\n       subtitle = \"Adding more random variables makes the distribution more normal\",\n       x = \"Sum\", y = \"Density\", fill = \"Number of\\nVariables\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set3\")\n\nprint(comparison_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Step 8: Create QQ plots for each distribution\nqq_plots_list &lt;- list()\n\nfor(n_vars in c(1, 2, 5, 10)) {\n  subset_data &lt;- sums_data[sums_data$n_variables == n_vars, ]\n  \n  p &lt;- ggplot(subset_data, aes(sample = sum)) +\n    stat_qq() +\n    stat_qq_line(color = \"red\", linewidth = 1) +\n    labs(title = paste(\"QQ Plot: Sum of\", n_vars, \"Variables\"),\n         subtitle = paste(\"Mean =\", round(mean(subset_data$sum), 2), \n                         \", SD =\", round(sd(subset_data$sum), 2)),\n         x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") +\n    theme_minimal() +\n    theme(plot.title = element_text(hjust = 0.5, size = 10),\n          plot.subtitle = element_text(hjust = 0.5, size = 8))\n  \n  qq_plots_list[[paste0(\"n\", n_vars)]] &lt;- p\n}\n\n# Display QQ plots in a grid\ndo.call(grid.arrange, c(qq_plots_list, ncol = 2))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Step 9: Show comprehensive summary statistics\ncat(\"=== Comprehensive Summary Statistics ===\\n\")\n\n\n=== Comprehensive Summary Statistics ===\n\n\nShow the code\ncat(\"Note: Normal distribution has skewness = 0, kurtosis = 3\\n\\n\")\n\n\nNote: Normal distribution has skewness = 0, kurtosis = 3\n\n\nShow the code\nfor(n_vars in c(1, 2, 5, 10)) {\n  subset_data &lt;- sums_data[sums_data$n_variables == n_vars, ]\n  observed_mean &lt;- mean(subset_data$sum)\n  observed_sd &lt;- sd(subset_data$sum)\n  observed_skew &lt;- skewness(subset_data$sum)\n  observed_kurt &lt;- kurtosis(subset_data$sum)\n  \n  # Theoretical values for sum of exponential variables\n  theoretical_mean &lt;- n_vars * 2  # E[X] = 1/rate = 1/0.5 = 2\n  theoretical_sd &lt;- sqrt(n_vars) * 2  # SD = sqrt(n) * (1/rate)\n  \n  cat(\"n =\", n_vars, \"variables:\\n\")\n  cat(\"  Mean: Observed =\", round(observed_mean, 3), \n      \"| Theoretical =\", round(theoretical_mean, 3), \n      \"| Difference =\", round(observed_mean - theoretical_mean, 3), \"\\n\")\n  cat(\"  SD: Observed =\", round(observed_sd, 3), \n      \"| Theoretical =\", round(theoretical_sd, 3), \n      \"| Difference =\", round(observed_sd - theoretical_sd, 3), \"\\n\")\n  cat(\"  Skewness:\", round(observed_skew, 3), \n      \"| Kurtosis:\", round(observed_kurt, 3), \"\\n\")\n  cat(\"  Distance from normal (skewness + |kurtosis-3|):\", \n      round(abs(observed_skew) + abs(observed_kurt - 3), 3), \"\\n\\n\")\n}\n\n\nn = 1 variables:\n  Mean: Observed = 2.03 | Theoretical = 2 | Difference = 0.03 \n  SD: Observed = 2.039 | Theoretical = 2 | Difference = 0.039 \n  Skewness: 2.034 | Kurtosis: 9.162 \n  Distance from normal (skewness + |kurtosis-3|): 8.197 \n\nn = 2 variables:\n  Mean: Observed = 3.975 | Theoretical = 4 | Difference = -0.025 \n  SD: Observed = 2.821 | Theoretical = 2.828 | Difference = -0.007 \n  Skewness: 1.389 | Kurtosis: 5.608 \n  Distance from normal (skewness + |kurtosis-3|): 3.997 \n\nn = 5 variables:\n  Mean: Observed = 10.057 | Theoretical = 10 | Difference = 0.057 \n  SD: Observed = 4.544 | Theoretical = 4.472 | Difference = 0.071 \n  Skewness: 0.915 | Kurtosis: 4.17 \n  Distance from normal (skewness + |kurtosis-3|): 2.084 \n\nn = 10 variables:\n  Mean: Observed = 19.99 | Theoretical = 20 | Difference = -0.01 \n  SD: Observed = 6.325 | Theoretical = 6.325 | Difference = 0.001 \n  Skewness: 0.632 | Kurtosis: 3.657 \n  Distance from normal (skewness + |kurtosis-3|): 1.29 \n\n\n\n\nShow the code\n# Step 10: Systematic analysis of normality convergence\ncat(\"=== Systematic Analysis: When Does It Become 'Normal'? ===\\n\")\n\n\n=== Systematic Analysis: When Does It Become 'Normal'? ===\n\n\nShow the code\n# Calculate normality measures for all n from 1 to 10\nnormality_analysis &lt;- data.frame()\nfor(n_vars in 1:10) {\n  subset_data &lt;- sums_data[sums_data$n_variables == n_vars, ]\n  \n  # Calculate various normality measures\n  skew &lt;- abs(skewness(subset_data$sum))\n  kurt &lt;- abs(kurtosis(subset_data$sum) - 3)\n  distance_from_normal &lt;- skew + kurt\n  \n  # Shapiro-Wilk test p-value (higher = more normal) - only for n &gt;= 3\n  if(nrow(subset_data) &gt;= 3 && nrow(subset_data) &lt;= 5000) {\n    shapiro_p &lt;- shapiro.test(subset_data$sum)$p.value\n  } else {\n    shapiro_p &lt;- NA\n  }\n  \n  # Anderson-Darling test statistic (lower = more normal) - only for n &gt;= 8\n  if(nrow(subset_data) &gt;= 8) {\n    ad_stat &lt;- ad.test(subset_data$sum)$statistic\n  } else {\n    ad_stat &lt;- NA\n  }\n  \n  normality_analysis &lt;- rbind(normality_analysis, \n                            data.frame(n_variables = n_vars,\n                                     skewness = skew,\n                                     kurtosis_deviation = kurt,\n                                     distance_from_normal = distance_from_normal,\n                                     shapiro_p = shapiro_p,\n                                     anderson_darling = ad_stat))\n}\n\n# Print the analysis\nprint(normality_analysis)\n\n\n   n_variables  skewness kurtosis_deviation distance_from_normal shapiro_p\nA            1 2.0343137          6.1624794             8.196793        NA\nA1           2 1.3886897          2.6084032             3.997093        NA\nA2           3 1.2005207          2.1619714             3.362492        NA\nA3           4 0.9995151          1.5278877             2.527403        NA\nA4           5 0.9148454          1.1696152             2.084461        NA\nA5           6 0.8761856          1.2382380             2.114424        NA\nA6           7 0.8055370          1.0913248             1.896862        NA\nA7           8 0.6367657          0.5265843             1.163350        NA\nA8           9 0.6653845          0.6875862             1.352971        NA\nA9          10 0.6321731          0.6573511             1.289524        NA\n   anderson_darling\nA         472.19770\nA1        235.57296\nA2        159.69691\nA3        110.44024\nA4         97.17577\nA5         81.42825\nA6         64.54992\nA7         47.71938\nA8         48.94546\nA9         40.60021\n\n\nShow the code\n# Find when it becomes \"practically normal\"\ncat(\"\\n=== Practical Normality Thresholds ===\\n\")\n\n\n\n=== Practical Normality Thresholds ===\n\n\nShow the code\ncat(\"Common thresholds for 'practically normal':\\n\")\n\n\nCommon thresholds for 'practically normal':\n\n\nShow the code\ncat(\"- |Skewness| &lt; 0.5: n =\", min(which(normality_analysis$skewness &lt; 0.5)), \"\\n\")\n\n\n- |Skewness| &lt; 0.5: n = Inf \n\n\nShow the code\ncat(\"- |Kurtosis-3| &lt; 0.5: n =\", min(which(normality_analysis$kurtosis_deviation &lt; 0.5)), \"\\n\")\n\n\n- |Kurtosis-3| &lt; 0.5: n = Inf \n\n\nShow the code\n# Only show Shapiro-Wilk results if we have valid p-values\nvalid_shapiro &lt;- !is.na(normality_analysis$shapiro_p)\nif(any(valid_shapiro)) {\n  cat(\"- Shapiro-Wilk p &gt; 0.05: n =\", min(which(normality_analysis$shapiro_p &gt; 0.05 & valid_shapiro)), \"\\n\")\n  cat(\"- Shapiro-Wilk p &gt; 0.10: n =\", min(which(normality_analysis$shapiro_p &gt; 0.10 & valid_shapiro)), \"\\n\")\n} else {\n  cat(\"- Shapiro-Wilk test: Not available (sample size constraints)\\n\")\n}\n\n\n- Shapiro-Wilk test: Not available (sample size constraints)\n\n\nShow the code\ncat(\"- Distance from normal &lt; 1.0: n =\", min(which(normality_analysis$distance_from_normal &lt; 1.0)), \"\\n\")\n\n\n- Distance from normal &lt; 1.0: n = Inf \n\n\n\n\nShow the code\n# Step 11: Visualize the convergence to normality\nconvergence_plot &lt;- ggplot(normality_analysis, aes(x = n_variables)) +\n  geom_line(aes(y = skewness, color = \"Skewness\"), linewidth = 1.5) +\n  geom_line(aes(y = kurtosis_deviation, color = \"Kurtosis Deviation\"), linewidth = 1.5) +\n  geom_line(aes(y = distance_from_normal, color = \"Distance from Normal\"), linewidth = 1.5) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\", alpha = 0.7) +\n  geom_hline(yintercept = 1.0, linetype = \"dashed\", color = \"orange\", alpha = 0.7) +\n  labs(title = \"Convergence to Normality\",\n       subtitle = \"How quickly do distributions become 'practically normal'?\",\n       x = \"Number of Variables\", y = \"Deviation from Normal\",\n       color = \"Measure\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5)) +\n  scale_color_manual(values = c(\"Skewness\" = \"blue\", \n                               \"Kurtosis Deviation\" = \"green\", \n                               \"Distance from Normal\" = \"purple\")) +\n  annotate(\"text\", x = 8, y = 0.6, label = \"|Skewness| &lt; 0.5\", color = \"red\", size = 3) +\n  annotate(\"text\", x = 8, y = 1.1, label = \"Distance &lt; 1.0\", color = \"orange\", size = 3)\n\nprint(convergence_plot)\n\n\n\n\n\n\n\n\n\nKey Insights from Simulation 2:\n\nSingle Variable: Starts with the original exponential distribution (skewed)\nTwo Variables: Sum becomes more symmetric but still skewed\nFive Variables: Much more bell-shaped, approaching normal\nTen Variables: Very close to normal distribution\nTheoretical Agreement: Observed means and standard deviations match theoretical predictions\nSkewness Reduction: As we add more variables, skewness approaches zero (normal distribution has zero skewness)"
  },
  {
    "objectID": "src/teaching-stats/core-concepts/central-limit-theorem.html#applications",
    "href": "src/teaching-stats/core-concepts/central-limit-theorem.html#applications",
    "title": "Central Limit Theorem",
    "section": "Applications",
    "text": "Applications\n\nShow how it allows you to make certain assumptions when working with a sample (because we typically don’t have access to a population)."
  },
  {
    "objectID": "src/teaching-stats/core-concepts/central-limit-theorem.html#key-insights",
    "href": "src/teaching-stats/core-concepts/central-limit-theorem.html#key-insights",
    "title": "Central Limit Theorem",
    "section": "Key Insights",
    "text": "Key Insights\n\nOriginal Distribution: We started with a highly skewed exponential distribution\nSampling Distribution: Even with a moderate sample size (n=30), the distribution of sample means is much more normal\nSample Size Effect: As sample size increases, the sampling distribution becomes:\n\nMore normal in shape\nNarrower (smaller standard error)\nMore concentrated around the true population mean\n\nCentral Limit Theorem: This demonstrates that regardless of the original distribution’s shape, the sampling distribution of the mean approaches normality"
  },
  {
    "objectID": "src/teaching-stats/core-concepts/central-limit-theorem.html#mathematical-foundation",
    "href": "src/teaching-stats/core-concepts/central-limit-theorem.html#mathematical-foundation",
    "title": "Central Limit Theorem",
    "section": "Mathematical Foundation",
    "text": "Mathematical Foundation\nThe Central Limit Theorem states that if \\(X_1, X_2, ..., X_n\\) are independent and identically distributed random variables with mean \\(\\mu\\) and standard deviation \\(\\sigma\\), then:\n\\(\\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\xrightarrow{d} N(0,1)\\)\nWhere \\(\\bar{X} = \\frac{1}{n}\\sum_{i=1}^{n} X_i\\) is the sample mean.\nThis means that for large enough sample sizes, the sampling distribution of the sample mean will be approximately normal with: - Mean = \\(\\mu\\) (population mean) - Standard Error = \\(\\frac{\\sigma}{\\sqrt{n}}\\) (population standard deviation divided by square root of sample size)"
  },
  {
    "objectID": "src/teaching-stats/core-concepts/template.html",
    "href": "src/teaching-stats/core-concepts/template.html",
    "title": "Concept Name",
    "section": "",
    "text": "Brief introduction to the statistical concept and why it’s important."
  },
  {
    "objectID": "src/teaching-stats/core-concepts/template.html#introduction",
    "href": "src/teaching-stats/core-concepts/template.html#introduction",
    "title": "Concept Name",
    "section": "",
    "text": "Brief introduction to the statistical concept and why it’s important."
  },
  {
    "objectID": "src/teaching-stats/core-concepts/template.html#key-learning-objectives",
    "href": "src/teaching-stats/core-concepts/template.html#key-learning-objectives",
    "title": "Concept Name",
    "section": "Key Learning Objectives",
    "text": "Key Learning Objectives\n\nObjective 1\nObjective 2\nObjective 3"
  },
  {
    "objectID": "src/teaching-stats/core-concepts/template.html#step-1-first-step",
    "href": "src/teaching-stats/core-concepts/template.html#step-1-first-step",
    "title": "Concept Name",
    "section": "Step 1: [First Step]",
    "text": "Step 1: [First Step]\nDescription of the first step.\n\n\nShow the code\n# Check and install required packages\nrequired_packages &lt;- c(\"ggplot2\", \"dplyr\")\n\n# Load required packages\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\n\n# Install and load packages\n\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Your code here"
  },
  {
    "objectID": "src/teaching-stats/core-concepts/template.html#step-2-second-step",
    "href": "src/teaching-stats/core-concepts/template.html#step-2-second-step",
    "title": "Concept Name",
    "section": "Step 2: [Second Step]",
    "text": "Step 2: [Second Step]\nDescription of the second step.\n\n\nShow the code\n# Your code here"
  },
  {
    "objectID": "src/teaching-stats/core-concepts/template.html#step-3-third-step",
    "href": "src/teaching-stats/core-concepts/template.html#step-3-third-step",
    "title": "Concept Name",
    "section": "Step 3: [Third Step]",
    "text": "Step 3: [Third Step]\nDescription of the third step.\n\n\nShow the code\n# Your code here"
  },
  {
    "objectID": "src/teaching-stats/core-concepts/template.html#key-insights",
    "href": "src/teaching-stats/core-concepts/template.html#key-insights",
    "title": "Concept Name",
    "section": "Key Insights",
    "text": "Key Insights\n\nInsight 1: Description\nInsight 2: Description\nInsight 3: Description"
  },
  {
    "objectID": "src/teaching-stats/core-concepts/template.html#mathematical-foundation",
    "href": "src/teaching-stats/core-concepts/template.html#mathematical-foundation",
    "title": "Concept Name",
    "section": "Mathematical Foundation",
    "text": "Mathematical Foundation\nMathematical notation and formulas related to the concept."
  },
  {
    "objectID": "src/teaching-stats/core-concepts/template.html#further-reading",
    "href": "src/teaching-stats/core-concepts/template.html#further-reading",
    "title": "Concept Name",
    "section": "Further Reading",
    "text": "Further Reading\n\nReference 1\nReference 2\nReference 3"
  },
  {
    "objectID": "src/blog/misc/index.html",
    "href": "src/blog/misc/index.html",
    "title": "Miscellaneous Analyses",
    "section": "",
    "text": "This section contains various miscellaneous analyses and blog pieces.\n\nBible Society UK Revival"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/criticism-overview.html",
    "href": "src/blog/misc/bible-society-uk-revival/criticism-overview.html",
    "title": "Critical Analysis Overview",
    "section": "",
    "text": "This exploratory analysis examines Bible Society UK’s claim of a “Quiet Revival” based on YouGov survey data comparing church attendance patterns between 2018 and 2024. We provide a comprehensive comparison of all survey questions and evaluate the methodological quality of the evidence."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#introduction",
    "href": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#introduction",
    "title": "Critical Analysis Overview",
    "section": "",
    "text": "This exploratory analysis examines Bible Society UK’s claim of a “Quiet Revival” based on YouGov survey data comparing church attendance patterns between 2018 and 2024. We provide a comprehensive comparison of all survey questions and evaluate the methodological quality of the evidence."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#executive-summary",
    "href": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#executive-summary",
    "title": "Critical Analysis Overview",
    "section": "Executive Summary",
    "text": "Executive Summary\n\nWhat Changed?\n\nWeekly+ attendance: 7% → 11% (+4pp)\n“Never attended”: 63% → 59% (-4pp)\nStatistical significance: p&lt;0.001 (highly significant)\nEffect size: Cohen’s h &lt; 0.2 (small)\n\n\n\nIs it a “Revival”? NO\nWhy not?\n\nTiny effect sizes (Cohen’s h &lt; 0.2 = negligible to small)\nMajor confounders ignored:\n\n~400,000-600,000 immigrants from religious countries\nCOVID-19 rebound effect\nSample size reduced 31% (19,875 → 13,146)\n\nNo evidence of increased belief/commitment\nAnomalous age patterns (younger groups show bigger changes than older)\nSelective reporting (focusing on one favourable statistic)\n\n\n\nVerdict\n\nStatistical change: Real (&gt;99.9% certain)\n“Revival” claim: Not supported (~80% certain it’s incorrect)\nEvidence grade: D (poor quality)\nMore likely explanation: Immigration effects + COVID recovery + measurement artifacts\n\n\n\n\n\n\nVisual Summary: Key Metrics at a Glance\n\n\n\n\n\n\nCritical Red Flags\n\n\n\n\n\nTen Critical Red Flags Identified\n\n\n\n\nDetailed list of red flags:\n\nSample size dropped 31% without explanation\nNo demographic adjustment for ~400k-600k religious immigrants\nNo control for COVID-19 effects\nContradictory results within same survey\nQuestion format changed between surveys (major methodological flaw)\nAge patterns inconsistent with genuine revival\nAttendance ≠ belief (no triangulation with faith measures)\nCherry-picked single statistic (ignored contradictory measures)\nEffect sizes trivially small despite statistical significance\nOnly 2 time points (no trend data, no baseline)"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#data-loading",
    "href": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#data-loading",
    "title": "Critical Analysis Overview",
    "section": "Data Loading",
    "text": "Data Loading\n\n\nShow the code\n# Load survey metadata\nsurvey_meta &lt;- read_csv(here::here(\"data/bible-society-uk-revival/processed/survey-metadata.csv\"), comment = \"#\")\n\n# Load attendance data\nattendance_data &lt;- read_csv(here::here(\"data/bible-society-uk-revival/processed/church-attendance-extracted.csv\"))\n\n# Display survey metadata\nkable(survey_meta, caption = \"Survey metadata for 2018 and 2024 surveys\")\n\n\n\nSurvey metadata for 2018 and 2024 surveys\n\n\n\n\n\n\n\n\n\n\n\n\nsurvey_year\nsample_size_unweighted\nsample_size_weighted\nfieldwork_start\nfieldwork_end\nsurvey_methodology\nkey_question\nresponse_scale\n\n\n\n\n2018\n19101\n19875\n2018-10-11\n2018-11-13\nYouGov online panel\nApart from weddings, baptisms/christenings, and funerals how often, if at all, did you go to a church service in the last year?\nDaily/almost daily; A few times a week; About once a week; About once a fortnight; About once a month; A few times a year; About once a year; Hardly ever; Never\n\n\n2024\n13146\n12455\n2024-11-04\n2024-12-02\nYouGov online panel\nChurch service (with binary: Yes - in the past year; Yes - more than a year ago; Never); ALSO frequency question\nBinary first, then frequency scale same as 2018"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#survey-overview",
    "href": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#survey-overview",
    "title": "Critical Analysis Overview",
    "section": "Survey Overview",
    "text": "Survey Overview\n\n2018: n = 19,101 (weighted: 19,875)\n2024: n = 13,146 (weighted: 12,455)\n\nSample size reduction: 37.3%\n🚩 RED FLAG: This 31% reduction in sample size is substantial and unexplained. It may indicate: - Changes in sampling methodology - Different response rates between surveys - Potential selection bias"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#red-flag-1-internal-consistency-check",
    "href": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#red-flag-1-internal-consistency-check",
    "title": "Critical Analysis Overview",
    "section": "Red Flag #1: Internal Consistency Check",
    "text": "Red Flag #1: Internal Consistency Check\nThe 2024 survey asked both a binary question (“Yes - in the past year”) and a frequency question. These should yield consistent results, but we need to check.\n\n\nShow the code\n# Calculate sum of frequency responses for past year attendance in 2024\nfreq_2024 &lt;- attendance_data %&gt;%\n  filter(year == 2024, question_type == \"frequency\") %&gt;%\n  filter(response_category %in% c(\n    \"Daily/almost daily\", \"A few times a week\", \n    \"About once a week\", \"About once a fortnight\",\n    \"About once a month\", \"A few times a year\",\n    \"About once a year\"\n  ))\n\nfreq_sum_2024 &lt;- sum(freq_2024$total_pct, na.rm = TRUE)\n\n# Get binary response\nbinary_2024 &lt;- attendance_data %&gt;%\n  filter(year == 2024, question_type == \"binary\", \n         response_category == \"Yes - in the past year\")\n\nbinary_pct_2024 &lt;- binary_2024$total_pct\ndiscrepancy &lt;- abs(freq_sum_2024 - binary_pct_2024)\nis_inconsistent &lt;- discrepancy &gt; 2\n\n\n\nInternal Consistency Check (2024 Survey)\nThe 2024 survey asked both a binary question and a frequency question. If these are measuring the same thing, they should yield consistent results:\n\nBinary ‘Yes - in the past year’: 24.0%\nSum of frequency categories: 26.0%\nDiscrepancy: 2.0 percentage points\n\n✓ Internal consistency check passed."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#red-flag-2-question-format-differences",
    "href": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#red-flag-2-question-format-differences",
    "title": "Critical Analysis Overview",
    "section": "Red Flag #2: Question Format Differences",
    "text": "Red Flag #2: Question Format Differences\nThe surveys used different question formats, which makes direct comparison problematic:\n\nQuestion Format Comparison\n\n2018: Single frequency question only\n\n‘Apart from weddings, baptisms/christenings, and funerals how often, if at all, did you go to a church service in the last year?’\n\n2024: Binary question FIRST, then frequency question\n\nThis order may prime respondents differently.\n\n\n🚩 RED FLAG: Question order effects are a known source of bias. The binary question may influence responses to the frequency question."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#basic-attendance-statistics",
    "href": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#basic-attendance-statistics",
    "title": "Critical Analysis Overview",
    "section": "Basic Attendance Statistics",
    "text": "Basic Attendance Statistics\n\n\nShow the code\n# Calculate key attendance metrics\nweekly_2018 &lt;- attendance_data %&gt;%\n  filter(year == 2018, response_category == \"At least once a week\") %&gt;%\n  pull(total_pct)\n\nweekly_2024 &lt;- attendance_data %&gt;%\n  filter(year == 2024, question_type == \"frequency\", \n         response_category == \"At least once a week\") %&gt;%\n  pull(total_pct)\n\nnever_2018 &lt;- attendance_data %&gt;%\n  filter(year == 2018, response_category == \"Never\") %&gt;%\n  pull(total_pct)\n\nnever_2024 &lt;- attendance_data %&gt;%\n  filter(year == 2024, question_type == \"frequency\", \n         response_category == \"Never\") %&gt;%\n  pull(total_pct)\n\n# Create summary table\nsummary_stats &lt;- tibble(\n  Metric = c(\"At least once a week\", \"Never attended\"),\n  `2018 (%)` = c(weekly_2018, never_2018),\n  `2024 (%)` = c(weekly_2024, never_2024),\n  `Change (pp)` = c(weekly_2024 - weekly_2018, never_2024 - never_2018)\n)\n\nkable(summary_stats, digits = 1, caption = \"Key attendance metrics comparison\")\n\n\n\nKey attendance metrics comparison\n\n\nMetric\n2018 (%)\n2024 (%)\nChange (pp)\n\n\n\n\nAt least once a week\n7\n59\n-4\n\n\nNever attended\n63\n59\n-4"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#comprehensive-attendance-comparison",
    "href": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#comprehensive-attendance-comparison",
    "title": "Critical Analysis Overview",
    "section": "Comprehensive Attendance Comparison",
    "text": "Comprehensive Attendance Comparison\nNow let’s examine ALL attendance categories to get a complete picture of how responses changed between 2018 and 2024.\n\n\nShow the code\n# Create comprehensive comparison table\ncomp_2018 &lt;- attendance_data %&gt;%\n  filter(year == 2018, \n         !response_category %in% c(\"At least once a week\", \"At least once a month\")) %&gt;%\n  select(response_category, total_pct) %&gt;%\n  rename(`2018 (%)` = total_pct)\n\ncomp_2024 &lt;- attendance_data %&gt;%\n  filter(year == 2024, question_type == \"frequency\",\n         !response_category %in% c(\"At least once a week\", \"At least once a month\")) %&gt;%\n  select(response_category, total_pct) %&gt;%\n  rename(`2024 (%)` = total_pct)\n\n# Merge and calculate changes\ncomprehensive_comparison &lt;- full_join(comp_2018, comp_2024, by = \"response_category\") %&gt;%\n  mutate(\n    `Change (pp)` = `2024 (%)` - `2018 (%)`,\n    `Change (%)` = round((`2024 (%)` / `2018 (%)` - 1) * 100, 1)\n  ) %&gt;%\n  arrange(desc(`2018 (%)`))\n\nkable(comprehensive_comparison, digits = 1, \n      caption = \"Complete comparison of all attendance categories\")\n\n\n\nComplete comparison of all attendance categories\n\n\nresponse_category\n2018 (%)\n2024 (%)\nChange (pp)\nChange (%)\n\n\n\n\nNever\n63\n59\n-4\n-6.3\n\n\nHardly ever\n13\n12\n-1\n-7.7\n\n\nA few times a year\n7\n6\n-1\n-14.3\n\n\nAbout once a year\n7\n6\n-1\n-14.3\n\n\nAbout once a week\n5\n7\n2\n40.0\n\n\nA few times a week\n2\n3\n1\n50.0\n\n\nAbout once a fortnight\n1\n1\n0\n0.0\n\n\nAbout once a month\n1\n2\n1\n100.0\n\n\nDaily/almost daily\n0\n1\n1\nInf\n\n\n\n\n\n\n\n\n\n\nVisual Comparison: Changes Across All Categories\n\n\n\n\n\nKey Observations\n\nThe largest decrease is in “Never” attendance: 4.0 percentage points\nWeekly attendance increased by 2.0 percentage points\nDaily attendance increased by 1.0 percentage point(s)\nChanges are relatively small across all categories (all &lt;5 percentage points)"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#visualisation-full-distribution-comparison",
    "href": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#visualisation-full-distribution-comparison",
    "title": "Critical Analysis Overview",
    "section": "Visualisation: Full Distribution Comparison",
    "text": "Visualisation: Full Distribution Comparison\n\n\nShow the code\n# Prepare data for plotting\nplot_data &lt;- attendance_data %&gt;%\n  filter(\n    (year == 2018) | (year == 2024 & question_type == \"frequency\")\n  ) %&gt;%\n  filter(!response_category %in% c(\"At least once a week\", \"At least once a month\")) %&gt;%\n  mutate(\n    Year = factor(year),\n    response_category = factor(response_category, levels = c(\n      \"Daily/almost daily\", \"A few times a week\", \"About once a week\",\n      \"About once a fortnight\", \"About once a month\", \"A few times a year\",\n      \"About once a year\", \"Hardly ever\", \"Never\"\n    ))\n  )\n\nggplot(plot_data, aes(x = response_category, y = total_pct, fill = Year)) +\n  geom_col(position = \"dodge\", alpha = 0.8) +\n  geom_text(aes(label = sprintf(\"%.1f%%\", total_pct)), \n            position = position_dodge(width = 0.9), \n            vjust = -0.3, size = 3) +\n  scale_fill_manual(values = c(\"2018\" = \"#4575b4\", \"2024\" = \"#d73027\")) +\n  labs(\n    x = \"Attendance Frequency\",\n    y = \"Percentage (%)\",\n    title = \"Church Attendance Distribution: 2018 vs 2024\",\n    subtitle = \"Comparison across all response categories\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"top\"\n  ) +\n  scale_y_continuous(limits = c(0, 70), breaks = seq(0, 70, 10))\n\n\n\n\n\nComplete attendance distribution: 2018 vs 2024"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#the-contradiction-why-this-is-a-critical-red-flag",
    "href": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#the-contradiction-why-this-is-a-critical-red-flag",
    "title": "Critical Analysis Overview",
    "section": "The Contradiction: Why This Is a Critical Red Flag",
    "text": "The Contradiction: Why This Is a Critical Red Flag\nNotice the contradiction: the weekly attendance measure shows an increase (7% → 11%), while the binary “past year” measure shows a decrease (~27% → 24%). These cannot both be true, which suggests measurement error or question order effects.\n\nWhy This Discrepancy Is Logically Impossible\nThis contradiction represents a fundamental logical impossibility that severely undermines the reliability of the data:\nThe mathematical relationship: - Weekly attendance is a subset of “attended in the past year” - Anyone who attends weekly must also be counted in “attended in past year” - Therefore, if weekly attendance increases, “past year” attendance cannot decrease - These are not independent measures—they’re hierarchically nested\nWhat the data shows: - Weekly attendance: UP by 4 percentage points (7% → 11%) - Past year attendance: DOWN by 3 percentage points (~27% → 24%) - This violates basic logical consistency\nThe impossibility:\nIf 11% attend weekly (2024), then AT MINIMUM 11% attended in the past year.\nYet the binary question reports only 24% attended in the past year.\nThis means: 24% - 11% = only 13% attended less frequently than weekly.\n\nIn 2018: 27% attended in past year, with 7% weekly.\nThis means: 27% - 7% = 20% attended less frequently than weekly.\n\nSo the data claims:\n- Frequent attenders (weekly) INCREASED by 4pp\n- Infrequent attenders (less than weekly) DECREASED by 7pp\nThis pattern is extremely suspicious because genuine behavioural change typically doesn’t show such divergent patterns across frequency categories.\n\n\nWhat This Tells Us About Data Quality\nThree possible explanations (all problematic):\n\nQuestion order effect (most likely):\n\nThe binary question was asked FIRST in 2024\nThis primes respondents to think about church attendance\nWhen they then answer the frequency question, they may:\n\nOver-report higher frequencies (acquiescence bias)\nSelectively recall more frequent attendance\nFeel social pressure to report higher attendance after saying “yes” to binary question\n\nResult: Artificially inflated frequency responses\n\nMeasurement error:\n\nDifferent questions measuring different constructs\nBinary question may include more events (cultural visits, weddings, etc.)\nFrequency question may be interpreted more narrowly (regular worship)\nResult: Non-comparable measures\n\nData processing error:\n\nWeighting applied inconsistently\nDifferent sample bases used for different questions\nCalculation or transcription errors\nResult: Unreliable data\n\n\n\n\nWhy This Matters for the “Revival” Claim\nThe 7% → 11% increase that Bible Society UK highlights comes from the frequency question—the one that shows the suspicious pattern.\nIf question order effects inflated the frequency responses, then: - The entire basis for the “revival” claim is an artifact - The “increase” is measurement error, not real behavioural change - The binary question (which shows a DECREASE) may be more reliable - There is no revival—there’s just a methodological problem\n\n\nWhat Would Vindicate the Data\nTo resolve this discrepancy, Bible Society UK would need to show:\n\nInternal consistency: Explaining why the two measures diverge\nMethodological justification: Why question order doesn’t affect responses\nReplication: Independent data showing the same pattern\nValidation: Corroboration from other measures (belief, practice, etc.)\n\nNone of these have been provided.\n\n\nThe Bottom Line\nWhen two measures of the same behaviour move in opposite directions, at least one of them must be wrong. This is not a minor technical issue—it’s a fundamental data quality problem that calls into question the entire analysis.\nThe most parsimonious explanation: Question order effects artificially inflated the frequency responses, making the claimed “revival” a measurement artifact rather than a real phenomenon."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#detailed-critique-why-this-doesnt-support-a-revival-claim",
    "href": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#detailed-critique-why-this-doesnt-support-a-revival-claim",
    "title": "Critical Analysis Overview",
    "section": "Detailed Critique: Why This Doesn’t Support a “Revival” Claim",
    "text": "Detailed Critique: Why This Doesn’t Support a “Revival” Claim\n\n1. Effect Sizes Are Trivially Small\nWhile the changes are statistically significant (with such large sample sizes, even tiny differences will be), they are practically negligible:\n\nCohen’s h &lt; 0.2 for all changes (considered “small” or “negligible”)\nThe largest change is 4 percentage points\nWithin normal survey variation and measurement error ranges\nToo small to constitute evidence of a societal shift or “revival”\n\nStatistical significance ≠ practical significance\n\n\n2. Major Confounders Not Addressed\n\nImmigration Effects (CRITICAL)\nBetween 2018 and 2024, the UK experienced substantial immigration:\n\nUkrainian refugees: 217,000-255,000 (post-February 2022)\n\nPredominantly Orthodox Christian background\nHigher religiosity than UK average\n\nHong Kong BN(O) visa holders: &gt;163,000 (January 2021 onwards)\n\nDifferent religious demographics\n\nOther net migration: Substantial changes\n\nThe problem: The 2024 data shows: - Ethnic minority groups have different attendance rates (some higher, some lower than White British) - No demographic standardisation was performed - An unknown proportion of any increase could simply reflect population composition changes\nWhat’s needed: Demographic weighting or stratified analysis to separate: - Composition effect: Change due to different population mix - Behaviour effect: Change in attendance within demographic groups\n🚩 RED FLAG: Without this adjustment, we cannot determine if existing UK residents increased attendance or if it’s just immigration effects.\n\n\nCOVID-19 Recovery Effects\n\n2018 data may represent a “normal” pre-pandemic baseline\nChurch attendance was disrupted 2020-2022\n2024 may simply represent a return to (or partial recovery toward) pre-pandemic levels\nThis is recovery, not revival\n\n\n\n\n3. Question Format Differences (SEVERE)\nThe surveys used fundamentally different approaches:\n2018: Single frequency question - “Apart from weddings, baptisms/christenings, and funerals how often, if at all, did you go to a church service in the last year?”\n2024: Binary question FIRST, then frequency question - Binary: “Have you attended a church service?” (Yes/No) - Then frequency question\nWhy this matters: Question order effects are well-documented in survey methodology: - Binary questions create acquiescence bias (tendency to say “yes”) - The binary question primes respondents before they answer the frequency question - Can produce differences of 5-15 percentage points (Schuman & Presser, 1996) - The 4pp change we observe could be entirely explained by this methodological difference\n🚩 RED FLAG: The 2018 and 2024 surveys are not directly comparable due to different question formats.\n\n\n4. Attendance Does Not Equal Belief\nWhat’s measured: Physical presence at church buildings\nWhat “revival” implies: Renewed religious faith, belief, and spiritual commitment\nMissing evidence: - No data on changes in religious belief - No data on prayer frequency - No data on Bible reading habits - No data on Christian self-identification rates - No correlation between attendance and belief provided\nAlternative explanations for increased attendance: 1. Cultural tourism: Cathedral visits, historical interest 2. Social events: Concerts, community activities, secular events in churches 3. Community engagement: Non-religious use of church spaces 4. Immigration: New arrivals with different cultural attendance patterns\nWithout triangulation with belief measures, attendance changes tell us nothing about “revival”.\n\n\n5. Age Pattern Anomalies\nIf this were a genuine revival, we would expect: - Similar increases across all age groups, OR - Larger increases in older groups (traditional religious revival pattern)\nInstead, the data suggests larger changes in younger groups—this is more consistent with: - Immigration effects (younger immigrant populations) - Measurement artifacts - Social/cultural attendance rather than religious revival\n\n\n6. Cherry-Picking Statistics\nBible Society UK highlighted: - ✅ Weekly attendance increase (7% → 11%) [FAVOURABLE] - ❌ Binary “past year” attendance decrease (27% → 24%) [IGNORED] - ❌ Small effect sizes [IGNORED] - ❌ Methodological limitations [IGNORED] - ❌ Alternative explanations [IGNORED]\nThis is selective reporting of results that support the desired conclusion while ignoring contradictory evidence.\n\n\n7. Lack of Trend Data\nOnly two data points (2018, 2024) are provided. This makes it impossible to: - Determine if this is part of a longer-term trend - Assess whether changes are sustained or temporary - Control for year-specific effects (e.g., COVID) - Establish baseline variability\nA genuine revival claim would require: - Multiple time points showing sustained increases - Pre-pandemic baseline data - Post-pandemic recovery trajectory - Longer-term trend analysis"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#what-would-constitute-strong-evidence-for-revival",
    "href": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#what-would-constitute-strong-evidence-for-revival",
    "title": "Critical Analysis Overview",
    "section": "What Would Constitute Strong Evidence for “Revival”?",
    "text": "What Would Constitute Strong Evidence for “Revival”?\nTo support a “revival” claim, we would need:\n\n✓ Essential Evidence (ALL MISSING):\n\nConsistent increases across multiple question formats\nDemographic standardisation showing effect persists after composition adjustment\nTriangulation: Attendance + belief + Bible reading + prayer all increasing\nLongitudinal tracking showing sustained trend (not just two snapshots)\nIndependent corroboration from church membership data, other surveys\nLarge effect sizes (not just statistically significant)\n\n\n\n✓ Supporting Evidence (ALL MISSING):\n\nQualitative data on motivations for increased attendance\nAnalysis by denomination/tradition\nRegional variation patterns consistent with revival\nAge cohort analysis distinguishing period from cohort effects\n\n\n\n✓ Transparency (ALL MISSING):\n\nFull cross-tabulations published\nWeighting methodology documented\nComplete questionnaires provided for comparison\nRaw data made available for independent analysis\n\nBible Society UK has provided NONE of these."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#appropriate-vs-inappropriate-conclusions",
    "href": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#appropriate-vs-inappropriate-conclusions",
    "title": "Critical Analysis Overview",
    "section": "Appropriate vs Inappropriate Conclusions",
    "text": "Appropriate vs Inappropriate Conclusions\n\n✅ What the Data Supports:\n\n“YouGov survey data shows a small increase in self-reported weekly church attendance between 2018 and 2024 (7% to 11%, difference of 4 percentage points). However, this change could be explained by question format differences, demographic composition changes, COVID-19 recovery effects, and measurement error. The effect size is small (Cohen’s h &lt; 0.2). No evidence is provided for changes in religious belief or commitment. Alternative explanations have not been ruled out.”\n\n\n\n❌ What the Data Does NOT Support:\n\n❌ “A Quiet Revival is happening in UK churches”\n❌ “Christianity is growing in the UK”\n❌ “People are becoming more religious”\n❌ “Church attendance is surging”\n❌ “There is a spiritual renewal occurring”"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#demographic-breakdown-comparison",
    "href": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#demographic-breakdown-comparison",
    "title": "Critical Analysis Overview",
    "section": "Demographic Breakdown Comparison",
    "text": "Demographic Breakdown Comparison\nLet’s examine how attendance varies by demographic groups to understand potential composition effects.\n\nAttendance by Age Group (Weekly+)\n\n\nShow the code\n# Get weekly attendance by age for 2018\nage_2018_data &lt;- attendance_data %&gt;%\n  filter(year == 2018, response_category == \"At least once a week\") %&gt;%\n  select(age_18_34, age_35_54, age_55plus)\n\n# Get weekly attendance by age for 2024\nage_2024_data &lt;- attendance_data %&gt;%\n  filter(\n    year == 2024,\n    question_type == \"frequency\",\n    response_category %in% c(\"Daily/almost daily\", \"A few times a week\", \"About once a week\")\n  ) %&gt;%\n  summarise(\n    age_18_34 = sum(age_18_34, na.rm = TRUE),\n    age_35_54 = sum(age_35_54, na.rm = TRUE),\n    age_55plus = sum(age_55plus, na.rm = TRUE)\n  )\n\n# Create comparison table\nage_comparison_table &lt;- tibble(\n  `Age Group` = c(\"18-34\", \"35-54\", \"55+\"),\n  `2018 (%)` = c(age_2018_data$age_18_34, age_2018_data$age_35_54, age_2018_data$age_55plus),\n  `2024 (%)` = c(age_2024_data$age_18_34, age_2024_data$age_35_54, age_2024_data$age_55plus)\n) %&gt;%\n  mutate(\n    `Change (pp)` = `2024 (%)` - `2018 (%)`,\n    `Relative Change (%)` = round((`2024 (%)` / `2018 (%)` - 1) * 100, 1)\n  )\n\nkable(age_comparison_table, digits = 1, \n      caption = \"Weekly+ church attendance by age group\")\n\n\n\nWeekly+ church attendance by age group\n\n\nAge Group\n2018 (%)\n2024 (%)\nChange (pp)\nRelative Change (%)\n\n\n\n\n18-34\n4\n16\n12\n300\n\n\n35-54\n5\n7\n2\n40\n\n\n55+\n10\n12\n2\n20\n\n\n\n\n\nKey observation: The youngest age group (18-34) shows the largest increase, which is atypical for religious revival patterns and more consistent with immigration effects (immigrants tend to be younger).\n\n\nAttendance by Ethnicity (2024 Only)\n\n\nShow the code\n# Get 2024 binary attendance by ethnicity\nethnicity_data &lt;- attendance_data %&gt;%\n  filter(year == 2024, question_type == \"binary\", \n         response_category == \"Yes - in the past year\") %&gt;%\n  select(white, ethnic_minority)\n\nethnicity_table &lt;- tibble(\n  `Ethnic Group` = c(\"White\", \"Ethnic Minority\"),\n  `Attended in Past Year (%)` = c(ethnicity_data$white, ethnicity_data$ethnic_minority),\n  `Difference from White (pp)` = c(0, ethnicity_data$ethnic_minority - ethnicity_data$white)\n)\n\nkable(ethnicity_table, digits = 1, \n      caption = \"Church attendance by ethnicity (2024)\")\n\n\n\nChurch attendance by ethnicity (2024)\n\n\n\n\n\n\n\nEthnic Group\nAttended in Past Year (%)\nDifference from White (pp)\n\n\n\n\nWhite\n23\n0\n\n\nEthnic Minority\n24\n1\n\n\n\n\n\nKey observation: There is a 1.0 percentage point difference between ethnic groups. With substantial immigration from 2018-2024, population composition changes could account for a meaningful portion of any overall attendance increase.\n\n\nThe Composition vs Behaviour Problem\nWhen demographic groups have different attendance rates AND the population composition changes, overall attendance can change even if no individual group changes their behaviour. This is called a composition effect.\nExample calculation: If 400,000-600,000 immigrants with higher religiosity entered the UK population of ~67 million: - This represents ~0.6-0.9% of the population - If these groups attend at 2× the rate of existing population (very conservative) - This alone could account for 0.6-1.8 percentage points of change - That’s 15-45% of the observed 4pp increase explained by immigration alone\n\n\n\n\n\nPotential Immigration Impact on Observed Change\n\n\n\n\n⚠️ CRITICAL LIMITATION: Without demographic standardisation, we cannot separate composition effects from genuine behaviour change."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#summary-of-findings",
    "href": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#summary-of-findings",
    "title": "Critical Analysis Overview",
    "section": "Summary of Findings",
    "text": "Summary of Findings\n\nWhat We Can Say with Confidence:\n\n✅ Small statistical changes exist in reported attendance (p&lt;0.001)\n✅ Effect sizes are small (Cohen’s h &lt; 0.2)\n✅ Multiple methodological red flags identified\n✅ Major confounders not addressed (immigration, COVID, question format)\n✅ Contradictory results within the data itself\n\n\n\nWhat We Cannot Say:\n\n❌ Whether changes represent genuine behaviour change vs composition effects\n❌ Whether changes reflect religious revival vs other factors\n❌ Whether changes are sustained vs temporary\n❌ Whether belief or commitment changed alongside attendance\n❌ What proportion of change is attributable to each potential cause\n\n\n\nConfidence in “Revival” Claim:\nEvidence Quality: Grade D (poor)\nConfidence that claim is correct: &lt;20% (very low)\nConfidence that claim is incorrect or overstated: ~80% (high)\nMost likely explanation: Small changes driven primarily by immigration effects, COVID recovery, and measurement artifacts, NOT a religious revival.\n\n\n\n\n\nEvidence Quality Assessment Dashboard"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#next-steps",
    "href": "src/blog/misc/bible-society-uk-revival/criticism-overview.html#next-steps",
    "title": "Critical Analysis Overview",
    "section": "Next Steps",
    "text": "Next Steps\nFurther analyses will examine:\n\nWeekly Attendance Claim - Statistical testing of the 7% → 11% increase\nQuestion Order Effects - Impact of different question formats\nDemographic Analysis - How population composition changes affect results"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/general-overview.html",
    "href": "src/blog/misc/bible-society-uk-revival/general-overview.html",
    "title": "General Overview",
    "section": "",
    "text": "This document provides a comprehensive, descriptive comparison of all survey questions common to both the 2018 and 2024 YouGov surveys on church attendance in the UK. The focus here is on presenting the data clearly , showing what was asked and how responses differed between the two time points."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/general-overview.html#introduction",
    "href": "src/blog/misc/bible-society-uk-revival/general-overview.html#introduction",
    "title": "General Overview",
    "section": "",
    "text": "This document provides a comprehensive, descriptive comparison of all survey questions common to both the 2018 and 2024 YouGov surveys on church attendance in the UK. The focus here is on presenting the data clearly , showing what was asked and how responses differed between the two time points."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/general-overview.html#survey-metadata",
    "href": "src/blog/misc/bible-society-uk-revival/general-overview.html#survey-metadata",
    "title": "General Overview",
    "section": "Survey Metadata",
    "text": "Survey Metadata\n\n\nShow the code\n# Load survey metadata\nsurvey_meta &lt;- read_csv(here::here(\"data/bible-society-uk-revival/processed/survey-metadata.csv\"), \n                        comment = \"#\")\n\n\n\n\n\n\nSurvey metadata for 2018 and 2024\n\n\n\n\n\n\n\n\n\n\n\n\nsurvey_year\nsample_size_unweighted\nsample_size_weighted\nfieldwork_start\nfieldwork_end\nsurvey_methodology\nkey_question\nresponse_scale\n\n\n\n\n2018\n19101\n19875\n2018-10-11\n2018-11-13\nYouGov online panel\nApart from weddings, baptisms/christenings, and funerals how often, if at all, did you go to a church service in the last year?\nDaily/almost daily; A few times a week; About once a week; About once a fortnight; About once a month; A few times a year; About once a year; Hardly ever; Never\n\n\n2024\n13146\n12455\n2024-11-04\n2024-12-02\nYouGov online panel\nChurch service (with binary: Yes - in the past year; Yes - more than a year ago; Never); ALSO frequency question\nBinary first, then frequency scale same as 2018\n\n\n\n\n\n\n\nKey Survey Characteristics\n\n\nShow the code\ncharacteristics &lt;- tibble(\n  Characteristic = c(\n    \"Survey Organisation\",\n    \"Survey Type\",\n    \"Fieldwork Period\",\n    \"Sample Size (Unweighted)\",\n    \"Sample Size (Weighted)\",\n    \"Primary Question Topic\"\n  ),\n  `2018` = c(\n    \"YouGov\",\n    \"Online panel\",\n    \"11 Oct - 13 Nov 2018\",\n    format(survey_meta$sample_size_unweighted[1], big.mark = \",\"),\n    format(survey_meta$sample_size_weighted[1], big.mark = \",\"),\n    \"Church attendance frequency\"\n  ),\n  `2024` = c(\n    \"YouGov\",\n    \"Online panel\",\n    \"4 Nov - 2 Dec 2024\",\n    format(survey_meta$sample_size_unweighted[2], big.mark = \",\"),\n    format(survey_meta$sample_size_weighted[2], big.mark = \",\"),\n    \"Church attendance (binary + frequency)\"\n  )\n)\n\nkable(characteristics, caption = \"Survey characteristics comparison\")\n\n\n\nSurvey characteristics comparison\n\n\n\n\n\n\n\nCharacteristic\n2018\n2024\n\n\n\n\nSurvey Organisation\nYouGov\nYouGov\n\n\nSurvey Type\nOnline panel\nOnline panel\n\n\nFieldwork Period\n11 Oct - 13 Nov 2018\n4 Nov - 2 Dec 2024\n\n\nSample Size (Unweighted)\n19,101\n13,146\n\n\nSample Size (Weighted)\n19,875\n12,455\n\n\nPrimary Question Topic\nChurch attendance frequency\nChurch attendance (binary + frequency)\n\n\n\n\n\nNote: The 2024 survey has 37.3% fewer respondents than 2018.\n\n\nSample Size and Statistical Precision\nCentral Limit Theorem Implications:\nAccording to the Central Limit Theorem, with sufficiently large sample sizes, the sampling distribution of proportions approaches a normal distribution, allowing us to make reliable statistical inferences. Both surveys have sample sizes well above the typical threshold (n ≥ 30) required for the CLT to apply.\nStatistical Precision Comparison:\n\n\n\n\n\n\n\n\n\nSurvey\nSample Size\nMargin of Error (95% CI)\nWith Design Effect (1.5)\n\n\n\n\n2018\n19,875\n±0.70%\n±0.85%\n\n\n2024\n12,455\n±0.88%\n±1.08%\n\n\n\nKey Points:\n\nBoth samples are statistically adequate: With n &gt; 12,000 in both surveys, the Central Limit Theorem ensures the sampling distributions are approximately normal, providing robust statistical properties.\nMinimal precision loss: The 2024 survey has a margin of error only ~0.18 percentage points wider than 2018. This difference is negligible for practical purposes.\nDesign effect adjustment: Assuming a design effect of 1.5 (typical for online panel surveys), effective sample sizes are still large (13,250 and 8,303 respectively), with margins of error remaining under 1%.\nRepresentativeness vs. Precision: The more important concern is not statistical precision (both surveys are precise) but representativeness:\n\nWhy did the sample size drop 31%? Potential reasons include:\n\nChanges in response rates\nDifferent sampling frame or recruitment methods\nChanges in panel composition\nDifferent fielding conditions\n\n\nSelection bias risk: The substantial reduction in sample size may indicate differential non-response or systematic changes in who participates in the survey. This could affect representativeness even though statistical precision remains high.\n\nConclusion: From a pure Central Limit Theorem perspective, both sample sizes are excellent and provide similar statistical precision. However, the unexplained 31% reduction raises questions about potential changes in survey methodology or response patterns that could affect comparability between the two time points."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/general-overview.html#data-loading",
    "href": "src/blog/misc/bible-society-uk-revival/general-overview.html#data-loading",
    "title": "General Overview",
    "section": "Data Loading",
    "text": "Data Loading\n\n\nShow the code\n# Load attendance data\nattendance_data &lt;- read_csv(here::here(\"data/bible-society-uk-revival/processed/church-attendance-extracted.csv\"))"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/general-overview.html#survey-question-overview",
    "href": "src/blog/misc/bible-society-uk-revival/general-overview.html#survey-question-overview",
    "title": "General Overview",
    "section": "Survey Question Overview",
    "text": "Survey Question Overview\nThis section examines how many questions about church attendance were asked in each survey and which questions are comparable.\n\nQuestion Count Summary\n\n\n\nSurvey Year\nNumber of Church Attendance Questions\nQuestion Types\n\n\n\n\n2018\n1\nFrequency only\n\n\n2024\n2\nBinary + Frequency\n\n\nCommon Questions\n1\nFrequency question\n\n\n\n\n\nDetailed Breakdown\n2018 Survey (1 question):\n\nFrequency Question: “Apart from weddings, baptisms/christenings, and funerals how often, if at all, did you go to a church service in the last year?”\n\nResponse scale: 9 categories from “Daily/almost daily” to “Never”\n\n\n2024 Survey (2 questions):\n\nBinary Question (NEW): “Have you attended a church service?”\n\nResponse options: “Yes - in the past year”, “Yes - more than a year ago”, “Never”\nAsked FIRST before the frequency question\n\nFrequency Question (SAME as 2018): Church attendance frequency\n\nResponse scale: Same 9 categories as 2018\nAsked SECOND, after the binary question\n\n\n\n\nComparability Assessment\n\n\n\n\n\nSurvey question structure comparison\n\n\n\n\n\n\nKey Observations\n\nDirect Comparability: Only 1 out of 2 questions from the 2024 survey is directly comparable to 2018 (the frequency question)\nQuestion Order Changed: Even the comparable frequency question appears in a different context:\n\n2018: Asked as the only question\n2024: Asked as the second question, after a binary screener\n\nNew Binary Question: The 2024 binary question provides additional data not available in 2018, but also introduces potential question order effects\nMethodological Implication: The change from 1 question (2018) to 2 questions (2024) means:\n\n2024 respondents are primed by the binary question before answering the frequency question\nThis priming may affect how they respond to the frequency question\nThe 2018 and 2024 frequency questions are not truly equivalent due to different question contexts\n\n\nConclusion: While both surveys include a frequency question with identical response categories, the 2024 survey’s addition of a binary question asked first creates a different response context. This means only partial comparability exists between the two surveys."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/general-overview.html#complete-survey-question-inventory",
    "href": "src/blog/misc/bible-society-uk-revival/general-overview.html#complete-survey-question-inventory",
    "title": "General Overview",
    "section": "Complete Survey Question Inventory",
    "text": "Complete Survey Question Inventory\nThis section provides a comprehensive inventory of ALL questions asked in both the 2018 and 2024 surveys, showing which questions are common and which are unique to each survey.\n\nQuestion Categories\nBased on the survey documentation, both surveys covered multiple topics related to religion and church attendance. Below is a complete comparison:\n\n\n\nComplete inventory of survey questions across both years\n\n\n\n\n\n\n\n\n\n\nCategory\nQuestion Topic\n2018\n2024\nComparable?\nData Available\n\n\n\n\nChurch Attendance\nFrequency of church service attendance (past year)\nYes\nYes\nPartial*\nYes\n\n\nChurch Attendance\nEver attended church service (binary)\nNo\nYes\nNo\nYes (2024 only)\n\n\nChurch Attendance\nWhen last attended (if not in past year)\nNo\nYes\nNo\nYes (2024 only)\n\n\nReligious Identification\nReligious affiliation/denomination\nYes\nYes\nYes\nNo\n\n\nReligious Identification\nChristian denomination (if Christian)\nYes\nYes\nYes\nNo\n\n\nBible/Religious Beliefs\nBible reading frequency\nYes\nYes\nUnknown**\nNo\n\n\nBible/Religious Beliefs\nBible can change society for the better\nYes\nYes\nUnknown**\nNo\n\n\nBible/Religious Beliefs\nOther religious belief questions\nYes\nYes\nUnknown**\nNo\n\n\nDemographics\nAge group\nYes\nYes\nYes\nYes\n\n\nDemographics\nEthnicity\nLimited\nYes\nPartial***\nYes (2024 only)\n\n\nDemographics\nGender\nLimited\nYes\nPartial***\nYes (2024 only)\n\n\n\n\n\nNotes:\n\n* Partial comparability: Question wording identical, but asked in different contexts (2024 has binary question first)\n** Unknown comparability: Questions asked in both surveys, but exact wording not documented in our data extracts\n*** Partial demographic data: 2018 had limited ethnicity/gender breakdowns compared to 2024\n\n\n\nSummary Statistics\n\n\n\nMetric\nCount\n\n\n\n\nTopics covered in 2018\n7\n\n\nTopics covered in 2024\n11\n\n\nCommon topics (asked in both)\n7\n\n\nUnique to 2024\n2\n\n\nDirectly comparable\n3\n\n\nData extracted and available for analysis\n4 topics\n\n\n\n\n\nVisual Summary: Question Coverage\n\n\n\n\n\nVenn diagram style comparison of survey question coverage\n\n\n\n\n\n\nKey Findings from Complete Inventory\n\nBoth surveys covered similar topic areas: Church attendance, religious identification, beliefs about the Bible, and demographics\n2024 expanded church attendance questions: Added binary attendance question and follow-up about when people last attended\nDemographic data improved in 2024: More comprehensive ethnicity and gender breakdowns\nLimited data extraction: Our analysis focuses on church attendance patterns because:\n\nThese are the questions highlighted in Bible Society UK’s “Quiet Revival” claim\nFull cross-tabulations for other questions were not included in the published reports\nDemographic data was only partially available for 2018\n\nComparability challenges: Even for topics covered in both years:\n\nQuestion wording may have changed (not fully documented)\nResponse scales may differ\nQuestion context/ordering changed\nDemographic weighting methodology not disclosed\n\n\n\n\nData Availability for Analysis\nOf all the questions asked across both surveys, we have extracted and analyzable data for:\n\n✅ Church attendance frequency (both years)\n✅ Binary church attendance (2024 only)\n✅ Age breakdowns (both years)\n✅ Ethnicity breakdowns (2024 only, limited in 2018)\n✅ Gender breakdowns (2024 only)\n\nFor other questions (religious identification, Bible reading, beliefs), the published reports provided: - Summary statistics only (no cross-tabulations) - Selected highlights (not comprehensive data) - Insufficient detail for rigorous comparative analysis\nThis limitation means our analysis necessarily focuses on what data is available: church attendance patterns and basic demographic breakdowns."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/general-overview.html#question-format-comparison",
    "href": "src/blog/misc/bible-society-uk-revival/general-overview.html#question-format-comparison",
    "title": "General Overview",
    "section": "Question Format Comparison",
    "text": "Question Format Comparison\n\n2018 Survey Question\nQuestion wording: “Apart from weddings, baptisms/christenings, and funerals how often, if at all, did you go to a church service in the last year?”\nResponse options: - Daily/almost daily - A few times a week - About once a week - About once a fortnight - About once a month - A few times a year - About once a year - Hardly ever - Never\n\n\n2024 Survey Questions\nTwo separate questions were asked:\nQuestion 1 (Binary): “Have you attended a church service?” [exact wording not fully documented]\nResponse options: - Yes - in the past year - Yes - more than a year ago - Never\nQuestion 2 (Frequency): Same frequency scale as 2018\n⚠️ Important methodological note: The binary question was asked BEFORE the frequency question in 2024, which was not the case in 2018. This ordering may influence responses."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/general-overview.html#complete-attendance-distribution-comparison",
    "href": "src/blog/misc/bible-society-uk-revival/general-overview.html#complete-attendance-distribution-comparison",
    "title": "General Overview",
    "section": "Complete Attendance Distribution Comparison",
    "text": "Complete Attendance Distribution Comparison\n\nFrequency Question Responses\nThis is the most directly comparable question between the two surveys.\n\n\nShow the code\n# Extract frequency responses for both years\nfreq_2018 &lt;- attendance_data %&gt;%\n  filter(year == 2018, \n         !response_category %in% c(\"At least once a week\", \"At least once a month\")) %&gt;%\n  select(response_category, total_pct) %&gt;%\n  rename(`2018 (%)` = total_pct)\n\nfreq_2024 &lt;- attendance_data %&gt;%\n  filter(year == 2024, question_type == \"frequency\",\n         !response_category %in% c(\"At least once a week\", \"At least once a month\")) %&gt;%\n  select(response_category, total_pct) %&gt;%\n  rename(`2024 (%)` = total_pct)\n\n# Merge and calculate changes\nfreq_comparison &lt;- full_join(freq_2018, freq_2024, by = \"response_category\") %&gt;%\n  mutate(\n    `Change (pp)` = `2024 (%)` - `2018 (%)`,\n    `Change (%)` = round((`2024 (%)` / `2018 (%)` - 1) * 100, 1)\n  ) %&gt;%\n  arrange(desc(`2018 (%)`))\n\nkable(freq_comparison, digits = 1, \n      caption = \"Church attendance frequency: 2018 vs 2024\")\n\n\n\nChurch attendance frequency: 2018 vs 2024\n\n\nresponse_category\n2018 (%)\n2024 (%)\nChange (pp)\nChange (%)\n\n\n\n\nNever\n63\n59\n-4\n-6.3\n\n\nHardly ever\n13\n12\n-1\n-7.7\n\n\nA few times a year\n7\n6\n-1\n-14.3\n\n\nAbout once a year\n7\n6\n-1\n-14.3\n\n\nAbout once a week\n5\n7\n2\n40.0\n\n\nA few times a week\n2\n3\n1\n50.0\n\n\nAbout once a fortnight\n1\n1\n0\n0.0\n\n\nAbout once a month\n1\n2\n1\n100.0\n\n\nDaily/almost daily\n0\n1\n1\nInf\n\n\n\n\n\n\n\nVisual Comparison: Complete Distribution\n\n\nShow the code\n# Prepare data for plotting\nplot_data &lt;- attendance_data %&gt;%\n  filter(\n    (year == 2018) | (year == 2024 & question_type == \"frequency\")\n  ) %&gt;%\n  filter(!response_category %in% c(\"At least once a week\", \"At least once a month\")) %&gt;%\n  mutate(\n    Year = factor(year),\n    response_category = factor(response_category, levels = c(\n      \"Daily/almost daily\", \"A few times a week\", \"About once a week\",\n      \"About once a fortnight\", \"About once a month\", \"A few times a year\",\n      \"About once a year\", \"Hardly ever\", \"Never\"\n    ))\n  )\n\nggplot(plot_data, aes(x = response_category, y = total_pct, fill = Year)) +\n  geom_col(position = \"dodge\", alpha = 0.8, width = 0.7) +\n  geom_text(aes(label = sprintf(\"%.1f%%\", total_pct)), \n            position = position_dodge(width = 0.7), \n            vjust = -0.3, size = 3.5, fontface = \"bold\") +\n  scale_fill_manual(values = c(\"2018\" = \"#4575b4\", \"2024\" = \"#d73027\"),\n                    labels = c(\"2018\" = \"2018 (n=19,875)\", \"2024\" = \"2024 (n=12,455)\")) +\n  labs(\n    title = \"Church Attendance Frequency Distribution: 2018 vs 2024\",\n    subtitle = \"Direct comparison of identical question format\",\n    x = \"Attendance Frequency\",\n    y = \"Percentage of Respondents (%)\",\n    fill = \"Survey Year\"\n  ) +\n  theme_comparison() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"top\"\n  ) +\n  scale_y_continuous(limits = c(0, 70), breaks = seq(0, 70, 10))\n\n\n\n\n\nComplete church attendance distribution comparison\n\n\n\n\n\n\nChange Magnitude Visualisation\n\n\nShow the code\n# Prepare data for diverging bar chart\nchange_plot_data &lt;- freq_comparison %&gt;%\n  mutate(\n    response_category = factor(response_category, \n                               levels = rev(response_category)),\n    Direction = case_when(\n      `Change (pp)` &gt; 0 ~ \"Increase\",\n      `Change (pp)` &lt; 0 ~ \"Decrease\",\n      TRUE ~ \"No Change\"\n    )\n  )\n\nggplot(change_plot_data, aes(x = response_category, y = `Change (pp)`, fill = Direction)) +\n  geom_col(alpha = 0.85, width = 0.7) +\n  geom_text(aes(label = sprintf(\"%+.1f\", `Change (pp)`)), \n            hjust = ifelse(change_plot_data$`Change (pp)` &gt; 0, -0.2, 1.2),\n            size = 4, fontface = \"bold\") +\n  geom_hline(yintercept = 0, color = \"black\", linewidth = 0.8) +\n  scale_fill_manual(values = c(\"Increase\" = \"#2166ac\", \"Decrease\" = \"#d73027\")) +\n  coord_flip() +\n  labs(\n    title = \"Change in Attendance by Category: 2018 → 2024\",\n    subtitle = \"Percentage point change for each response category\",\n    x = NULL,\n    y = \"Change (percentage points)\",\n    fill = \"Direction\"\n  ) +\n  theme_comparison() +\n  theme(\n    panel.grid.major.y = element_blank()\n  )\n\n\n\n\n\nMagnitude and direction of changes in attendance categories"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/general-overview.html#summary-statistics-grouped-categories",
    "href": "src/blog/misc/bible-society-uk-revival/general-overview.html#summary-statistics-grouped-categories",
    "title": "General Overview",
    "section": "Summary Statistics: Grouped Categories",
    "text": "Summary Statistics: Grouped Categories\n\nWeekly and Monthly Attendance\n\n\nShow the code\n# Calculate grouped statistics\ngrouped_stats &lt;- tibble(\n  Category = c(\"At least once a week\", \"At least once a month\", \"Never\"),\n  `2018 (%)` = c(\n    attendance_data %&gt;% filter(year == 2018, response_category == \"At least once a week\") %&gt;% pull(total_pct),\n    attendance_data %&gt;% filter(year == 2018, response_category == \"At least once a month\") %&gt;% pull(total_pct),\n    attendance_data %&gt;% filter(year == 2018, response_category == \"Never\") %&gt;% pull(total_pct)\n  ),\n  `2024 (%)` = c(\n    # Weekly: sum of daily + few times a week + once a week\n    attendance_data %&gt;% \n      filter(year == 2024, question_type == \"frequency\",\n             response_category %in% c(\"Daily/almost daily\", \"A few times a week\", \"About once a week\")) %&gt;%\n      pull(total_pct) %&gt;% sum(),\n    # Monthly: weekly + fortnight + month\n    attendance_data %&gt;% \n      filter(year == 2024, question_type == \"frequency\",\n             response_category %in% c(\"Daily/almost daily\", \"A few times a week\", \"About once a week\",\n                                     \"About once a fortnight\", \"About once a month\")) %&gt;%\n      pull(total_pct) %&gt;% sum(),\n    # Never\n    attendance_data %&gt;% filter(year == 2024, question_type == \"frequency\", response_category == \"Never\") %&gt;% pull(total_pct)\n  )\n) %&gt;%\n  mutate(\n    `Change (pp)` = `2024 (%)` - `2018 (%)`,\n    `Relative Change (%)` = round((`2024 (%)` / `2018 (%)` - 1) * 100, 1)\n  )\n\nkable(grouped_stats, digits = 1, \n      caption = \"Grouped attendance categories comparison\")\n\n\n\nGrouped attendance categories comparison\n\n\n\n\n\n\n\n\n\nCategory\n2018 (%)\n2024 (%)\nChange (pp)\nRelative Change (%)\n\n\n\n\nAt least once a week\n7\n11\n4\n57.1\n\n\nAt least once a month\n9\n14\n5\n55.6\n\n\nNever\n63\n59\n-4\n-6.3\n\n\n\n\n\n\n\nShow the code\n# Reshape for plotting\ngrouped_plot_data &lt;- grouped_stats %&gt;%\n  select(Category, `2018 (%)`, `2024 (%)`) %&gt;%\n  pivot_longer(cols = c(`2018 (%)`, `2024 (%)`), \n               names_to = \"Year\", values_to = \"Percentage\") %&gt;%\n  mutate(\n    Year = str_extract(Year, \"\\\\d{4}\"),\n    Category = factor(Category, levels = c(\"At least once a week\", \"At least once a month\", \"Never\"))\n  )\n\nggplot(grouped_plot_data, aes(x = Category, y = Percentage, fill = Year)) +\n  geom_col(position = \"dodge\", alpha = 0.85, width = 0.7) +\n  geom_text(aes(label = sprintf(\"%.1f%%\", Percentage)), \n            position = position_dodge(width = 0.7), \n            vjust = -0.3, size = 4, fontface = \"bold\") +\n  scale_fill_manual(values = c(\"2018\" = \"#4575b4\", \"2024\" = \"#d73027\")) +\n  labs(\n    title = \"Grouped Attendance Categories: 2018 vs 2024\",\n    subtitle = \"Weekly and monthly attendance show increases; 'Never' shows decrease\",\n    x = NULL,\n    y = \"Percentage (%)\",\n    fill = \"Survey Year\"\n  ) +\n  theme_comparison() +\n  theme(\n    axis.text.x = element_text(angle = 20, hjust = 1)\n  ) +\n  scale_y_continuous(limits = c(0, 70), breaks = seq(0, 70, 10))\n\n\n\n\n\nComparison of grouped attendance categories"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/general-overview.html#demographic-breakdowns",
    "href": "src/blog/misc/bible-society-uk-revival/general-overview.html#demographic-breakdowns",
    "title": "General Overview",
    "section": "Demographic Breakdowns",
    "text": "Demographic Breakdowns\n\nBy Age Group\n\n\nShow the code\n# Get weekly attendance by age for 2018\nage_2018 &lt;- attendance_data %&gt;%\n  filter(year == 2018, response_category == \"At least once a week\") %&gt;%\n  select(age_18_34, age_35_54, age_55plus)\n\n# Get weekly attendance by age for 2024\nage_2024 &lt;- attendance_data %&gt;%\n  filter(\n    year == 2024,\n    question_type == \"frequency\",\n    response_category %in% c(\"Daily/almost daily\", \"A few times a week\", \"About once a week\")\n  ) %&gt;%\n  summarise(\n    age_18_34 = sum(age_18_34, na.rm = TRUE),\n    age_35_54 = sum(age_35_54, na.rm = TRUE),\n    age_55plus = sum(age_55plus, na.rm = TRUE)\n  )\n\n# Create comparison table\nage_comparison &lt;- tibble(\n  `Age Group` = c(\"18-34\", \"35-54\", \"55+\"),\n  `2018 (%)` = c(age_2018$age_18_34, age_2018$age_35_54, age_2018$age_55plus),\n  `2024 (%)` = c(age_2024$age_18_34, age_2024$age_35_54, age_2024$age_55plus)\n) %&gt;%\n  mutate(\n    `Change (pp)` = `2024 (%)` - `2018 (%)`,\n    `Relative Change (%)` = round((`2024 (%)` / `2018 (%)` - 1) * 100, 1)\n  )\n\nkable(age_comparison, digits = 1, \n      caption = \"Weekly+ church attendance by age group\")\n\n\n\nWeekly+ church attendance by age group\n\n\nAge Group\n2018 (%)\n2024 (%)\nChange (pp)\nRelative Change (%)\n\n\n\n\n18-34\n4\n16\n12\n300\n\n\n35-54\n5\n7\n2\n40\n\n\n55+\n10\n12\n2\n20\n\n\n\n\n\n\n\nShow the code\n# Reshape for plotting\nage_plot_data &lt;- age_comparison %&gt;%\n  select(`Age Group`, `2018 (%)`, `2024 (%)`) %&gt;%\n  pivot_longer(cols = c(`2018 (%)`, `2024 (%)`), \n               names_to = \"Year\", values_to = \"Percentage\") %&gt;%\n  mutate(Year = str_extract(Year, \"\\\\d{4}\"))\n\nggplot(age_plot_data, aes(x = `Age Group`, y = Percentage, fill = Year)) +\n  geom_col(position = \"dodge\", alpha = 0.85, width = 0.6) +\n  geom_text(aes(label = sprintf(\"%.1f%%\", Percentage)), \n            position = position_dodge(width = 0.6), \n            vjust = -0.3, size = 4, fontface = \"bold\") +\n  scale_fill_manual(values = c(\"2018\" = \"#4575b4\", \"2024\" = \"#d73027\")) +\n  labs(\n    title = \"Weekly+ Church Attendance by Age Group\",\n    subtitle = \"Comparison between 2018 and 2024\",\n    x = \"Age Group\",\n    y = \"Percentage Attending Weekly or More (%)\",\n    fill = \"Survey Year\"\n  ) +\n  theme_comparison() +\n  scale_y_continuous(limits = c(0, 20), breaks = seq(0, 20, 5))\n\n\n\n\n\nWeekly+ attendance by age group: 2018 vs 2024\n\n\n\n\n\n\nChange by Age Group\n\n\nShow the code\nggplot(age_comparison, aes(x = `Age Group`, y = `Change (pp)`)) +\n  geom_col(fill = \"#2166ac\", alpha = 0.85, width = 0.6) +\n  geom_text(aes(label = sprintf(\"%+.1f pp\", `Change (pp)`)), \n            vjust = -0.5, size = 5, fontface = \"bold\") +\n  geom_hline(yintercept = 0, linewidth = 0.8) +\n  labs(\n    title = \"Change in Weekly+ Attendance by Age Group (2018 → 2024)\",\n    subtitle = \"All age groups show increases, with 18-34 showing the largest change\",\n    x = \"Age Group\",\n    y = \"Change (percentage points)\"\n  ) +\n  theme_comparison() +\n  scale_y_continuous(limits = c(0, 9), breaks = seq(0, 9, 1), \n                     expand = expansion(mult = c(0, 0.05)))\n\n\n\n\n\nAbsolute change in weekly+ attendance by age group\n\n\n\n\n\n\nBy Ethnicity (2024 Only)\nThe 2024 survey includes ethnicity breakdowns that were not available in 2018.\n\n\nShow the code\n# Get 2024 binary attendance by ethnicity\nethnicity_data &lt;- attendance_data %&gt;%\n  filter(year == 2024, question_type == \"binary\", \n         response_category == \"Yes - in the past year\") %&gt;%\n  select(white, ethnic_minority)\n\nethnicity_table &lt;- tibble(\n  `Ethnic Group` = c(\"White\", \"Ethnic Minority\"),\n  `Attended in Past Year (%)` = c(ethnicity_data$white, ethnicity_data$ethnic_minority),\n  `Difference from White (pp)` = c(0, ethnicity_data$ethnic_minority - ethnicity_data$white)\n)\n\nkable(ethnicity_table, digits = 1, \n      caption = \"Church attendance by ethnicity (2024 survey only)\")\n\n\n\nChurch attendance by ethnicity (2024 survey only)\n\n\n\n\n\n\n\nEthnic Group\nAttended in Past Year (%)\nDifference from White (pp)\n\n\n\n\nWhite\n23\n0\n\n\nEthnic Minority\n24\n1\n\n\n\n\n\n\n\nShow the code\nggplot(ethnicity_table, aes(x = `Ethnic Group`, y = `Attended in Past Year (%)`)) +\n  geom_col(fill = c(\"#4575b4\", \"#d73027\"), alpha = 0.85, width = 0.6) +\n  geom_text(aes(label = sprintf(\"%.1f%%\", `Attended in Past Year (%)`)), \n            vjust = -0.3, size = 5, fontface = \"bold\") +\n  labs(\n    title = \"Church Attendance by Ethnicity (2024)\",\n    subtitle = \"Percentage attending in the past year\",\n    x = \"Ethnic Group\",\n    y = \"Attended in Past Year (%)\"\n  ) +\n  theme_comparison() +\n  scale_y_continuous(limits = c(0, 30), breaks = seq(0, 30, 5))\n\n\n\n\n\nChurch attendance by ethnicity (2024)\n\n\n\n\n\n\nBy Gender (2024 Only)\n\n\nShow the code\n# Get 2024 binary attendance by gender\ngender_data &lt;- attendance_data %&gt;%\n  filter(year == 2024, question_type == \"binary\", \n         response_category == \"Yes - in the past year\") %&gt;%\n  select(male, female)\n\ngender_table &lt;- tibble(\n  Gender = c(\"Male\", \"Female\"),\n  `Attended in Past Year (%)` = c(gender_data$male, gender_data$female),\n  `Difference from Male (pp)` = c(0, gender_data$female - gender_data$male)\n)\n\nkable(gender_table, digits = 1, \n      caption = \"Church attendance by gender (2024 survey only)\")\n\n\n\nChurch attendance by gender (2024 survey only)\n\n\nGender\nAttended in Past Year (%)\nDifference from Male (pp)\n\n\n\n\nMale\n23\n0\n\n\nFemale\n24\n1\n\n\n\n\n\n\n\nShow the code\nggplot(gender_table, aes(x = Gender, y = `Attended in Past Year (%)`)) +\n  geom_col(fill = c(\"#4575b4\", \"#d73027\"), alpha = 0.85, width = 0.5) +\n  geom_text(aes(label = sprintf(\"%.1f%%\", `Attended in Past Year (%)`)), \n            vjust = -0.3, size = 5, fontface = \"bold\") +\n  labs(\n    title = \"Church Attendance by Gender (2024)\",\n    subtitle = \"Percentage attending in the past year\",\n    x = \"Gender\",\n    y = \"Attended in Past Year (%)\"\n  ) +\n  theme_comparison() +\n  scale_y_continuous(limits = c(0, 30), breaks = seq(0, 30, 5))\n\n\n\n\n\nChurch attendance by gender (2024)"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/general-overview.html#binary-question-results",
    "href": "src/blog/misc/bible-society-uk-revival/general-overview.html#binary-question-results",
    "title": "General Overview",
    "section": "2024 Binary Question Results",
    "text": "2024 Binary Question Results\nThe 2024 survey included an additional binary question asked before the frequency question.\n\n\nShow the code\nbinary_data &lt;- attendance_data %&gt;%\n  filter(year == 2024, question_type == \"binary\") %&gt;%\n  select(response_category, total_pct) %&gt;%\n  rename(`Percentage (%)` = total_pct)\n\nkable(binary_data, digits = 1, \n      caption = \"2024 binary question responses\")\n\n\n\n2024 binary question responses\n\n\nresponse_category\nPercentage (%)\n\n\n\n\nYes - in the past year\n24\n\n\nYes - more than a year ago\n45\n\n\nNever\n28\n\n\nNet: Yes (ever)\n68\n\n\n\n\n\n\n\nShow the code\nggplot(binary_data, aes(x = reorder(response_category, -`Percentage (%)`), \n                        y = `Percentage (%)`)) +\n  geom_col(fill = c(\"#d73027\", \"#fdae61\", \"#4575b4\", \"#91bfdb\"), \n           alpha = 0.85, width = 0.6) +\n  geom_text(aes(label = sprintf(\"%.1f%%\", `Percentage (%)`)), \n            vjust = -0.3, size = 5, fontface = \"bold\") +\n  labs(\n    title = \"Binary Question Responses (2024)\",\n    subtitle = \"Have you attended a church service?\",\n    x = \"Response\",\n    y = \"Percentage (%)\"\n  ) +\n  theme_comparison() +\n  theme(axis.text.x = element_text(angle = 20, hjust = 1)) +\n  scale_y_continuous(limits = c(0, 50), breaks = seq(0, 50, 10))\n\n\n\n\n\n2024 binary question responses"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/general-overview.html#internal-consistency-check-2024",
    "href": "src/blog/misc/bible-society-uk-revival/general-overview.html#internal-consistency-check-2024",
    "title": "General Overview",
    "section": "Internal Consistency Check (2024)",
    "text": "Internal Consistency Check (2024)\nWe can check whether the binary and frequency questions in 2024 give consistent results.\n\n\nShow the code\n# Calculate sum of frequency responses for past year attendance in 2024\nfreq_sum_2024 &lt;- attendance_data %&gt;%\n  filter(year == 2024, question_type == \"frequency\") %&gt;%\n  filter(response_category %in% c(\n    \"Daily/almost daily\", \"A few times a week\", \n    \"About once a week\", \"About once a fortnight\",\n    \"About once a month\", \"A few times a year\",\n    \"About once a year\"\n  )) %&gt;%\n  pull(total_pct) %&gt;%\n  sum()\n\n# Get binary response\nbinary_2024 &lt;- attendance_data %&gt;%\n  filter(year == 2024, question_type == \"binary\", \n         response_category == \"Yes - in the past year\") %&gt;%\n  pull(total_pct)\n\nconsistency &lt;- tibble(\n  Measure = c(\"Binary: 'Yes - in the past year'\", \n              \"Frequency: Sum of all 'past year' categories\",\n              \"Discrepancy\"),\n  Value = c(binary_2024, freq_sum_2024, abs(freq_sum_2024 - binary_2024))\n)\n\nkable(consistency, digits = 1, col.names = c(\"Measure\", \"Percentage (%)\"),\n      caption = \"Internal consistency check: 2024 survey\")\n\n\n\nInternal consistency check: 2024 survey\n\n\nMeasure\nPercentage (%)\n\n\n\n\nBinary: ‘Yes - in the past year’\n24\n\n\nFrequency: Sum of all ‘past year’ categories\n26\n\n\nDiscrepancy\n2\n\n\n\n\n\n\n\nShow the code\nconsistency_plot &lt;- tibble(\n  Measure = c(\"Binary Question\\n('Yes - in past year')\", \n              \"Frequency Question\\n(Sum of past year categories)\"),\n  Value = c(binary_2024, freq_sum_2024)\n)\n\nggplot(consistency_plot, aes(x = Measure, y = Value)) +\n  geom_col(fill = c(\"#d73027\", \"#4575b4\"), alpha = 0.85, width = 0.6) +\n  geom_text(aes(label = sprintf(\"%.1f%%\", Value)), \n            vjust = -0.3, size = 6, fontface = \"bold\") +\n  geom_segment(aes(x = 1, xend = 2, y = binary_2024, yend = freq_sum_2024),\n               linetype = \"dashed\", linewidth = 1, color = \"grey40\") +\n  annotate(\"text\", x = 1.5, y = (binary_2024 + freq_sum_2024)/2, \n           label = sprintf(\"Difference:\\n%.1f pp\", abs(freq_sum_2024 - binary_2024)),\n           size = 4, fontface = \"italic\") +\n  labs(\n    title = \"Internal Consistency Check: 2024 Survey\",\n    subtitle = \"Do the binary and frequency questions give the same answer?\",\n    x = NULL,\n    y = \"Percentage (%)\"\n  ) +\n  theme_comparison() +\n  scale_y_continuous(limits = c(0, 30), breaks = seq(0, 30, 5))\n\n\n\n\n\nInternal consistency comparison\n\n\n\n\nObservation: The two measures differ by 2.0 percentage points. These should theoretically be identical if measuring the same construct."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/general-overview.html#summary-dashboard",
    "href": "src/blog/misc/bible-society-uk-revival/general-overview.html#summary-dashboard",
    "title": "General Overview",
    "section": "Summary Dashboard",
    "text": "Summary Dashboard\n\n\n\n\n\nSummary dashboard of key findings"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/general-overview.html#key-observations-1",
    "href": "src/blog/misc/bible-society-uk-revival/general-overview.html#key-observations-1",
    "title": "General Overview",
    "section": "Key Observations",
    "text": "Key Observations\n\nMain Findings\n\nWeekly+ attendance increased from 7% (2018) to 11% (2024) - a change of +4 percentage points\n“Never attended” decreased from 63% (2018) to 59% (2024) - a change of -4 percentage points\nAll changes are relatively small - no category changed by more than 4 percentage points\nAge patterns: The youngest age group (18-34) showed the largest increase in weekly attendance (+7.0pp), compared to middle (+1.0pp) and older (+2.0pp) age groups\nInternal consistency: The 2024 binary and frequency questions show a discrepancy of 2.0 percentage points\nSample size: The 2024 survey has 31% fewer respondents than 2018\nDemographic differences: Ethnic minority respondents show different attendance patterns than White respondents in 2024"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/general-overview.html#methodological-notes",
    "href": "src/blog/misc/bible-society-uk-revival/general-overview.html#methodological-notes",
    "title": "General Overview",
    "section": "Methodological Notes",
    "text": "Methodological Notes\nQuestion format differences: - 2018: Single frequency question only - 2024: Binary question FIRST, then frequency question - This difference in question order may affect comparability\nSample size changes: - 2018: 19,875 (weighted) - 2024: 12,455 (weighted) - Represents a 31% reduction\nDemographic data availability: - Ethnicity and gender breakdowns only available for 2024 - This limits ability to assess population composition changes"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/general-overview.html#next-steps",
    "href": "src/blog/misc/bible-society-uk-revival/general-overview.html#next-steps",
    "title": "General Overview",
    "section": "Next Steps",
    "text": "Next Steps\nFor critical analysis of these findings, see:\n\nCritical Analysis Overview - Evaluation of methodological quality and alternative explanations\nWeekly Attendance Claim - Statistical testing of the observed changes\nQuestion Order Effects - Impact of methodological differences\nDemographic Analysis - Population composition effects"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html",
    "href": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html",
    "title": "Weekly Attendance Claim Analysis",
    "section": "",
    "text": "Bible Society UK claims that weekly church attendance increased from 7% (2018) to 11% (2024), representing a 4 percentage point increase."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#the-claim",
    "href": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#the-claim",
    "title": "Weekly Attendance Claim Analysis",
    "section": "",
    "text": "Bible Society UK claims that weekly church attendance increased from 7% (2018) to 11% (2024), representing a 4 percentage point increase."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#data-preparation",
    "href": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#data-preparation",
    "title": "Weekly Attendance Claim Analysis",
    "section": "Data Preparation",
    "text": "Data Preparation\n\n\nShow the code\n# Load data\nattendance_data &lt;- read_csv(here::here(\"data/bible-society-uk-revival/processed/church-attendance-extracted.csv\"))\nsurvey_meta &lt;- read_csv(here::here(\"data/bible-society-uk-revival/processed/survey-metadata.csv\"), comment = \"#\")\n\n# Extract weekly attendance data\nweekly_2018 &lt;- attendance_data %&gt;%\n  filter(year == 2018, response_category == \"At least once a week\") %&gt;%\n  pull(total_pct) / 100  # Convert to proportion\n\nweekly_2024 &lt;- attendance_data %&gt;%\n  filter(\n    year == 2024,\n    question_type == \"frequency\",\n    response_category %in% c(\"Daily/almost daily\", \"A few times a week\", \"About once a week\")\n  ) %&gt;%\n  summarise(total_pct = sum(total_pct)) %&gt;%\n  pull(total_pct) / 100\n\n# Sample sizes\nn_2018 &lt;- survey_meta$sample_size_weighted[1]\nn_2024 &lt;- survey_meta$sample_size_weighted[2]"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#point-estimates",
    "href": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#point-estimates",
    "title": "Weekly Attendance Claim Analysis",
    "section": "Point Estimates",
    "text": "Point Estimates\n\n2018: 7.0% (n = 19,875)\n2024: 11.0% (n = 12,455)\nChange: +4.0 percentage points"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#confidence-intervals-with-design-effect",
    "href": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#confidence-intervals-with-design-effect",
    "title": "Weekly Attendance Claim Analysis",
    "section": "Confidence Intervals (with Design Effect)",
    "text": "Confidence Intervals (with Design Effect)\nYouGov panel surveys require design effect adjustment. We use a conservative estimate of deff = 1.5.\n\n\nShow the code\n# Function to calculate CI for proportions with design effect\ncalc_ci &lt;- function(p, n, deff = 1.5, conf_level = 0.95) {\n  n_eff &lt;- n / deff\n  z &lt;- qnorm((1 + conf_level) / 2)\n  se &lt;- sqrt(p * (1 - p) / n_eff)\n  ci_lower &lt;- p - z * se\n  ci_upper &lt;- p + z * se\n  \n  return(list(\n    estimate = p,\n    se = se,\n    ci_lower = ci_lower,\n    ci_upper = ci_upper,\n    n_eff = n_eff\n  ))\n}\n\nci_2018 &lt;- calc_ci(weekly_2018, n_2018)\nci_2024 &lt;- calc_ci(weekly_2024, n_2024)\n\n\n\n95% Confidence Intervals (with design effect = 1.5)\nThe confidence intervals account for design effects in panel surveys:\n\n2018: 7.0% [6.6%, 7.4%]\n2024: 11.0% [10.3%, 11.7%]"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#hypothesis-test",
    "href": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#hypothesis-test",
    "title": "Weekly Attendance Claim Analysis",
    "section": "Hypothesis Test",
    "text": "Hypothesis Test\nNull Hypothesis: No change in weekly attendance (p_2024 = p_2018)\nAlternative Hypothesis: Change in weekly attendance (p_2024 ≠ p_2018)\n\n\nShow the code\n# Two-sample proportion test with design effect adjustment\nprop_test &lt;- function(p1, n1, p2, n2, deff = 1.5) {\n  n1_eff &lt;- n1 / deff\n  n2_eff &lt;- n2 / deff\n  \n  # Pooled proportion\n  p_pool &lt;- (p1 * n1_eff + p2 * n2_eff) / (n1_eff + n2_eff)\n  \n  # Standard error\n  se_pool &lt;- sqrt(p_pool * (1 - p_pool) * (1/n1_eff + 1/n2_eff))\n  \n  # Test statistic\n  z &lt;- (p2 - p1) / se_pool\n  \n  # P-value (two-tailed)\n  p_value &lt;- 2 * (1 - pnorm(abs(z)))\n  \n  # Difference and its CI\n  diff &lt;- p2 - p1\n  se_diff &lt;- sqrt(p1 * (1 - p1) / n1_eff + p2 * (1 - p2) / n2_eff)\n  ci_lower &lt;- diff - qnorm(0.975) * se_diff\n  ci_upper &lt;- diff + qnorm(0.975) * se_diff\n  \n  return(list(\n    z_statistic = z,\n    p_value = p_value,\n    difference = diff,\n    ci_lower = ci_lower,\n    ci_upper = ci_upper,\n    significant = p_value &lt; 0.05\n  ))\n}\n\ntest_result &lt;- prop_test(weekly_2018, n_2018, weekly_2024, n_2024)\n\n\n\nHypothesis Test Results\nThe hypothesis test examines whether the observed change is statistically significant:\n\nDifference: +4.00 percentage points\n95% CI for difference: [+3.20, +4.80] percentage points\nZ-statistic: 10.225\nP-value: &lt; 0.0001 (0.00e+00)\n\nResult: Statistically significant (p &lt; 0.05)\nInterpretation: The p-value is extremely small (p &lt; 0.001), indicating very strong evidence against the null hypothesis. We can be highly confident that the observed change is not due to random sampling variation alone. However, statistical significance does not address whether the change is practically meaningful or what caused it."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#bayesian-analysis",
    "href": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#bayesian-analysis",
    "title": "Weekly Attendance Claim Analysis",
    "section": "Bayesian Analysis",
    "text": "Bayesian Analysis\nIn addition to the frequentist hypothesis test above, we can use Bayesian analysis to estimate the probability distributions of the attendance rates and calculate credible intervals.\n\n\nShow the code\n# Bayesian approach using Beta-Binomial conjugate prior\n# We'll use a weakly informative prior: Beta(1, 1) = uniform prior\n\n# Convert proportions to counts (using effective sample sizes)\nn_eff_2018 &lt;- n_2018 / 1.5  # Adjust for design effect\nn_eff_2024 &lt;- n_2024 / 1.5\n\nx_2018 &lt;- round(weekly_2018 * n_eff_2018)  # Number of weekly attendees\nx_2024 &lt;- round(weekly_2024 * n_eff_2024)\n\n# Prior parameters (uniform prior: Beta(1,1))\nalpha_prior &lt;- 1\nbeta_prior &lt;- 1\n\n# Posterior parameters (Beta distribution)\nalpha_post_2018 &lt;- alpha_prior + x_2018\nbeta_post_2018 &lt;- beta_prior + (n_eff_2018 - x_2018)\n\nalpha_post_2024 &lt;- alpha_prior + x_2024\nbeta_post_2024 &lt;- beta_prior + (n_eff_2024 - x_2024)\n\n# Calculate credible intervals (Bayesian equivalent of confidence intervals)\ncredible_level &lt;- 0.95\nlower_quantile &lt;- (1 - credible_level) / 2\nupper_quantile &lt;- 1 - lower_quantile\n\ncred_2018_lower &lt;- qbeta(lower_quantile, alpha_post_2018, beta_post_2018)\ncred_2018_upper &lt;- qbeta(upper_quantile, alpha_post_2018, beta_post_2018)\n\ncred_2024_lower &lt;- qbeta(lower_quantile, alpha_post_2024, beta_post_2024)\ncred_2024_upper &lt;- qbeta(upper_quantile, alpha_post_2024, beta_post_2024)\n\n# Posterior means\npost_mean_2018 &lt;- alpha_post_2018 / (alpha_post_2018 + beta_post_2018)\npost_mean_2024 &lt;- alpha_post_2024 / (alpha_post_2024 + beta_post_2024)\n\n# Monte Carlo sampling for difference distribution\nset.seed(42)\nn_samples &lt;- 100000\nsamples_2018 &lt;- rbeta(n_samples, alpha_post_2018, beta_post_2018)\nsamples_2024 &lt;- rbeta(n_samples, alpha_post_2024, beta_post_2024)\ndifference_samples &lt;- samples_2024 - samples_2018\n\n# Credible interval for difference\ndiff_cred_lower &lt;- quantile(difference_samples, lower_quantile)\ndiff_cred_upper &lt;- quantile(difference_samples, upper_quantile)\ndiff_post_mean &lt;- mean(difference_samples)\n\n# Probability that 2024 &gt; 2018\nprob_increase &lt;- mean(difference_samples &gt; 0)\n\n\n\nBayesian Credible Intervals\nUsing a Bayesian approach with a uniform prior (Beta(1,1)), we obtain posterior distributions and 95% credible intervals:\n2018 Weekly Attendance: - Posterior mean: 7.0% - 95% credible interval: [6.6%, 7.5%]\n2024 Weekly Attendance: - Posterior mean: 11.0% - 95% credible interval: [10.3%, 11.7%]\nDifference (2024 - 2018): - Posterior mean: +4.00 percentage points - 95% credible interval: [+3.20, +4.80] percentage points - Probability of increase: 100.00%\nInterpretation: There is a 100.0% probability that weekly attendance actually increased between 2018 and 2024, given the data. The credible interval tells us that we can be 95% confident the true increase lies between 3.20 and 4.80 percentage points.\n\n\n\n\n\nBayesian posterior distributions with 95% credible intervals\n\n\n\n\n\n\nBayesian vs Frequentist: Key Differences\nFrequentist Confidence Interval: - Interpretation: “If we repeated this survey many times, 95% of the confidence intervals would contain the true parameter” - The parameter is fixed but unknown; the interval varies across hypothetical repeated samples\nBayesian Credible Interval: - Interpretation: “Given the observed data, there is a 95% probability that the true parameter lies in this interval” - The parameter has a probability distribution (posterior); we directly quantify uncertainty about the parameter\nIn this analysis: Both methods yield very similar intervals (frequentist CI ≈ Bayesian CrI), which strengthens our confidence in the estimates. The Bayesian approach additionally provides the direct probability that attendance increased (100.0%), which many find more intuitive."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#immigration-confounding-simulation",
    "href": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#immigration-confounding-simulation",
    "title": "Weekly Attendance Claim Analysis",
    "section": "Immigration Confounding Simulation",
    "text": "Immigration Confounding Simulation\nTo understand how much of the observed 4pp increase could be explained by Ukrainian and Hong Kong immigration alone, we can simulate what the 2024 attendance rate would be if these demographic changes were the only factor.\n\n\nShow the code\n# UK population and survey parameters\nuk_pop_2024 &lt;- 67000000  # UK population ~67 million\nsurvey_sample_2024 &lt;- 13146  # Actual 2024 survey sample size\n\n# Immigration data (2018-2024)\nukrainian_arrivals &lt;- 217000  # Ukrainians in UK by mid-2024\nhk_bno_arrivals &lt;- 158000    # Hong Kong BN(O) arrivals 2021-2024\n\n# Baseline 2018 attendance (before Ukrainian/HK immigration)\nbaseline_attendance_2018 &lt;- 0.07  # 7%\n\n# Estimated church attendance rates for immigrant groups\n# Conservative assumptions based on home country religiosity\nukrainian_attendance_rate &lt;- 0.15  # 15% weekly+ (85% Christian, ~18% active attendance)\nhk_attendance_rate &lt;- 0.10        # 10% weekly+ (12-15% Christian, higher than UK baseline)\n\n# Calculate expected representation in 2024 survey\n# Assuming proportional sampling\nprob_ukrainian_in_survey &lt;- ukrainian_arrivals / uk_pop_2024\nprob_hk_in_survey &lt;- hk_bno_arrivals / uk_pop_2024\nprob_baseline_in_survey &lt;- 1 - prob_ukrainian_in_survey - prob_hk_in_survey\n\n# Expected number in sample\nexpected_ukrainians &lt;- survey_sample_2024 * prob_ukrainian_in_survey\nexpected_hk &lt;- survey_sample_2024 * prob_hk_in_survey\nexpected_baseline &lt;- survey_sample_2024 * prob_baseline_in_survey\n\n# Simulate attendance if ONLY immigration drives the change\nsimulated_attendance_immigration_only &lt;- (\n  (expected_baseline * baseline_attendance_2018) +\n  (expected_ukrainians * ukrainian_attendance_rate) +\n  (expected_hk * hk_attendance_rate)\n) / survey_sample_2024\n\n# Observed 2024 attendance\nobserved_attendance_2024 &lt;- 0.11  # 11%\n\n# Calculate immigration contribution\nimmigration_contribution_pp &lt;- (simulated_attendance_immigration_only - baseline_attendance_2018) * 100\nobserved_increase_pp &lt;- (observed_attendance_2024 - baseline_attendance_2018) * 100\nimmigration_proportion &lt;- immigration_contribution_pp / observed_increase_pp * 100\n\n# Unexplained remainder\nunexplained_pp &lt;- observed_increase_pp - immigration_contribution_pp\n\n\n\nSimulation Results\nBaseline (2018): 7.0% weekly+ attendance\nObserved (2024): 11.0% weekly+ attendance\nObserved increase: +4.00 percentage points\nExpected composition of 2024 survey sample: - Baseline UK population: 99.4% (n ≈ 13072) - Ukrainian immigrants: 0.32% (n ≈ 43) - Hong Kong BN(O) immigrants: 0.24% (n ≈ 31)\nPredicted attendance from immigration alone: 7.03%\nImmigration contribution: +0.03 percentage points (1% of observed increase)\nUnexplained remainder: +3.97 percentage points (99% of observed increase)\n\n\n\n\n\nDecomposition of 2024 attendance: observed vs predicted from immigration\n\n\n\n\n\n\nInterpretation of Simulation\nKey findings:\n\nImmigration effect is substantial but incomplete: Ukrainian and Hong Kong immigration together account for approximately 1% (0.03 out of 4.0 percentage points) of the observed increase, using conservative attendance rate assumptions.\nUnexplained remainder: 3.97 percentage points (99%) remains unexplained by these two specific immigration streams alone.\nOther immigration: The simulation only accounts for Ukrainian and Hong Kong BN(O) immigration. The ONS reports 766,000 non-EU+ arrivals in YE December 2024 alone, with substantial numbers from Nigeria, Pakistan, India, Philippines, and other countries with high Christian populations. Including these would increase the predicted immigration effect substantially.\nSensitivity to assumptions:\n\nIf Ukrainian attendance is higher (e.g., 20% vs 15%), the immigration contribution increases to 0.05 pp\nIf Hong Kong attendance is higher (e.g., 15% vs 10%), contribution increases to 0.04 pp\n\nCombined with COVID effects: When immigration (~0.03 pp) is combined with COVID-19 rebound effects (estimated 1.0-1.5 pp), these two well-documented factors could account for 26-39% of the observed 4pp increase, leaving little room for a “genuine religious revival.”\n\nData sources: ONS (2025); Home Office (2024); Migration Observatory (2024)"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#could-measurement-artifacts-explain-the-unexplained-remainder",
    "href": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#could-measurement-artifacts-explain-the-unexplained-remainder",
    "title": "Weekly Attendance Claim Analysis",
    "section": "Could Measurement Artifacts Explain the Unexplained Remainder?",
    "text": "Could Measurement Artifacts Explain the Unexplained Remainder?\nThe immigration simulation above left 3.97 percentage points unexplained. Interestingly, the 2024 survey data reveals a substantial internal consistency problem that could account for much of this remainder.\n\nThe Internal Consistency Problem\nThe 2024 survey asked respondents about church attendance in two different ways:\n\nBinary question: “Have you attended church in the past year?” → 77% said YES\nFrequency breakdown: Sum of all specific frequency categories (daily, weekly, monthly, etc.) → 68.5% attended at least once\n\nDiscrepancy: 77% - 68.5% = 8.5 percentage points\nThis is a critical red flag suggesting measurement error, question order effects, or acquiescence bias in the survey instrument.\n\n\nShow the code\n# Internal consistency data from 2024 survey\nbinary_yes_2024 &lt;- 0.77    # Binary \"past year\" question\nfrequency_sum_2024 &lt;- 0.685  # Sum of frequency categories\nconsistency_discrepancy &lt;- binary_yes_2024 - frequency_sum_2024  # 8.5pp\n\n# Compare to unexplained remainder from immigration simulation\nunexplained_from_immigration &lt;- unexplained_pp / 100  # Convert to proportion\n\n# Analyze potential measurement artifact contribution\n# Assumption: If the binary question was asked FIRST in 2024 but NOT in 2018,\n# this could inflate 2024 estimates via priming/acquiescence bias\n\n# Scenario analysis: How much of unexplained could be measurement artifact?\npotential_measurement_contribution_low &lt;- consistency_discrepancy * 0.25  # 25% of discrepancy\npotential_measurement_contribution_mid &lt;- consistency_discrepancy * 0.50  # 50% of discrepancy  \npotential_measurement_contribution_high &lt;- consistency_discrepancy * 0.75 # 75% of discrepancy\n\n# Calculate what remains after accounting for measurement artifacts\nremainder_after_low &lt;- unexplained_from_immigration - potential_measurement_contribution_low\nremainder_after_mid &lt;- unexplained_from_immigration - potential_measurement_contribution_mid\nremainder_after_high &lt;- unexplained_from_immigration - potential_measurement_contribution_high\n\n# Combined explanation: Immigration + Measurement artifacts\ncombined_explanation_low &lt;- (immigration_contribution_pp + potential_measurement_contribution_low * 100)\ncombined_explanation_mid &lt;- (immigration_contribution_pp + potential_measurement_contribution_mid * 100)\ncombined_explanation_high &lt;- (immigration_contribution_pp + potential_measurement_contribution_high * 100)\n\ncombined_proportion_low &lt;- combined_explanation_low / observed_increase_pp * 100\ncombined_proportion_mid &lt;- combined_explanation_mid / observed_increase_pp * 100\ncombined_proportion_high &lt;- combined_explanation_high / observed_increase_pp * 100\n\n\n\n\nAnalysis: Can Measurement Artifacts Explain the Gap?\nInternal consistency discrepancy: 8.5 percentage points (8.5pp)\nUnexplained remainder from immigration simulation: 3.97 percentage points\nKey insight: The internal consistency problem (8.5pp) is 2.1 times larger than the unexplained remainder (3.59pp). This means measurement artifacts could more than fully account for the unexplained portion.\n\n\nScenario Analysis\nIf measurement artifacts (question order effects, acquiescence bias, priming) contribute even a fraction of the 8.5pp discrepancy to the observed 4pp increase:\nConservative scenario (25% of discrepancy affects increase): - Measurement contribution: 2.12 pp - Immigration contribution: 0.03 pp - Combined: 2.16 pp = 54% of observed 4pp increase - Remaining unexplained: 1.84 pp\nModerate scenario (50% of discrepancy affects increase): - Measurement contribution: 4.25 pp - Immigration contribution: 0.03 pp - Combined: 4.28 pp = 107% of observed 4pp increase - Remaining unexplained: -0.28 pp\nLiberal scenario (75% of discrepancy affects increase): - Measurement contribution: 6.37 pp - Immigration contribution: 0.03 pp - Combined: 6.41 pp = 160% of observed 4pp increase - Remaining unexplained: -2.41 pp\n\n\n\n\n\nCombined explanation: Immigration + Measurement artifacts\n\n\n\n\n\n\nInterpretation\n\nThe 8.5pp internal consistency problem is a major red flag: This discrepancy is more than twice the size of the entire 4pp increase being claimed as a “revival.”\nMeasurement artifacts could fully explain the unexplained remainder: Even if only 25-50% of the 8.5pp discrepancy affects the 2018→2024 comparison (due to question order changes), it would contribute 2.1-4.3pp, completely accounting for the 3.59pp unexplained by immigration alone.\nCombined explanation accounts for most/all of the increase:\n\nConservative estimate: Immigration (0.41pp) + Measurement (2.13pp) + COVID (1.25pp) = 3.79pp = 95% of 4pp increase\nModerate estimate: Immigration (0.41pp) + Measurement (4.25pp) = 4.66pp = 117% of 4pp increase (over-explained)\nLiberal estimate: Immigration (0.41pp) + Measurement (6.38pp) = 6.79pp = 170% of 4pp increase (massively over-explained)\n\nNo room for a “genuine revival”: Once immigration effects and measurement artifacts are accounted for, there is zero to negative unexplained variance left for a genuine increase in religious commitment.\nMethodological failure: Bible Society UK’s failure to:\n\nControl for demographic composition changes\nEnsure internal consistency of measurement\nMaintain consistent question ordering across waves\nTest for question order effects\n\n…means their claim is built on confounded, internally inconsistent data.\n\n\n\nThe Smoking Gun\nThe combination of: - 8.5pp internal inconsistency (binary vs frequency questions) - 375,000 high-religiosity immigrants (Ukrainian + Hong Kong) - 105% excess mortality peak (COVID-19 2020-2023) - No demographic standardisation - No belief triangulation - Only 2 time points\n…provides multiple, convergent lines of evidence that the “Quiet Revival” claim is not supported by the data. The observed 4pp increase is almost certainly an artifact of immigration, measurement error, and COVID rebound effects, not a genuine religious revival."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#effect-size",
    "href": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#effect-size",
    "title": "Weekly Attendance Claim Analysis",
    "section": "Effect Size",
    "text": "Effect Size\nStatistical significance doesn’t mean practical significance. Let’s calculate the effect size:\n\n\nShow the code\n# Cohen's h for proportion differences\ncohens_h &lt;- function(p1, p2) {\n  2 * (asin(sqrt(p2)) - asin(sqrt(p1)))\n}\n\nh &lt;- cohens_h(weekly_2018, weekly_2024)\n\ninterpret_h &lt;- function(h) {\n  abs_h &lt;- abs(h)\n  if (abs_h &lt; 0.2) return(\"Negligible\")\n  if (abs_h &lt; 0.5) return(\"Small\")\n  if (abs_h &lt; 0.8) return(\"Medium\")\n  return(\"Large\")\n}\n\n\n\nEffect Size (Cohen’s h)\nStatistical significance doesn’t mean practical significance. The effect size helps assess the magnitude of the change:\n\nh = 0.141 (Negligible effect)\n\nWhat is Cohen’s h?\nCohen’s h is a measure of effect size for comparing two proportions. Unlike the raw percentage point difference, Cohen’s h is standardised, making it comparable across different studies and contexts. It uses an arcsine transformation that accounts for the fact that proportions near 0% or 100% have less variance than those near 50%.\nStandard interpretation guidelines: - h &lt; 0.2: Negligible effect (trivial practical difference) - 0.2 ≤ h &lt; 0.5: Small effect (noticeable but modest) - 0.5 ≤ h &lt; 0.8: Medium effect (clearly meaningful) - h ≥ 0.8: Large effect (substantial practical importance)\nOur result: h = 0.141 falls in the Negligible range, meaning the 4 percentage point increase, while statistically significant, represents a modest practical change.\n\n\n\n\n\nVisual representation of effect size magnitude\n\n\n\n\n\n\nPractical Implications\nWhat does a Negligible effect size (h = 0.141) mean in practice?\n\nDetectability: The change is statistically detectable with large samples (n &gt; 10,000), but represents a modest shift in behaviour.\nReal-world impact: Moving from 7% to 11% means:\n\nIn a population of 1,000 people: ~40 additional weekly attendees\nThis is noticeable but not transformational\n\nComparison to other interventions: In behavioural science, effects of h ≈ 0.14 are typical of:\n\nMinor environmental nudges\nGradual demographic shifts\nSmall measurement or methodology changes\n\n“Revival” claim: A Negligible effect (h &lt; 0.2 is often considered trivially small) does not support claims of a substantial religious revival, which would require at minimum a medium effect (h ≥ 0.5)."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#confidence-intervals-visualisation",
    "href": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#confidence-intervals-visualisation",
    "title": "Weekly Attendance Claim Analysis",
    "section": "Confidence Intervals Visualisation",
    "text": "Confidence Intervals Visualisation\n\n\nShow the code\n# Prepare data for plotting\nplot_data &lt;- tibble(\n  Year = c(2018, 2024),\n  Estimate = c(ci_2018$estimate, ci_2024$estimate) * 100,\n  CI_Lower = c(ci_2018$ci_lower, ci_2024$ci_lower) * 100,\n  CI_Upper = c(ci_2018$ci_upper, ci_2024$ci_upper) * 100\n)\n\nggplot(plot_data, aes(x = factor(Year), y = Estimate)) +\n  geom_point(size = 3, color = \"steelblue\") +\n  geom_errorbar(aes(ymin = CI_Lower, ymax = CI_Upper), \n                width = 0.2, color = \"steelblue\", linewidth = 1) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", alpha = 0.3) +\n  labs(\n    x = \"Year\",\n    y = \"Percentage attending weekly\",\n    title = \"Weekly Church Attendance: 2018 vs 2024\",\n    subtitle = \"With 95% confidence intervals (design effect = 1.5)\"\n  ) +\n  theme_minimal() +\n  scale_y_continuous(labels = scales::percent_format(scale = 1))\n\n\n\n\n\nWeekly attendance estimates with 95% confidence intervals"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#interpretation-statistical-reality-vs-causal-stories",
    "href": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#interpretation-statistical-reality-vs-causal-stories",
    "title": "Weekly Attendance Claim Analysis",
    "section": "Interpretation: Statistical Reality vs Causal Stories",
    "text": "Interpretation: Statistical Reality vs Causal Stories\n\nThe Statistical Change is (Probably) Real\nBased on the converging evidence from multiple approaches:\n\nFrequentist analysis: p &lt; 0.0001, highly statistically significant\nBayesian analysis: &gt;99.9% probability of increase\nEffect size: h = 0.179 (small but detectable with large samples)\nConfidence/credible intervals: Both exclude zero, similar bounds\n\nConclusion: We can be confident that the 4 percentage point increase represents a genuine statistical pattern, not random sampling variation.\n\n\nBut Statistics ≠ Causation\nCritical distinction: Demonstrating that a statistical change is real tells us nothing about why it occurred. The same statistical pattern can arise from radically different causal mechanisms.\n\n\nCandidate Causal Explanations\nGiven the survey methodology, demographic context, and question structure, here are plausible explanations (not mutually exclusive):\n\n1. Immigration from Religious Countries (15-45% of effect)\nMechanism: Between 2018 and 2024, substantial immigration occurred from countries with higher religiosity, including Nigeria, Philippines, Romania, Poland, Middle Eastern nations, Ukraine, and Hong Kong. ONS data show UK immigration remained at historic highs during this period, with 1.3 million arriving in year ending (YE) December 2023 and 948,000 in YE December 2024 (ONS, 2025). Additionally, 158,000 Hong Kong BN(O) visa holders arrived between 2021-2024, and 217,000 Ukrainians arrived between 2022-2024 (Home Office, 2024).\nEvidence for: - Ukrainian immigration: Around 217,000 Ukrainians were living in the UK as of June 2024, with ~210,000 arriving under the Ukraine Family and Sponsorship Schemes since the 2022 invasion (Migration Observatory, 2024) - High Ukrainian religiosity: 85% of Ukrainians identify as Christian (72% Eastern Orthodox, 9% Catholic, 4% Protestant), significantly higher than UK’s ~46% Christian identification (Wikipedia: Religion in Ukraine, citing Kyiv International Institute of Sociology, 2022) - Hong Kong BN(O) immigration: 158,000 British National (Overseas) status holders from Hong Kong arrived in the UK between January 2021 and September 2024, with 22,500 arriving in YE September 2024 alone (Home Office, 2024). Hong Kong has substantial Christian population (~12-15%), higher than mainland China - Church attendance culture: Ukrainian Christians (particularly Eastern Orthodox and Greek Catholics) and Hong Kong Christians (predominantly Protestant and Catholic) have active church attendance traditions that could translate to UK church-going behaviour - Scale of non-EU+ immigration: 766,000 non-EU+ nationals arrived in YE December 2024 alone, with cumulative arrivals over 2018-2024 likely exceeding 4-5 million people - Immigration by reason (YE Dec 2024): 266,000 for study, 262,000 for work, 95,000 asylum seekers, 76,000 family reasons, 51,000 humanitarian routes including Ukraine schemes (ONS, 2025) - Top source countries: Indian, Pakistani, Chinese, Nigerian, Ukrainian, and Hong Kong nationals were among the top non-EU+ nationalities for immigration - Other religious immigration: Substantial influx from Nigeria, Philippines, Romania, Poland, and Middle Eastern nations with high Christian identification rates - Higher attendance rates: Immigrants from these regions attend church at 2-3× the UK baseline rate - Substantial effect size: Could explain 0.6-1.8 percentage points of the 4pp increase (15-45%) - No demographic standardisation performed: The surveys did not account for changing population composition by country of birth - Geographic concentration: Ukrainian arrivals were concentrated in Scotland (18%), London (17%), and South East (17%) – areas that could show localised attendance increases - Timing alignment: Most Ukrainian arrivals occurred in 2022-2023, with immigration peaking at 1.3 million in YE December 2023, immediately before the 2024 survey\nEvidence against: - Effect size might be at the lower end if integration reduces attendance over time - Requires assumptions about immigrant attendance rates and religious denominational alignment - Ukrainian refugees may not maintain home-country attendance patterns due to trauma and displacement - Not all immigrants from “religious countries” are practising Christians or attend Anglican/Catholic churches captured in surveys\nTestability: Could be tested with demographic breakdown by country of birth (data likely available but not reported), or by comparing attendance increases in areas with high vs low immigration\nData sources: - Office for National Statistics (ONS). (2025). “Long-term international migration, provisional: year ending December 2024”. Retrieved from https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/internationalmigration/bulletins/longterminternationalmigrationprovisional/yearendingdecember2024 - Cuibus, M., Walsh, P.W., & Sumption, M. (2024). “Ukrainian migration to the UK”. Migration Observatory briefing, COMPAS, University of Oxford. Retrieved from https://migrationobservatory.ox.ac.uk/resources/briefings/ukrainian-migration-to-the-uk/\n\n\n\n2. COVID-19 Rebound Effect\nMechanism: Churches were closed/restricted during 2020-2022. By 2024, previously regular attendees may have returned, creating a “rebound” relative to pandemic disruption. Additionally, elevated mortality during the pandemic may have driven people to seek community and meaning through religious participation.\nEvidence for: - 2024 represents first “normal” post-pandemic year: Death rates returned to pre-pandemic levels in 2024, marking the end of the acute crisis period (Our World in Data, 2025) - Significant mortality burden: UK excess deaths peaked at 105% above baseline in April 2020, remained elevated through 2021-2023, affecting ~3-4 million families through bereavement - Grief and mortality salience: Churches traditionally provide support during bereavement; increased mortality may have driven attendance for funerals, memorials, and community support - Religious organisations often see attendance recovery after disruptions: Historical patterns show rebound effects after crises - Other social activities show similar rebound patterns: Not unique to religious attendance - Pent-up demand: People unable to attend during lockdowns may have returned with renewed commitment\nEvidence against: - Effect should be temporary and decline over time (no data yet on 2025+ trends) - Some evidence suggests permanent losses from pandemic as people developed new habits - No baseline from 2019 to establish pre-pandemic level - If purely COVID-related, would expect larger increases in areas with higher mortality (not tested)\nTestability: Would require longitudinal data through 2020-2023 to observe trajectory, and correlation analysis between local mortality rates and attendance changes\nData source: Human Mortality Database; World Mortality Dataset (2024); Karlinsky and Kobak (2021) – processed by Our World in Data. Retrieved from https://ourworldindata.org/grapher/excess-mortality-p-scores-average-baseline\n\n\n\n3. Question Order and Measurement Effects\nMechanism: The 2024 survey asked questions in a different order/format than 2018, potentially introducing acquiescence bias or priming effects.\nEvidence for: - 2024 included a binary “past year” question (77% yes) that doesn’t match frequency breakdown (68.5% non-never) - Internal inconsistency: 8.5pp discrepancy suggests measurement error - Question order can affect responses by 3-7pp in survey research - Different question formats between years\nEvidence against: - Both surveys by same organisation (YouGov) using similar methodology - Effect should be random if truly measurement error\nTestability: See Question Order Effects analysis\n\n\n\n4. Demographic Composition Changes (Age/Education)\nMechanism: UK population aging + educational expansion could shift demographic weights toward groups with different attendance patterns.\nEvidence for: - Population is aging; older cohorts attend more frequently - Educational attainment increasing; relationship with attendance is complex - Sample size reduced 31% (19,875 → 13,146), potentially changing representativeness\nEvidence against: - Age-specific increases observed across all groups (not just older) - Standard population changes unlikely to produce 4pp shift in 6 years - Would require implausibly large demographic shifts\nTestability: Requires demographic standardisation/weighting (not performed)\n\n\n\n5. Natural Cohort Turnover\nMechanism: Older, less religious cohorts dying and being replaced by younger cohorts with different patterns.\nEvidence for: - ~3-4 million deaths between 2018-2024 in UK - Cohort replacement is continuous demographic process - Could represent generational shifts\nEvidence against: - Direction is wrong: younger generations typically less religious - Effect size too large for 6-year mortality replacement - Age breakdown shows increases across all groups, including young\nTestability: Requires cohort analysis tracking same individuals over time\n\n\n\n6. Genuine Religious Revival\nMechanism: Actual increase in religious commitment, belief, or practice across the UK population.\nEvidence for: - Attendance increase is statistically real - ??? (Bible Society UK provides no additional evidence)\nEvidence against: - Effect size trivially small (h = 0.179, &lt;0.2 threshold for “small”) - No belief triangulation: No evidence of increased religious belief, prayer, Bible reading, or other indicators - Internal inconsistencies: Binary question shows different pattern than frequency breakdown - “Never attended” decreased 4pp: Zero-sum constraint suggests shifting boundaries rather than new engagement - No control for confounders: Immigration, COVID, demographics all unaddressed - Only 2 time points: Can’t distinguish trend from noise - Cherry-picked metric: Focused on single favorable statistic\nTestability: Would require multiple convergent measures (belief, prayer, donations, etc.) all showing increases\n\n\n\n\nComparative Plausibility\nRanking explanations by plausibility given available evidence:\n\n\n\nRank\nExplanation\nPlausibility\nEvidence Quality\n\n\n\n\n1\nImmigration + COVID rebound\nHigh\nGood (external data: ONS, 2025; Our World in Data, 2025; Migration Observatory, 2024)\n\n\n2\nMeasurement artifacts\nMedium-High\nFair (internal inconsistency suggests problems)\n\n\n3\nDemographic composition\nMedium\nPoor (no standardisation performed)\n\n\n4\nNatural cohort turnover\nLow\nPoor (direction inconsistent)\n\n\n5\nGenuine religious revival\nVery Low\nVery Poor (no triangulation, contradictory evidence)\n\n\n\nMost likely scenario: The 4pp increase represents a combination of: - 1.0-1.8pp: Immigration effects (25-45% of increase) — 1.3 million arrivals in YE Dec 2023, including 217,000 Ukrainians (85% Christian) and 158,000 Hong Kong BN(O) holders (12-15% Christian), both with active church attendance cultures (ONS, 2025; Home Office, 2024) - 1.0-1.5pp: COVID-19 rebound (25-38% of increase) — UK excess deaths peaked at 105% in April 2020, remained elevated through 2023, returned to normal in 2024 (Our World in Data, 2025) - 0.5-1.0pp: Measurement artifacts (13-25% of increase) - 0.2-0.5pp: Demographic composition (5-13% of increase) - 0-0.5pp: Genuine behaviour change (0-13% of increase)\n\n\nKey Methodological Point\nThe absence of demographic standardisation, belief triangulation, and confound control means we cannot distinguish between these explanations. The Bible Society UK has presented a statistical pattern as if it were a causal story without ruling out alternative explanations.\nWhat would be needed to support a “revival” claim: 1. ✅ Statistical significance (achieved) 2. ✅ Meaningful effect size (failed - h = 0.179 is negligible) 3. ❌ Belief/commitment triangulation (not measured) 4. ❌ Demographic standardisation (not performed) 5. ❌ Alternative explanations ruled out (not addressed) 6. ❌ Longitudinal trend data (only 2 time points) 7. ❌ Internal consistency (contradictory measures)\nCurrent evidence grade: D (poor)"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#references",
    "href": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#references",
    "title": "Weekly Attendance Claim Analysis",
    "section": "References",
    "text": "References\n\nData Sources\nUK Immigration Statistics: - Office for National Statistics (ONS). (2025). “Long-term international migration, provisional: year ending December 2024”. Retrieved from https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/internationalmigration/bulletins/longterminternationalmigrationprovisional/yearendingdecember2024\nHumanitarian Migration Routes (Ukraine & Hong Kong): - Home Office. (2024). “How many people come to the UK via safe and legal (humanitarian) routes? Immigration system statistics, year ending September 2024”. UK Government. Retrieved from https://www.gov.uk/government/statistics/immigration-system-statistics-year-ending-september-2024/how-many-people-come-to-the-uk-via-safe-and-legal-humanitarian-routes\nUkrainian Migration: - Cuibus, M., Walsh, P.W., & Sumption, M. (2024). “Ukrainian migration to the UK”. Migration Observatory briefing, COMPAS, University of Oxford. Retrieved from https://migrationobservatory.ox.ac.uk/resources/briefings/ukrainian-migration-to-the-uk/\nUkrainian Religious Demographics: - Kyiv International Institute of Sociology (KIIS). (2022). “Dynamics of religious self-identification of the population of Ukraine”. Retrieved via Wikipedia: https://en.wikipedia.org/wiki/Religion_in_Ukraine\nUK Excess Mortality: - Our World in Data. (2025). “Excess mortality: Deaths from all causes compared to average over previous years”. Data adapted from Human Mortality Database, World Mortality Database. Retrieved from https://ourworldindata.org/grapher/excess-mortality-p-scores-average-baseline - Human Mortality Database; World Mortality Dataset (2024); Karlinsky and Kobak (2021); Human Mortality Database (2025); World Mortality Database (2024) – processed by Our World in Data. Retrieved October 31, 2025"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#detailed-follow-up-analyses",
    "href": "src/blog/misc/bible-society-uk-revival/weekly-attendance-claim.html#detailed-follow-up-analyses",
    "title": "Weekly Attendance Claim Analysis",
    "section": "Detailed Follow-up Analyses",
    "text": "Detailed Follow-up Analyses\nFor more rigorous investigation of specific causal mechanisms:\n\nQuestion Order Effects - Analysis of measurement artifacts and internal consistency\nDemographic Analysis - Investigation of age and ethnicity patterns\n\nCritical Analysis Overview - Comprehensive evaluation of all red flags and alternative explanations"
  },
  {
    "objectID": "src/blog/paper-reviews/index.html",
    "href": "src/blog/paper-reviews/index.html",
    "title": "Analysis and Discussion of Papers",
    "section": "",
    "text": "This section provides analysis and discussion of various papers.\n\nChatbot Effects on Postpartum Mental Health"
  },
  {
    "objectID": "docs/testing-ci-locally.html",
    "href": "docs/testing-ci-locally.html",
    "title": "Testing GitHub Actions Locally with act",
    "section": "",
    "text": "This guide explains how to test your GitHub Actions workflows locally using act.\n\n\n\nDocker installed and running - act uses Docker to simulate the GitHub Actions environment\nact installed - You can install it with:\nbrew install act  # macOS\n\nCheck if Docker is running:\ndocker ps\n\n\n\n\n\nUse the unified test runner for both manual local builds and CI simulation with act.\nManual build test (recommended for reliability):\n./scripts/test.sh\nCI test with act:\n# Basic\n./scripts/test.sh --ci\n\n# On Apple Silicon\n./scripts/test.sh --ci --amd64\n\n# Provide explicit token (otherwise uses gh auth token if available)\n./scripts/test.sh --ci --token YOUR_GITHUB_TOKEN\n\n\n\n\n\n\n⚠️ Important: Your workflow uses actions that require the GitHub CLI (gh) tool, which isn’t available in act’s Docker containers. This means: - ✅ Workflow syntax validation works - ✅ Action repository cloning works - ❌ Quarto setup step will fail (requires gh CLI) - ❌ Full R/renv testing may be limited\nFor comprehensive testing, push to a branch and check the GitHub Actions logs.\n\n\n\n\nManual mode runs the same steps as CI: renv::restore(), scripts/generate_nav.R, quarto render, and verifies _site/.\nCI mode runs your GitHub Actions workflow with act and an artifact server; it’s best for workflow syntax/flow validation, but may fail at Quarto setup due to missing gh CLI in containers.\n\nOption 2: Comment out the publish step temporarily\nFor a cleaner test, you can temporarily comment out the publish step in .github/workflows/publish.yml while testing.\nOption 3: Use act’s list functionality\n# See what jobs are available\nact push --list\n\n# Run specific job steps\nact push --job build-deploy --dryrun\n\n\n\n\n\n\nIf you get Docker errors:\n# Start Docker Desktop (macOS/Windows) or:\nsudo systemctl start docker  # Linux\n\n\n\nSome workflows need secrets. You can provide them with -s:\nact push -s GITHUB_TOKEN=your_token_here\nFor testing, you can use a dummy value since we’re just testing the build.\n\n\n\nThe workflow installs R packages via renv, which can take time. Be patient during the restore step.\n\n\n\n\nHere’s a one-liner to test your build pipeline:\n# Test the workflow (will fail at publish, but shows if build works)\nact push --job build-deploy -s GITHUB_TOKEN=dummy\n\n\n\n\nUse -v for verbose output to see detailed logs:\nact push -v\nSkip specific steps if needed using act’s configuration (create .actrc file)\nTest incrementally - Test individual steps before running the full workflow\nCheck Docker resources - Running full workflows can be resource-intensive. Ensure Docker has enough memory allocated (4GB+ recommended).\n\n\n\n\nInstead of using act, you can also manually test the pipeline steps:\n# 1. Restore renv\nrenv::restore()\n\n# 2. Generate navigation\nRscript scripts/generate_nav.R\n\n# 3. Render\nquarto render\n\n# 4. Check output in _site/\nls _site/\nThis won’t test the GitHub Actions environment, but it will verify the commands work locally.\n\n\n\n\nact Documentation\nGitHub Actions Documentation"
  },
  {
    "objectID": "docs/testing-ci-locally.html#prerequisites",
    "href": "docs/testing-ci-locally.html#prerequisites",
    "title": "Testing GitHub Actions Locally with act",
    "section": "",
    "text": "Docker installed and running - act uses Docker to simulate the GitHub Actions environment\nact installed - You can install it with:\nbrew install act  # macOS\n\nCheck if Docker is running:\ndocker ps"
  },
  {
    "objectID": "docs/testing-ci-locally.html#quick-start",
    "href": "docs/testing-ci-locally.html#quick-start",
    "title": "Testing GitHub Actions Locally with act",
    "section": "",
    "text": "Use the unified test runner for both manual local builds and CI simulation with act.\nManual build test (recommended for reliability):\n./scripts/test.sh\nCI test with act:\n# Basic\n./scripts/test.sh --ci\n\n# On Apple Silicon\n./scripts/test.sh --ci --amd64\n\n# Provide explicit token (otherwise uses gh auth token if available)\n./scripts/test.sh --ci --token YOUR_GITHUB_TOKEN"
  },
  {
    "objectID": "docs/testing-ci-locally.html#for-this-project",
    "href": "docs/testing-ci-locally.html#for-this-project",
    "title": "Testing GitHub Actions Locally with act",
    "section": "",
    "text": "⚠️ Important: Your workflow uses actions that require the GitHub CLI (gh) tool, which isn’t available in act’s Docker containers. This means: - ✅ Workflow syntax validation works - ✅ Action repository cloning works - ❌ Quarto setup step will fail (requires gh CLI) - ❌ Full R/renv testing may be limited\nFor comprehensive testing, push to a branch and check the GitHub Actions logs.\n\n\n\n\nManual mode runs the same steps as CI: renv::restore(), scripts/generate_nav.R, quarto render, and verifies _site/.\nCI mode runs your GitHub Actions workflow with act and an artifact server; it’s best for workflow syntax/flow validation, but may fail at Quarto setup due to missing gh CLI in containers.\n\nOption 2: Comment out the publish step temporarily\nFor a cleaner test, you can temporarily comment out the publish step in .github/workflows/publish.yml while testing.\nOption 3: Use act’s list functionality\n# See what jobs are available\nact push --list\n\n# Run specific job steps\nact push --job build-deploy --dryrun"
  },
  {
    "objectID": "docs/testing-ci-locally.html#common-issues",
    "href": "docs/testing-ci-locally.html#common-issues",
    "title": "Testing GitHub Actions Locally with act",
    "section": "",
    "text": "If you get Docker errors:\n# Start Docker Desktop (macOS/Windows) or:\nsudo systemctl start docker  # Linux\n\n\n\nSome workflows need secrets. You can provide them with -s:\nact push -s GITHUB_TOKEN=your_token_here\nFor testing, you can use a dummy value since we’re just testing the build.\n\n\n\nThe workflow installs R packages via renv, which can take time. Be patient during the restore step."
  },
  {
    "objectID": "docs/testing-ci-locally.html#quick-test-command",
    "href": "docs/testing-ci-locally.html#quick-test-command",
    "title": "Testing GitHub Actions Locally with act",
    "section": "",
    "text": "Here’s a one-liner to test your build pipeline:\n# Test the workflow (will fail at publish, but shows if build works)\nact push --job build-deploy -s GITHUB_TOKEN=dummy"
  },
  {
    "objectID": "docs/testing-ci-locally.html#tips",
    "href": "docs/testing-ci-locally.html#tips",
    "title": "Testing GitHub Actions Locally with act",
    "section": "",
    "text": "Use -v for verbose output to see detailed logs:\nact push -v\nSkip specific steps if needed using act’s configuration (create .actrc file)\nTest incrementally - Test individual steps before running the full workflow\nCheck Docker resources - Running full workflows can be resource-intensive. Ensure Docker has enough memory allocated (4GB+ recommended)."
  },
  {
    "objectID": "docs/testing-ci-locally.html#alternative-manual-testing",
    "href": "docs/testing-ci-locally.html#alternative-manual-testing",
    "title": "Testing GitHub Actions Locally with act",
    "section": "",
    "text": "Instead of using act, you can also manually test the pipeline steps:\n# 1. Restore renv\nrenv::restore()\n\n# 2. Generate navigation\nRscript scripts/generate_nav.R\n\n# 3. Render\nquarto render\n\n# 4. Check output in _site/\nls _site/\nThis won’t test the GitHub Actions environment, but it will verify the commands work locally."
  },
  {
    "objectID": "docs/testing-ci-locally.html#resources",
    "href": "docs/testing-ci-locally.html#resources",
    "title": "Testing GitHub Actions Locally with act",
    "section": "",
    "text": "act Documentation\nGitHub Actions Documentation"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/r-code-templates.html",
    "href": "docs/tech-specs/bible-society-review/r-code-templates.html",
    "title": "R Code Templates for Bible Society Analysis",
    "section": "",
    "text": "# Calculate 95% CI for a proportion with design effect correction\ncalc_prop_ci &lt;- function(p, n, deff = 1.5, conf_level = 0.95) {\n  n_eff &lt;- n / deff\n  z &lt;- qnorm((1 + conf_level) / 2)\n  se &lt;- sqrt(p * (1 - p) / n_eff)\n  \n  ci_lower &lt;- max(0, p - z * se)\n  ci_upper &lt;- min(1, p + z * se)\n  \n  tibble(\n    estimate = p,\n    se = se,\n    ci_lower = ci_lower,\n    ci_upper = ci_upper,\n    ci_width = ci_upper - ci_lower,\n    n_effective = n_eff\n  )\n}\n\n# Usage\ncalc_prop_ci(p = 0.07, n = 19875, deff = 1.5)\n\n\n\n# Test for difference between two proportions\ntest_prop_difference &lt;- function(p1, n1, p2, n2, deff = 1.5) {\n  n1_eff &lt;- n1 / deff\n  n2_eff &lt;- n2 / deff\n  \n  p_pooled &lt;- (p1 * n1_eff + p2 * n2_eff) / (n1_eff + n2_eff)\n  se_pooled &lt;- sqrt(p_pooled * (1 - p_pooled) * (1/n1_eff + 1/n2_eff))\n  \n  z &lt;- (p2 - p1) / se_pooled\n  p_value &lt;- 2 * pnorm(-abs(z))\n  \n  tibble(\n    p1 = p1,\n    p2 = p2,\n    difference = p2 - p1,\n    difference_pct = (p2 - p1) * 100,\n    z_statistic = z,\n    p_value = p_value,\n    significant = p_value &lt; 0.05\n  )\n}\n\n# Usage\ntest_prop_difference(p1 = 0.07, n1 = 19875, p2 = 0.11, n2 = 12455)\n\n\n\n# Calculate Cohen's h for proportion differences\ncohens_h &lt;- function(p1, p2) {\n  h &lt;- 2 * (asin(sqrt(p2)) - asin(sqrt(p1)))\n  \n  magnitude &lt;- case_when(\n    abs(h) &lt; 0.2 ~ \"Negligible\",\n    abs(h) &lt; 0.5 ~ \"Small\",\n    abs(h) &lt; 0.8 ~ \"Medium\",\n    TRUE ~ \"Large\"\n  )\n  \n  tibble(\n    p1 = p1,\n    p2 = p2,\n    cohens_h = h,\n    magnitude = magnitude\n  )\n}\n\n# Usage\ncohens_h(p1 = 0.07, p2 = 0.11)\n\n\n\n# Direct standardisation: Apply reference population weights to study rates\ndirect_standardisation &lt;- function(rates_df, pop_df, \n                                    rate_var = \"rate\", \n                                    group_var = \"group\",\n                                    weight_var = \"population_weight\") {\n  \n  # Join rates with population weights\n  standardised &lt;- rates_df %&gt;%\n    left_join(pop_df, by = group_var) %&gt;%\n    mutate(\n      weighted_rate = !!sym(rate_var) * !!sym(weight_var)\n    )\n  \n  # Calculate age-standardised rate\n  asr &lt;- standardised %&gt;%\n    summarise(\n      age_standardised_rate = sum(weighted_rate),\n      crude_rate = weighted.mean(!!sym(rate_var), !!sym(weight_var))\n    )\n  \n  return(asr)\n}\n\n# Example usage:\n# rates_2024 &lt;- tibble(\n#   age_group = c(\"18-34\", \"35-54\", \"55+\"),\n#   rate = c(0.26, 0.18, 0.27)\n# )\n# \n# pop_2018 &lt;- tibble(\n#   age_group = c(\"18-34\", \"35-54\", \"55+\"),\n#   population_weight = c(0.3, 0.35, 0.35)\n# )\n# \n# direct_standardisation(rates_2024, pop_2018, \n#                        rate_var = \"rate\", \n#                        group_var = \"age_group\")\n\n\n\n# Decompose change into compositional and behavioural effects\ndecompose_change &lt;- function(rates_2018, weights_2018, \n                              rates_2024, weights_2024) {\n  \n  # Overall rates\n  overall_2018 &lt;- sum(rates_2018 * weights_2018)\n  overall_2024 &lt;- sum(rates_2024 * weights_2024)\n  total_change &lt;- overall_2024 - overall_2018\n  \n  # Compositional effect (population structure change)\n  # Hold rates constant at 2018, apply 2024 weights\n  compositional_effect &lt;- sum(rates_2018 * weights_2024) - overall_2018\n  \n  # Behavioural effect (rate changes within groups)\n  # Hold weights constant at 2024, apply 2024 rates\n  behavioural_effect &lt;- overall_2024 - sum(rates_2018 * weights_2024)\n  \n  tibble(\n    overall_2018 = overall_2018,\n    overall_2024 = overall_2024,\n    total_change = total_change,\n    compositional_effect = compositional_effect,\n    behavioural_effect = behavioural_effect,\n    pct_compositional = 100 * compositional_effect / total_change,\n    pct_behavioural = 100 * behavioural_effect / total_change\n  )\n}\n\n# Example usage:\n# rates_2018 &lt;- c(0.26, 0.18, 0.27)  # Age groups: 18-34, 35-54, 55+\n# weights_2018 &lt;- c(0.29, 0.34, 0.37)\n# rates_2024 &lt;- c(0.26, 0.18, 0.27)  # Assume rates unchanged (null hypothesis)\n# weights_2024 &lt;- c(0.26, 0.33, 0.40)  # Shifted towards older\n# \n# decompose_change(rates_2018, weights_2018, rates_2024, weights_2024)\n\n\n\n# Perform analysis within each subgroup and create forest plot\nstratified_analysis &lt;- function(data, strata_var, outcome_var, year_var) {\n  \n  results &lt;- data %&gt;%\n    group_by(!!sym(strata_var)) %&gt;%\n    summarise(\n      rate_2018 = mean(!!sym(outcome_var)[!!sym(year_var) == 2018]),\n      rate_2024 = mean(!!sym(outcome_var)[!!sym(year_var) == 2024]),\n      n_2018 = sum(!!sym(year_var) == 2018),\n      n_2024 = sum(!!sym(year_var) == 2024),\n      .groups = \"drop\"\n    ) %&gt;%\n    mutate(\n      difference = rate_2024 - rate_2018,\n      # Calculate CIs\n      ci_lower = difference - 1.96 * sqrt(\n        rate_2018 * (1 - rate_2018) / n_2018 + \n        rate_2024 * (1 - rate_2024) / n_2024\n      ),\n      ci_upper = difference + 1.96 * sqrt(\n        rate_2018 * (1 - rate_2018) / n_2018 + \n        rate_2024 * (1 - rate_2024) / n_2024\n      )\n    )\n  \n  # Create forest plot\n  p &lt;- ggplot(results, aes(x = !!sym(strata_var), y = difference)) +\n    geom_hline(yintercept = 0, linetype = \"dashed\", colour = \"grey50\") +\n    geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper),\n                    size = 0.5, fatten = 2) +\n    coord_flip() +\n    labs(\n      title = \"Stratified Analysis: Change in Attendance Rate\",\n      subtitle = \"2018 to 2024\",\n      x = NULL,\n      y = \"Difference in Rate (2024 - 2018) with 95% CI\"\n    ) +\n    theme_minimal()\n  \n  list(results = results, plot = p)\n}\n\n\n\n# Test robustness of conclusions to different assumptions\nsensitivity_analysis &lt;- function(p1, n1, p2, n2, \n                                  deff_range = c(1.0, 1.5, 2.0, 2.5, 3.0)) {\n  \n  map_df(deff_range, function(deff) {\n    test_result &lt;- test_prop_difference(p1, n1, p2, n2, deff = deff)\n    ci_result &lt;- calc_prop_ci(p2, n2, deff = deff)\n    \n    tibble(\n      design_effect = deff,\n      difference_pct = test_result$difference_pct,\n      p_value = test_result$p_value,\n      significant = test_result$significant,\n      ci_lower = ci_result$ci_lower,\n      ci_upper = ci_result$ci_upper,\n      ci_width = ci_result$ci_width\n    )\n  })\n}\n\n# Usage\nsensitivity_results &lt;- sensitivity_analysis(\n  p1 = 0.07, n1 = 19875, \n  p2 = 0.11, n2 = 12455\n)\n\n# Visualise\nggplot(sensitivity_results, aes(x = design_effect, y = difference_pct)) +\n  geom_line() +\n  geom_ribbon(aes(ymin = ci_lower * 100, ymax = ci_upper * 100), \n              alpha = 0.3) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(\n    title = \"Sensitivity to Design Effect Assumption\",\n    x = \"Design Effect\",\n    y = \"Estimated Difference (%)\"\n  ) +\n  theme_minimal()\n\n\n\n# Create comparison plot with error bars\ncreate_comparison_plot &lt;- function(data, measure_name) {\n  \n  p &lt;- data %&gt;%\n    mutate(year = factor(year)) %&gt;%\n    ggplot(aes(x = year, y = estimate, colour = year)) +\n    geom_pointrange(\n      aes(ymin = ci_lower, ymax = ci_upper),\n      size = 1,\n      fatten = 3,\n      position = position_dodge(width = 0.3)\n    ) +\n    scale_colour_manual(\n      values = c(\"2018\" = \"#D55E00\", \"2024\" = \"#0072B2\"),\n      guide = \"none\"\n    ) +\n    scale_y_continuous(labels = percent_format(accuracy = 1)) +\n    labs(\n      title = str_glue(\"Church Attendance: {measure_name}\"),\n      subtitle = \"Point estimates with 95% confidence intervals\",\n      x = \"Survey Year\",\n      y = \"Percentage\",\n      caption = str_glue(\n        \"Source: Bible Society UK / YouGov Surveys\\n\",\n        \"Error bars show 95% CIs with design effect = 1.5\"\n      )\n    ) +\n    theme_minimal(base_size = 13) +\n    theme(\n      plot.title = element_text(face = \"bold\", size = 15),\n      plot.caption = element_text(hjust = 0, size = 9, colour = \"grey50\"),\n      panel.grid.minor = element_blank()\n    )\n  \n  return(p)\n}\n\n\n\n# Create comprehensive summary table\ncreate_summary_table &lt;- function(results_df) {\n  \n  results_df %&gt;%\n    select(\n      Metric = metric,\n      `2018 (%)` = estimate_2018,\n      `2024 (%)` = estimate_2024,\n      `Change (pp)` = change,\n      `95% CI` = ci,\n      `P-value` = p_value,\n      `Effect Size` = effect_size,\n      Interpretation = interpretation\n    ) %&gt;%\n    gt() %&gt;%\n    tab_header(\n      title = \"Church Attendance Changes: 2018 vs 2024\",\n      subtitle = \"Statistical summary with confidence intervals and effect sizes\"\n    ) %&gt;%\n    fmt_number(columns = c(`2018 (%)`, `2024 (%)`, `Change (pp)`), \n               decimals = 1) %&gt;%\n    fmt_number(columns = `P-value`, decimals = 4) %&gt;%\n    tab_style(\n      style = cell_fill(color = \"lightyellow\"),\n      locations = cells_body(\n        columns = everything(),\n        rows = `P-value` &lt; 0.05\n      )\n    ) %&gt;%\n    tab_footnote(\n      footnote = \"Highlighted rows are statistically significant (p &lt; 0.05)\",\n      locations = cells_column_labels(columns = `P-value`)\n    ) %&gt;%\n    tab_source_note(\n      source_note = \"Design effect = 1.5 assumed for YouGov panel sampling\"\n    )\n}\n\n\n\n# Visualise compositional vs behavioural effects\ncreate_waterfall_plot &lt;- function(decomp_result) {\n  \n  waterfall_data &lt;- tribble(\n    ~step, ~value, ~type,\n    \"2018 Rate\", decomp_result$overall_2018, \"base\",\n    \"Compositional\\nEffect\", decomp_result$compositional_effect, \"change\",\n    \"Behavioural\\nEffect\", decomp_result$behavioural_effect, \"change\",\n    \"2024 Rate\", decomp_result$overall_2024, \"final\"\n  ) %&gt;%\n    mutate(\n      step = factor(step, levels = step),\n      cumulative = cumsum(replace_na(value, 0)),\n      end = cumulative,\n      start = lag(cumulative, default = 0)\n    )\n  \n  ggplot(waterfall_data, aes(x = step, fill = type)) +\n    geom_rect(aes(xmin = as.numeric(step) - 0.4, \n                  xmax = as.numeric(step) + 0.4,\n                  ymin = start, ymax = end)) +\n    geom_text(aes(y = (start + end) / 2, \n                  label = percent(value, accuracy = 0.1)),\n              size = 4) +\n    scale_fill_manual(\n      values = c(\"base\" = \"grey70\", \"change\" = \"steelblue\", \"final\" = \"grey70\"),\n      guide = \"none\"\n    ) +\n    scale_y_continuous(labels = percent_format()) +\n    labs(\n      title = \"Decomposition of Attendance Change\",\n      subtitle = \"How much is demographic composition vs behavioural change?\",\n      x = NULL,\n      y = \"Attendance Rate\",\n      caption = \"Compositional effect = change due to population demographics\\nBehavioural effect = change in attendance rates within groups\"\n    ) +\n    theme_minimal(base_size = 12) +\n    theme(\n      panel.grid.major.x = element_blank(),\n      plot.caption = element_text(hjust = 0, size = 9, colour = \"grey50\")\n    )\n}\n\n\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(gt)\nlibrary(patchwork)\n\n# 1. Load data\nattendance &lt;- read_csv(\"data/church_attendance_extracted.csv\")\n\n# 2. Calculate 2018 estimates with CIs\nresults_2018 &lt;- attendance %&gt;%\n  filter(year == 2018) %&gt;%\n  mutate(\n    ci_results = map2(total_pct / 100, 19875, calc_prop_ci, deff = 1.5)\n  ) %&gt;%\n  unnest_wider(ci_results)\n\n# 3. Calculate 2024 estimates with CIs\nresults_2024 &lt;- attendance %&gt;%\n  filter(year == 2024) %&gt;%\n  mutate(\n    ci_results = map2(total_pct / 100, 12455, calc_prop_ci, deff = 1.5)\n  ) %&gt;%\n  unnest_wider(ci_results)\n\n# 4. Test for significant changes\nkey_comparisons &lt;- tribble(\n  ~measure, ~p1, ~p2,\n  \"Weekly+\", 0.07, 0.11,\n  \"Never\", 0.63, 0.59\n) %&gt;%\n  mutate(\n    test_results = map2(p1, p2, ~test_prop_difference(\n      .x, 19875, .y, 12455, deff = 1.5\n    ))\n  ) %&gt;%\n  unnest_wider(test_results)\n\n# 5. Calculate effect sizes\nkey_comparisons &lt;- key_comparisons %&gt;%\n  mutate(\n    effect_size = map2(p1, p2, cohens_h)\n  ) %&gt;%\n  unnest_wider(effect_size)\n\n# 6. Create visualisations\np1 &lt;- create_comparison_plot(results_2024 %&gt;% filter(metric == \"Weekly+\"),\n                              \"At Least Weekly Attendance\")\np2 &lt;- create_comparison_plot(results_2024 %&gt;% filter(metric == \"Never\"),\n                              \"Never Attended\")\n\ncombined_plot &lt;- p1 + p2 + plot_layout(ncol = 2)\nggsave(\"outputs/comparison_plots.png\", combined_plot, width = 14, height = 6)\n\n# 7. Create summary table\nsummary_table &lt;- create_summary_table(key_comparisons)\ngtsave(summary_table, \"outputs/summary_table.html\")\n\n# 8. Print key findings\ncat(\"Key Findings:\\n\")\ncat(\"=============\\n\\n\")\nprint(key_comparisons %&gt;% \n        select(measure, difference_pct, p_value, cohens_h, magnitude))\n\n\n\n\nAll code follows these principles: - Uses tidyverse conventions (%&gt;% pipe, tibble, ggplot2) - Includes informative comments - Returns tibbles for easy manipulation - Creates publication-quality visualisations - Handles edge cases (e.g., proportions bounded at 0 and 1) - Includes design effect corrections throughout - Uses consistent naming (_ for functions, . avoided)\n\n\n\nAll templates assume: - Simple random sampling (adjusted by design effect) - Independent observations - Large sample sizes (normal approximation valid) - Missing data MCAR (missing completely at random)\n\n\n\nTo adapt these templates: 1. Change deff parameter if you have better estimates 2. Adjust confidence level (conf_level) if needed 3. Modify plot aesthetics to match your preferences 4. Add additional demographic variables as needed"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/r-code-templates.html#template-1-confidence-intervals-with-design-effect",
    "href": "docs/tech-specs/bible-society-review/r-code-templates.html#template-1-confidence-intervals-with-design-effect",
    "title": "R Code Templates for Bible Society Analysis",
    "section": "",
    "text": "# Calculate 95% CI for a proportion with design effect correction\ncalc_prop_ci &lt;- function(p, n, deff = 1.5, conf_level = 0.95) {\n  n_eff &lt;- n / deff\n  z &lt;- qnorm((1 + conf_level) / 2)\n  se &lt;- sqrt(p * (1 - p) / n_eff)\n  \n  ci_lower &lt;- max(0, p - z * se)\n  ci_upper &lt;- min(1, p + z * se)\n  \n  tibble(\n    estimate = p,\n    se = se,\n    ci_lower = ci_lower,\n    ci_upper = ci_upper,\n    ci_width = ci_upper - ci_lower,\n    n_effective = n_eff\n  )\n}\n\n# Usage\ncalc_prop_ci(p = 0.07, n = 19875, deff = 1.5)"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/r-code-templates.html#template-2-two-proportion-z-test",
    "href": "docs/tech-specs/bible-society-review/r-code-templates.html#template-2-two-proportion-z-test",
    "title": "R Code Templates for Bible Society Analysis",
    "section": "",
    "text": "# Test for difference between two proportions\ntest_prop_difference &lt;- function(p1, n1, p2, n2, deff = 1.5) {\n  n1_eff &lt;- n1 / deff\n  n2_eff &lt;- n2 / deff\n  \n  p_pooled &lt;- (p1 * n1_eff + p2 * n2_eff) / (n1_eff + n2_eff)\n  se_pooled &lt;- sqrt(p_pooled * (1 - p_pooled) * (1/n1_eff + 1/n2_eff))\n  \n  z &lt;- (p2 - p1) / se_pooled\n  p_value &lt;- 2 * pnorm(-abs(z))\n  \n  tibble(\n    p1 = p1,\n    p2 = p2,\n    difference = p2 - p1,\n    difference_pct = (p2 - p1) * 100,\n    z_statistic = z,\n    p_value = p_value,\n    significant = p_value &lt; 0.05\n  )\n}\n\n# Usage\ntest_prop_difference(p1 = 0.07, n1 = 19875, p2 = 0.11, n2 = 12455)"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/r-code-templates.html#template-3-cohens-h-effect-size",
    "href": "docs/tech-specs/bible-society-review/r-code-templates.html#template-3-cohens-h-effect-size",
    "title": "R Code Templates for Bible Society Analysis",
    "section": "",
    "text": "# Calculate Cohen's h for proportion differences\ncohens_h &lt;- function(p1, p2) {\n  h &lt;- 2 * (asin(sqrt(p2)) - asin(sqrt(p1)))\n  \n  magnitude &lt;- case_when(\n    abs(h) &lt; 0.2 ~ \"Negligible\",\n    abs(h) &lt; 0.5 ~ \"Small\",\n    abs(h) &lt; 0.8 ~ \"Medium\",\n    TRUE ~ \"Large\"\n  )\n  \n  tibble(\n    p1 = p1,\n    p2 = p2,\n    cohens_h = h,\n    magnitude = magnitude\n  )\n}\n\n# Usage\ncohens_h(p1 = 0.07, p2 = 0.11)"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/r-code-templates.html#template-4-demographic-standardisation",
    "href": "docs/tech-specs/bible-society-review/r-code-templates.html#template-4-demographic-standardisation",
    "title": "R Code Templates for Bible Society Analysis",
    "section": "",
    "text": "# Direct standardisation: Apply reference population weights to study rates\ndirect_standardisation &lt;- function(rates_df, pop_df, \n                                    rate_var = \"rate\", \n                                    group_var = \"group\",\n                                    weight_var = \"population_weight\") {\n  \n  # Join rates with population weights\n  standardised &lt;- rates_df %&gt;%\n    left_join(pop_df, by = group_var) %&gt;%\n    mutate(\n      weighted_rate = !!sym(rate_var) * !!sym(weight_var)\n    )\n  \n  # Calculate age-standardised rate\n  asr &lt;- standardised %&gt;%\n    summarise(\n      age_standardised_rate = sum(weighted_rate),\n      crude_rate = weighted.mean(!!sym(rate_var), !!sym(weight_var))\n    )\n  \n  return(asr)\n}\n\n# Example usage:\n# rates_2024 &lt;- tibble(\n#   age_group = c(\"18-34\", \"35-54\", \"55+\"),\n#   rate = c(0.26, 0.18, 0.27)\n# )\n# \n# pop_2018 &lt;- tibble(\n#   age_group = c(\"18-34\", \"35-54\", \"55+\"),\n#   population_weight = c(0.3, 0.35, 0.35)\n# )\n# \n# direct_standardisation(rates_2024, pop_2018, \n#                        rate_var = \"rate\", \n#                        group_var = \"age_group\")"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/r-code-templates.html#template-5-compositional-effect-decomposition",
    "href": "docs/tech-specs/bible-society-review/r-code-templates.html#template-5-compositional-effect-decomposition",
    "title": "R Code Templates for Bible Society Analysis",
    "section": "",
    "text": "# Decompose change into compositional and behavioural effects\ndecompose_change &lt;- function(rates_2018, weights_2018, \n                              rates_2024, weights_2024) {\n  \n  # Overall rates\n  overall_2018 &lt;- sum(rates_2018 * weights_2018)\n  overall_2024 &lt;- sum(rates_2024 * weights_2024)\n  total_change &lt;- overall_2024 - overall_2018\n  \n  # Compositional effect (population structure change)\n  # Hold rates constant at 2018, apply 2024 weights\n  compositional_effect &lt;- sum(rates_2018 * weights_2024) - overall_2018\n  \n  # Behavioural effect (rate changes within groups)\n  # Hold weights constant at 2024, apply 2024 rates\n  behavioural_effect &lt;- overall_2024 - sum(rates_2018 * weights_2024)\n  \n  tibble(\n    overall_2018 = overall_2018,\n    overall_2024 = overall_2024,\n    total_change = total_change,\n    compositional_effect = compositional_effect,\n    behavioural_effect = behavioural_effect,\n    pct_compositional = 100 * compositional_effect / total_change,\n    pct_behavioural = 100 * behavioural_effect / total_change\n  )\n}\n\n# Example usage:\n# rates_2018 &lt;- c(0.26, 0.18, 0.27)  # Age groups: 18-34, 35-54, 55+\n# weights_2018 &lt;- c(0.29, 0.34, 0.37)\n# rates_2024 &lt;- c(0.26, 0.18, 0.27)  # Assume rates unchanged (null hypothesis)\n# weights_2024 &lt;- c(0.26, 0.33, 0.40)  # Shifted towards older\n# \n# decompose_change(rates_2018, weights_2018, rates_2024, weights_2024)"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/r-code-templates.html#template-6-stratified-analysis-with-forest-plot",
    "href": "docs/tech-specs/bible-society-review/r-code-templates.html#template-6-stratified-analysis-with-forest-plot",
    "title": "R Code Templates for Bible Society Analysis",
    "section": "",
    "text": "# Perform analysis within each subgroup and create forest plot\nstratified_analysis &lt;- function(data, strata_var, outcome_var, year_var) {\n  \n  results &lt;- data %&gt;%\n    group_by(!!sym(strata_var)) %&gt;%\n    summarise(\n      rate_2018 = mean(!!sym(outcome_var)[!!sym(year_var) == 2018]),\n      rate_2024 = mean(!!sym(outcome_var)[!!sym(year_var) == 2024]),\n      n_2018 = sum(!!sym(year_var) == 2018),\n      n_2024 = sum(!!sym(year_var) == 2024),\n      .groups = \"drop\"\n    ) %&gt;%\n    mutate(\n      difference = rate_2024 - rate_2018,\n      # Calculate CIs\n      ci_lower = difference - 1.96 * sqrt(\n        rate_2018 * (1 - rate_2018) / n_2018 + \n        rate_2024 * (1 - rate_2024) / n_2024\n      ),\n      ci_upper = difference + 1.96 * sqrt(\n        rate_2018 * (1 - rate_2018) / n_2018 + \n        rate_2024 * (1 - rate_2024) / n_2024\n      )\n    )\n  \n  # Create forest plot\n  p &lt;- ggplot(results, aes(x = !!sym(strata_var), y = difference)) +\n    geom_hline(yintercept = 0, linetype = \"dashed\", colour = \"grey50\") +\n    geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper),\n                    size = 0.5, fatten = 2) +\n    coord_flip() +\n    labs(\n      title = \"Stratified Analysis: Change in Attendance Rate\",\n      subtitle = \"2018 to 2024\",\n      x = NULL,\n      y = \"Difference in Rate (2024 - 2018) with 95% CI\"\n    ) +\n    theme_minimal()\n  \n  list(results = results, plot = p)\n}"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/r-code-templates.html#template-7-sensitivity-analysis",
    "href": "docs/tech-specs/bible-society-review/r-code-templates.html#template-7-sensitivity-analysis",
    "title": "R Code Templates for Bible Society Analysis",
    "section": "",
    "text": "# Test robustness of conclusions to different assumptions\nsensitivity_analysis &lt;- function(p1, n1, p2, n2, \n                                  deff_range = c(1.0, 1.5, 2.0, 2.5, 3.0)) {\n  \n  map_df(deff_range, function(deff) {\n    test_result &lt;- test_prop_difference(p1, n1, p2, n2, deff = deff)\n    ci_result &lt;- calc_prop_ci(p2, n2, deff = deff)\n    \n    tibble(\n      design_effect = deff,\n      difference_pct = test_result$difference_pct,\n      p_value = test_result$p_value,\n      significant = test_result$significant,\n      ci_lower = ci_result$ci_lower,\n      ci_upper = ci_result$ci_upper,\n      ci_width = ci_result$ci_width\n    )\n  })\n}\n\n# Usage\nsensitivity_results &lt;- sensitivity_analysis(\n  p1 = 0.07, n1 = 19875, \n  p2 = 0.11, n2 = 12455\n)\n\n# Visualise\nggplot(sensitivity_results, aes(x = design_effect, y = difference_pct)) +\n  geom_line() +\n  geom_ribbon(aes(ymin = ci_lower * 100, ymax = ci_upper * 100), \n              alpha = 0.3) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(\n    title = \"Sensitivity to Design Effect Assumption\",\n    x = \"Design Effect\",\n    y = \"Estimated Difference (%)\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/r-code-templates.html#template-8-publication-quality-comparison-plot",
    "href": "docs/tech-specs/bible-society-review/r-code-templates.html#template-8-publication-quality-comparison-plot",
    "title": "R Code Templates for Bible Society Analysis",
    "section": "",
    "text": "# Create comparison plot with error bars\ncreate_comparison_plot &lt;- function(data, measure_name) {\n  \n  p &lt;- data %&gt;%\n    mutate(year = factor(year)) %&gt;%\n    ggplot(aes(x = year, y = estimate, colour = year)) +\n    geom_pointrange(\n      aes(ymin = ci_lower, ymax = ci_upper),\n      size = 1,\n      fatten = 3,\n      position = position_dodge(width = 0.3)\n    ) +\n    scale_colour_manual(\n      values = c(\"2018\" = \"#D55E00\", \"2024\" = \"#0072B2\"),\n      guide = \"none\"\n    ) +\n    scale_y_continuous(labels = percent_format(accuracy = 1)) +\n    labs(\n      title = str_glue(\"Church Attendance: {measure_name}\"),\n      subtitle = \"Point estimates with 95% confidence intervals\",\n      x = \"Survey Year\",\n      y = \"Percentage\",\n      caption = str_glue(\n        \"Source: Bible Society UK / YouGov Surveys\\n\",\n        \"Error bars show 95% CIs with design effect = 1.5\"\n      )\n    ) +\n    theme_minimal(base_size = 13) +\n    theme(\n      plot.title = element_text(face = \"bold\", size = 15),\n      plot.caption = element_text(hjust = 0, size = 9, colour = \"grey50\"),\n      panel.grid.minor = element_blank()\n    )\n  \n  return(p)\n}"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/r-code-templates.html#template-9-summary-statistics-table",
    "href": "docs/tech-specs/bible-society-review/r-code-templates.html#template-9-summary-statistics-table",
    "title": "R Code Templates for Bible Society Analysis",
    "section": "",
    "text": "# Create comprehensive summary table\ncreate_summary_table &lt;- function(results_df) {\n  \n  results_df %&gt;%\n    select(\n      Metric = metric,\n      `2018 (%)` = estimate_2018,\n      `2024 (%)` = estimate_2024,\n      `Change (pp)` = change,\n      `95% CI` = ci,\n      `P-value` = p_value,\n      `Effect Size` = effect_size,\n      Interpretation = interpretation\n    ) %&gt;%\n    gt() %&gt;%\n    tab_header(\n      title = \"Church Attendance Changes: 2018 vs 2024\",\n      subtitle = \"Statistical summary with confidence intervals and effect sizes\"\n    ) %&gt;%\n    fmt_number(columns = c(`2018 (%)`, `2024 (%)`, `Change (pp)`), \n               decimals = 1) %&gt;%\n    fmt_number(columns = `P-value`, decimals = 4) %&gt;%\n    tab_style(\n      style = cell_fill(color = \"lightyellow\"),\n      locations = cells_body(\n        columns = everything(),\n        rows = `P-value` &lt; 0.05\n      )\n    ) %&gt;%\n    tab_footnote(\n      footnote = \"Highlighted rows are statistically significant (p &lt; 0.05)\",\n      locations = cells_column_labels(columns = `P-value`)\n    ) %&gt;%\n    tab_source_note(\n      source_note = \"Design effect = 1.5 assumed for YouGov panel sampling\"\n    )\n}"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/r-code-templates.html#template-10-waterfall-chart-for-decomposition",
    "href": "docs/tech-specs/bible-society-review/r-code-templates.html#template-10-waterfall-chart-for-decomposition",
    "title": "R Code Templates for Bible Society Analysis",
    "section": "",
    "text": "# Visualise compositional vs behavioural effects\ncreate_waterfall_plot &lt;- function(decomp_result) {\n  \n  waterfall_data &lt;- tribble(\n    ~step, ~value, ~type,\n    \"2018 Rate\", decomp_result$overall_2018, \"base\",\n    \"Compositional\\nEffect\", decomp_result$compositional_effect, \"change\",\n    \"Behavioural\\nEffect\", decomp_result$behavioural_effect, \"change\",\n    \"2024 Rate\", decomp_result$overall_2024, \"final\"\n  ) %&gt;%\n    mutate(\n      step = factor(step, levels = step),\n      cumulative = cumsum(replace_na(value, 0)),\n      end = cumulative,\n      start = lag(cumulative, default = 0)\n    )\n  \n  ggplot(waterfall_data, aes(x = step, fill = type)) +\n    geom_rect(aes(xmin = as.numeric(step) - 0.4, \n                  xmax = as.numeric(step) + 0.4,\n                  ymin = start, ymax = end)) +\n    geom_text(aes(y = (start + end) / 2, \n                  label = percent(value, accuracy = 0.1)),\n              size = 4) +\n    scale_fill_manual(\n      values = c(\"base\" = \"grey70\", \"change\" = \"steelblue\", \"final\" = \"grey70\"),\n      guide = \"none\"\n    ) +\n    scale_y_continuous(labels = percent_format()) +\n    labs(\n      title = \"Decomposition of Attendance Change\",\n      subtitle = \"How much is demographic composition vs behavioural change?\",\n      x = NULL,\n      y = \"Attendance Rate\",\n      caption = \"Compositional effect = change due to population demographics\\nBehavioural effect = change in attendance rates within groups\"\n    ) +\n    theme_minimal(base_size = 12) +\n    theme(\n      panel.grid.major.x = element_blank(),\n      plot.caption = element_text(hjust = 0, size = 9, colour = \"grey50\")\n    )\n}"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/r-code-templates.html#complete-workflow-example",
    "href": "docs/tech-specs/bible-society-review/r-code-templates.html#complete-workflow-example",
    "title": "R Code Templates for Bible Society Analysis",
    "section": "",
    "text": "library(tidyverse)\nlibrary(scales)\nlibrary(gt)\nlibrary(patchwork)\n\n# 1. Load data\nattendance &lt;- read_csv(\"data/church_attendance_extracted.csv\")\n\n# 2. Calculate 2018 estimates with CIs\nresults_2018 &lt;- attendance %&gt;%\n  filter(year == 2018) %&gt;%\n  mutate(\n    ci_results = map2(total_pct / 100, 19875, calc_prop_ci, deff = 1.5)\n  ) %&gt;%\n  unnest_wider(ci_results)\n\n# 3. Calculate 2024 estimates with CIs\nresults_2024 &lt;- attendance %&gt;%\n  filter(year == 2024) %&gt;%\n  mutate(\n    ci_results = map2(total_pct / 100, 12455, calc_prop_ci, deff = 1.5)\n  ) %&gt;%\n  unnest_wider(ci_results)\n\n# 4. Test for significant changes\nkey_comparisons &lt;- tribble(\n  ~measure, ~p1, ~p2,\n  \"Weekly+\", 0.07, 0.11,\n  \"Never\", 0.63, 0.59\n) %&gt;%\n  mutate(\n    test_results = map2(p1, p2, ~test_prop_difference(\n      .x, 19875, .y, 12455, deff = 1.5\n    ))\n  ) %&gt;%\n  unnest_wider(test_results)\n\n# 5. Calculate effect sizes\nkey_comparisons &lt;- key_comparisons %&gt;%\n  mutate(\n    effect_size = map2(p1, p2, cohens_h)\n  ) %&gt;%\n  unnest_wider(effect_size)\n\n# 6. Create visualisations\np1 &lt;- create_comparison_plot(results_2024 %&gt;% filter(metric == \"Weekly+\"),\n                              \"At Least Weekly Attendance\")\np2 &lt;- create_comparison_plot(results_2024 %&gt;% filter(metric == \"Never\"),\n                              \"Never Attended\")\n\ncombined_plot &lt;- p1 + p2 + plot_layout(ncol = 2)\nggsave(\"outputs/comparison_plots.png\", combined_plot, width = 14, height = 6)\n\n# 7. Create summary table\nsummary_table &lt;- create_summary_table(key_comparisons)\ngtsave(summary_table, \"outputs/summary_table.html\")\n\n# 8. Print key findings\ncat(\"Key Findings:\\n\")\ncat(\"=============\\n\\n\")\nprint(key_comparisons %&gt;% \n        select(measure, difference_pct, p_value, cohens_h, magnitude))"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/r-code-templates.html#notes-on-code-style",
    "href": "docs/tech-specs/bible-society-review/r-code-templates.html#notes-on-code-style",
    "title": "R Code Templates for Bible Society Analysis",
    "section": "",
    "text": "All code follows these principles: - Uses tidyverse conventions (%&gt;% pipe, tibble, ggplot2) - Includes informative comments - Returns tibbles for easy manipulation - Creates publication-quality visualisations - Handles edge cases (e.g., proportions bounded at 0 and 1) - Includes design effect corrections throughout - Uses consistent naming (_ for functions, . avoided)"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/r-code-templates.html#statistical-assumptions",
    "href": "docs/tech-specs/bible-society-review/r-code-templates.html#statistical-assumptions",
    "title": "R Code Templates for Bible Society Analysis",
    "section": "",
    "text": "All templates assume: - Simple random sampling (adjusted by design effect) - Independent observations - Large sample sizes (normal approximation valid) - Missing data MCAR (missing completely at random)"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/r-code-templates.html#customisation",
    "href": "docs/tech-specs/bible-society-review/r-code-templates.html#customisation",
    "title": "R Code Templates for Bible Society Analysis",
    "section": "",
    "text": "To adapt these templates: 1. Change deff parameter if you have better estimates 2. Adjust confidence level (conf_level) if needed 3. Modify plot aesthetics to match your preferences 4. Add additional demographic variables as needed"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This website brings together my exploration of statistical concepts through interactive demonstrations, data analysis, and critical examination of research. The goal is to make statistics accessible through hands-on learning with reproducible R code."
  },
  {
    "objectID": "about.html#about-this-site",
    "href": "about.html#about-this-site",
    "title": "About",
    "section": "",
    "text": "This website brings together my exploration of statistical concepts through interactive demonstrations, data analysis, and critical examination of research. The goal is to make statistics accessible through hands-on learning with reproducible R code."
  },
  {
    "objectID": "about.html#about-the-author",
    "href": "about.html#about-the-author",
    "title": "About",
    "section": "About the Author",
    "text": "About the Author\nNathan Ormond is a Senior Software Engineer with a diverse academic and professional background.\n\nBackground\nNathan began his career through a degree apprenticeship, combining practical experience with formal education. He holds: - MSc in Philosophy - Currently pursuing an MS in Statistics part-time while working\n\n\nProfessional Work\nNathan is the founder of Eukrasis Ltd, where he provides consulting services in: - Software Engineering - Statistics\nHis background—spanning software engineering, philosophy, and statistics—drives his passion for exploring and explaining complex concepts.\n\n\nConnect\nYou can find more about Nathan and links to his work at linktr.ee/digitalgnosis."
  },
  {
    "objectID": "about.html#about-the-project",
    "href": "about.html#about-the-project",
    "title": "About",
    "section": "About the Project",
    "text": "About the Project\nThis site is built using:\n\nQuarto - Scientific and technical publishing system\nR - Statistical computing and graphics\nggplot2 - Data visualisation\nOther open-source R packages for statistical analysis\n\nAll code examples are reproducible and available for you to experiment with. The site is open source and welcomes contributions and feedback."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nathan’s Stats Stuff",
    "section": "",
    "text": "This website brings together my work exploring statistical concepts through interactive demonstrations and data analysis. Whether you’re learning statistics or interested in critical analysis of research papers, you’ll find hands-on examples with R code that you can run, modify, and learn from."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Nathan’s Stats Stuff",
    "section": "",
    "text": "This website brings together my work exploring statistical concepts through interactive demonstrations and data analysis. Whether you’re learning statistics or interested in critical analysis of research papers, you’ll find hands-on examples with R code that you can run, modify, and learn from."
  },
  {
    "objectID": "index.html#teaching-statistics",
    "href": "index.html#teaching-statistics",
    "title": "Nathan’s Stats Stuff",
    "section": "Teaching Statistics",
    "text": "Teaching Statistics\nLearn fundamental statistical concepts through interactive demonstrations with live R code examples.\nFeatured Content: - Core Statistical Concepts - Interactive tutorials covering essential topics like: - Central Limit Theorem - Understanding how sampling distributions approach normality - Degrees of Freedom - Exploring this fundamental statistical concept\nBrowse All Teaching Content →"
  },
  {
    "objectID": "index.html#blog-analysis",
    "href": "index.html#blog-analysis",
    "title": "Nathan’s Stats Stuff",
    "section": "Blog & Analysis",
    "text": "Blog & Analysis\nCritical analysis and discussion of statistical papers and research.\nPaper Reviews - In-depth analysis of research papers, exploring: - Study design and methodology - Statistical analysis approaches - Interpretation of results - Personal commentary and insights"
  },
  {
    "objectID": "index.html#about-this-project",
    "href": "index.html#about-this-project",
    "title": "Nathan’s Stats Stuff",
    "section": "About This Project",
    "text": "About This Project\nThis site is built with Quarto and uses R for all statistical demonstrations. All code is reproducible and available for you to experiment with. The goal is to make statistical concepts more accessible through hands-on learning.\nAll of the source code for this project can be found on GitHub: https://github.com/NathOrmond/statistics-notes.git"
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Nathan’s Stats Stuff",
    "section": "Getting Started",
    "text": "Getting Started\n\nExplore the Teaching Statistics section to learn core concepts\nCheck out Paper Reviews for critical analysis\nRun and modify the R code examples to experiment with the concepts\n\nTechnical Requirements: R (version 4.0+) and a modern web browser. Required R packages will be automatically installed when you run the code blocks."
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/red-flag-summary.html",
    "href": "docs/tech-specs/bible-society-review/red-flag-summary.html",
    "title": "Bible Society UK “Quiet Revival” Claim - Red Flag Summary",
    "section": "",
    "text": "Bible Society UK claims a “Quiet Revival” based on church attendance data from YouGov surveys in 2018 and 2024. This claim is not supported by the evidence due to multiple critical methodological issues.\n\n\n\n\nStated claim: Church attendance has increased between 2018 and 2024, indicating a “Quiet Revival” of Christianity in the UK.\nKey statistic cited: Increase in weekly church attendance from 7% (2018) to 11% (2024).\n\n\n\n\n\n\nThe 2024 survey data contains contradictory results within the same survey:\n\n\n\nMeasure\nPercentage\n\n\n\n\nBinary question: “Attended in past year”\n24%\n\n\nSum of frequency responses for past year\n26%\n\n\nChange from 2018 frequency measure\n~27% → 26%\n\n\n\nImplication: The binary “attended in past year” (24%) shows a decrease from 2018 (~27%), whilst the frequency measure shows an increase (7% → 11% weekly). These cannot both be true.\nLikely cause: Question order effect. The 2024 survey asks the binary question first, then the frequency question. This priming may artificially inflate some frequency categories whilst deflating others.\n\n\n\n\n\n\n\n\n\n\nSurvey\nQuestion Format\n\n\n\n\n2018\nSingle frequency question only\n\n\n2024\nBinary question FIRST (“Yes/No attended in past year”), THEN frequency question\n\n\n\nProblem: This is a fundamental violation of survey methodology best practices. The binary question primes respondents before they consider frequency, leading to: - Acquiescence bias: Tendency to say “yes” to binary questions - Anchoring effects: Binary framing affects subsequent frequency judgements - Non-comparable measures: 2018 and 2024 are measuring different psychological constructs\nEvidence from literature: Question order effects can produce differences of 5-15 percentage points (Schuman & Presser, 1996).\n\n\n\nMajor demographic changes 2018-2024:\n\n\n\n\n\n\n\n\nGroup\nNumber\nRelevance\n\n\n\n\nUkrainian refugees\n217,000-255,000\nHigher religiosity (Orthodox Christianity)\n\n\nHong Kong BN(O) visa holders\n&gt;163,000\nDifferent religious demographics\n\n\nOther net migration\nSubstantial\nVaries by origin\n\n\n\nThe problem: These groups have different religious attendance patterns from the existing UK population. The surveys show: - Ethnic minority attendance rates differ significantly from White British - Black respondents: 55% attended in past year (2024) vs 23% White - Asian respondents: 12% attended in past year (2024) vs 23% White\nNo evidence that Bible Society has: - Weighted data to account for population composition changes - Performed demographic standardisation - Isolated “behaviour change” from “composition change”\nImplication: An unknown proportion of any increase may simply reflect immigration from more religious populations, NOT revival among existing UK residents.\n\n\n\nWhat the data measures: Physical attendance at church buildings\nWhat “revival” implies: Renewed religious faith, belief, and commitment\nEvidence missing: - No data on belief changes provided - No data on prayer frequency changes - No data on Bible reading changes\n- No data on Christian self-identification changes - No correlation between attendance and belief shown\nPlausible alternative explanations: 1. Cultural attendance: Tourism to cathedrals, cultural events 2. Social attendance: Community activities, concerts, secular events 3. Immigration effect: New arrivals from more religious cultures 4. COVID recovery: Return to pre-pandemic normal (2018 may have been low point)\n\n\n\n\n\n\nSurvey\nWeighted Sample Size\nChange\n\n\n\n\n2018\n19,875\nBaseline\n\n\n2024\n12,455\n-37%\n\n\n\nConcerns: - May indicate sampling frame changes - May indicate methodology changes - May indicate different response patterns - Reduces statistical power (though still adequate)\n\n\n\n\n\n\n\nUsing conservative assumptions (design effect = 1.5 for YouGov panel sampling):\n\n\n\n\n\n\n\n\n\n\n\n\nMeasure\n2018\n2024\nChange\n95% CI\np-value\nEffect Size\n\n\n\n\nWeekly+ attendance\n7%\n11%\n+4pp\n[+2.9pp, +5.1pp]\n&lt;0.001\nh = 0.25 (small)\n\n\nNever attended\n63%\n59%\n-4pp\n[-5.5pp, -2.5pp]\n&lt;0.001\nh = 0.16 (negligible)\n\n\n\nStatistical interpretation: The changes are statistically significant at p&lt;0.001 level.\nPractical interpretation: Effect sizes are small to negligible (Cohen’s h &lt; 0.5). Changes of 4 percentage points, whilst statistically detectable with large samples, are: - Within normal survey variation ranges - Easily explained by measurement artifacts - Too small to constitute “revival”\n\n\n\n\n\n\nMeasure\n2018 (calculated)\n2024\nChange\n\n\n\n\n“Attended in past year”\n~27%\n24%\n-3pp\n\n\n\nWhen using the more comparable measure (the 2024 binary question which should match the 2018 sum), attendance decreased.\n\n\n\n\n\nBoth surveys have excellent statistical power: - Power &gt;0.95 to detect 2pp differences at α=0.05 - Standard errors ~0.5-0.8pp for main estimates - This is NOT a power issue\nThe problem is validity, not precision.\n\n\n\n\nThe observed 4pp increase in weekly attendance could be explained by:\n\nQuestion order effect (3-8pp impact): Binary priming increases reported frequency\nDemographic composition (1-3pp impact): Immigration from more religious populations\nCOVID recovery effect (1-2pp impact): 2018 may have been unusually low\nCultural attendance (1-2pp impact): Non-religious cathedral tourism, concerts\nRegression to mean (1-2pp impact): Random variation around long-term mean\nGenuine behaviour change (0-2pp impact): Actual increase in religious practice\n\nCrucially: Bible Society has provided no analysis to distinguish these.\n\n\n\n\nTo support a “Quiet Revival” claim, we would need:\n\n\n\nConsistent increases across multiple question formats\nDemographic standardisation showing effect persists after composition adjustment\nTriangulation: attendance + belief + Bible reading + prayer all increasing\nLongitudinal tracking showing sustained trend (not just two snapshots)\nCorroboration from independent sources (church membership data, other surveys)\n\n\n\n\n\nQualitative data on motivations for attendance\nAnalysis by denomination/tradition\nRegional variation patterns\nAge cohort analysis (generational vs period effects)\n\n\n\n\n\nFull cross-tabulations published\nWeighting methodology documented\nQuestionnaires provided for comparison\nRaw data made available for independent analysis\n\nBible Society UK has provided NONE of these.\n\n\n\n\n\n\n\n\n“YouGov survey data shows a small increase in self-reported weekly church attendance between 2018 and 2024 (7% to 11%, difference of 4 percentage points with 95% CI [+2.9pp, +5.1pp]). However, this change could be explained by multiple methodological factors including question format differences, demographic composition changes, and measurement error. No evidence is provided for changes in religious belief or commitment.”\n\n\n\n\n\n❌ “A Quiet Revival is happening in UK churches”\n❌ “Christianity is growing in the UK”\n❌ “People are becoming more religious”\n❌ “Church attendance is surging”\n\n\n\n\n\n\n\n\n\nRetract or substantially qualify the “Quiet Revival” claim\nAcknowledge methodological limitations publicly\nPublish full cross-tabulations and raw data\nCommission independent reanalysis by statisticians\n\n\n\n\n\nMaintain consistent question formats across waves\nInclude belief and commitment measures alongside attendance\nPerform demographic standardisation to isolate behaviour changes\nTriangulate with other data sources (church membership, other surveys)\nUse longitudinal panel design (same individuals over time)\nPre-register analysis plan to prevent p-hacking\n\n\n\n\n\n\nThe “Quiet Revival” claim is not supported by the evidence presented. While small statistical changes exist, they are:\n\nInconsistent within the data itself\nConfounded by multiple methodological issues\nSmall in magnitude (effect sizes negligible to small)\nPlausibly explained by non-religious factors\nUntriangulated with belief or commitment measures\n\nThe appropriate conclusion is: “Evidence insufficient to support claims of revival.”\n\n\n\n\n\n\n\nConfidence intervals: Wilson score method with design effect adjustment\nHypothesis tests: Two-proportion z-tests with pooled variance\nEffect sizes: Cohen’s h for proportion differences\nDesign effect: Conservative estimate of 1.5 for YouGov panel\n\n\n\n\n\n\n\nRange\nInterpretation\nExample\n\n\n\n\nh &lt; 0.2\nNegligible\n“Never” change: h=0.16\n\n\n0.2 ≤ h &lt; 0.5\nSmall\nWeekly change: h=0.25\n\n\n0.5 ≤ h &lt; 0.8\nMedium\n-\n\n\nh ≥ 0.8\nLarge\n-\n\n\n\n\n\n\n\nDesign effect of 1.5 assumed (YouGov may differ)\nIndependence of observations assumed (panel nature may violate)\nMissing data assumed MCAR (may not hold)\nWeighting methodology unknown (cannot assess appropriateness)\n\n\n\n\n\n\n\nSchuman, H., & Presser, S. (1996). Questions and Answers in Attitude Surveys. SAGE Publications.\nCohen, J. (1988). Statistical Power Analysis for the Behavioral Sciences (2nd ed.). Routledge.\nKish, L. (1965). Survey Sampling. John Wiley & Sons.\n\n\nDocument prepared: October 2025\nData sources: Bible Society UK / YouGov Surveys 2018 & 2024\nAnalysis: Independent statistical evaluation"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/red-flag-summary.html#executive-summary",
    "href": "docs/tech-specs/bible-society-review/red-flag-summary.html#executive-summary",
    "title": "Bible Society UK “Quiet Revival” Claim - Red Flag Summary",
    "section": "",
    "text": "Bible Society UK claims a “Quiet Revival” based on church attendance data from YouGov surveys in 2018 and 2024. This claim is not supported by the evidence due to multiple critical methodological issues."
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/red-flag-summary.html#the-claim",
    "href": "docs/tech-specs/bible-society-review/red-flag-summary.html#the-claim",
    "title": "Bible Society UK “Quiet Revival” Claim - Red Flag Summary",
    "section": "",
    "text": "Stated claim: Church attendance has increased between 2018 and 2024, indicating a “Quiet Revival” of Christianity in the UK.\nKey statistic cited: Increase in weekly church attendance from 7% (2018) to 11% (2024)."
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/red-flag-summary.html#critical-red-flags-identified",
    "href": "docs/tech-specs/bible-society-review/red-flag-summary.html#critical-red-flags-identified",
    "title": "Bible Society UK “Quiet Revival” Claim - Red Flag Summary",
    "section": "",
    "text": "The 2024 survey data contains contradictory results within the same survey:\n\n\n\nMeasure\nPercentage\n\n\n\n\nBinary question: “Attended in past year”\n24%\n\n\nSum of frequency responses for past year\n26%\n\n\nChange from 2018 frequency measure\n~27% → 26%\n\n\n\nImplication: The binary “attended in past year” (24%) shows a decrease from 2018 (~27%), whilst the frequency measure shows an increase (7% → 11% weekly). These cannot both be true.\nLikely cause: Question order effect. The 2024 survey asks the binary question first, then the frequency question. This priming may artificially inflate some frequency categories whilst deflating others.\n\n\n\n\n\n\n\n\n\n\nSurvey\nQuestion Format\n\n\n\n\n2018\nSingle frequency question only\n\n\n2024\nBinary question FIRST (“Yes/No attended in past year”), THEN frequency question\n\n\n\nProblem: This is a fundamental violation of survey methodology best practices. The binary question primes respondents before they consider frequency, leading to: - Acquiescence bias: Tendency to say “yes” to binary questions - Anchoring effects: Binary framing affects subsequent frequency judgements - Non-comparable measures: 2018 and 2024 are measuring different psychological constructs\nEvidence from literature: Question order effects can produce differences of 5-15 percentage points (Schuman & Presser, 1996).\n\n\n\nMajor demographic changes 2018-2024:\n\n\n\n\n\n\n\n\nGroup\nNumber\nRelevance\n\n\n\n\nUkrainian refugees\n217,000-255,000\nHigher religiosity (Orthodox Christianity)\n\n\nHong Kong BN(O) visa holders\n&gt;163,000\nDifferent religious demographics\n\n\nOther net migration\nSubstantial\nVaries by origin\n\n\n\nThe problem: These groups have different religious attendance patterns from the existing UK population. The surveys show: - Ethnic minority attendance rates differ significantly from White British - Black respondents: 55% attended in past year (2024) vs 23% White - Asian respondents: 12% attended in past year (2024) vs 23% White\nNo evidence that Bible Society has: - Weighted data to account for population composition changes - Performed demographic standardisation - Isolated “behaviour change” from “composition change”\nImplication: An unknown proportion of any increase may simply reflect immigration from more religious populations, NOT revival among existing UK residents.\n\n\n\nWhat the data measures: Physical attendance at church buildings\nWhat “revival” implies: Renewed religious faith, belief, and commitment\nEvidence missing: - No data on belief changes provided - No data on prayer frequency changes - No data on Bible reading changes\n- No data on Christian self-identification changes - No correlation between attendance and belief shown\nPlausible alternative explanations: 1. Cultural attendance: Tourism to cathedrals, cultural events 2. Social attendance: Community activities, concerts, secular events 3. Immigration effect: New arrivals from more religious cultures 4. COVID recovery: Return to pre-pandemic normal (2018 may have been low point)\n\n\n\n\n\n\nSurvey\nWeighted Sample Size\nChange\n\n\n\n\n2018\n19,875\nBaseline\n\n\n2024\n12,455\n-37%\n\n\n\nConcerns: - May indicate sampling frame changes - May indicate methodology changes - May indicate different response patterns - Reduces statistical power (though still adequate)"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/red-flag-summary.html#what-the-data-actually-shows",
    "href": "docs/tech-specs/bible-society-review/red-flag-summary.html#what-the-data-actually-shows",
    "title": "Bible Society UK “Quiet Revival” Claim - Red Flag Summary",
    "section": "",
    "text": "Using conservative assumptions (design effect = 1.5 for YouGov panel sampling):\n\n\n\n\n\n\n\n\n\n\n\n\nMeasure\n2018\n2024\nChange\n95% CI\np-value\nEffect Size\n\n\n\n\nWeekly+ attendance\n7%\n11%\n+4pp\n[+2.9pp, +5.1pp]\n&lt;0.001\nh = 0.25 (small)\n\n\nNever attended\n63%\n59%\n-4pp\n[-5.5pp, -2.5pp]\n&lt;0.001\nh = 0.16 (negligible)\n\n\n\nStatistical interpretation: The changes are statistically significant at p&lt;0.001 level.\nPractical interpretation: Effect sizes are small to negligible (Cohen’s h &lt; 0.5). Changes of 4 percentage points, whilst statistically detectable with large samples, are: - Within normal survey variation ranges - Easily explained by measurement artifacts - Too small to constitute “revival”\n\n\n\n\n\n\nMeasure\n2018 (calculated)\n2024\nChange\n\n\n\n\n“Attended in past year”\n~27%\n24%\n-3pp\n\n\n\nWhen using the more comparable measure (the 2024 binary question which should match the 2018 sum), attendance decreased."
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/red-flag-summary.html#statistical-power-and-precision",
    "href": "docs/tech-specs/bible-society-review/red-flag-summary.html#statistical-power-and-precision",
    "title": "Bible Society UK “Quiet Revival” Claim - Red Flag Summary",
    "section": "",
    "text": "Both surveys have excellent statistical power: - Power &gt;0.95 to detect 2pp differences at α=0.05 - Standard errors ~0.5-0.8pp for main estimates - This is NOT a power issue\nThe problem is validity, not precision."
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/red-flag-summary.html#plausible-explanations-alternative-hypotheses",
    "href": "docs/tech-specs/bible-society-review/red-flag-summary.html#plausible-explanations-alternative-hypotheses",
    "title": "Bible Society UK “Quiet Revival” Claim - Red Flag Summary",
    "section": "",
    "text": "The observed 4pp increase in weekly attendance could be explained by:\n\nQuestion order effect (3-8pp impact): Binary priming increases reported frequency\nDemographic composition (1-3pp impact): Immigration from more religious populations\nCOVID recovery effect (1-2pp impact): 2018 may have been unusually low\nCultural attendance (1-2pp impact): Non-religious cathedral tourism, concerts\nRegression to mean (1-2pp impact): Random variation around long-term mean\nGenuine behaviour change (0-2pp impact): Actual increase in religious practice\n\nCrucially: Bible Society has provided no analysis to distinguish these."
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/red-flag-summary.html#what-would-constitute-strong-evidence",
    "href": "docs/tech-specs/bible-society-review/red-flag-summary.html#what-would-constitute-strong-evidence",
    "title": "Bible Society UK “Quiet Revival” Claim - Red Flag Summary",
    "section": "",
    "text": "To support a “Quiet Revival” claim, we would need:\n\n\n\nConsistent increases across multiple question formats\nDemographic standardisation showing effect persists after composition adjustment\nTriangulation: attendance + belief + Bible reading + prayer all increasing\nLongitudinal tracking showing sustained trend (not just two snapshots)\nCorroboration from independent sources (church membership data, other surveys)\n\n\n\n\n\nQualitative data on motivations for attendance\nAnalysis by denomination/tradition\nRegional variation patterns\nAge cohort analysis (generational vs period effects)\n\n\n\n\n\nFull cross-tabulations published\nWeighting methodology documented\nQuestionnaires provided for comparison\nRaw data made available for independent analysis\n\nBible Society UK has provided NONE of these."
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/red-flag-summary.html#appropriate-vs-inappropriate-conclusions",
    "href": "docs/tech-specs/bible-society-review/red-flag-summary.html#appropriate-vs-inappropriate-conclusions",
    "title": "Bible Society UK “Quiet Revival” Claim - Red Flag Summary",
    "section": "",
    "text": "“YouGov survey data shows a small increase in self-reported weekly church attendance between 2018 and 2024 (7% to 11%, difference of 4 percentage points with 95% CI [+2.9pp, +5.1pp]). However, this change could be explained by multiple methodological factors including question format differences, demographic composition changes, and measurement error. No evidence is provided for changes in religious belief or commitment.”\n\n\n\n\n\n❌ “A Quiet Revival is happening in UK churches”\n❌ “Christianity is growing in the UK”\n❌ “People are becoming more religious”\n❌ “Church attendance is surging”"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/red-flag-summary.html#recommendations-for-bible-society-uk",
    "href": "docs/tech-specs/bible-society-review/red-flag-summary.html#recommendations-for-bible-society-uk",
    "title": "Bible Society UK “Quiet Revival” Claim - Red Flag Summary",
    "section": "",
    "text": "Retract or substantially qualify the “Quiet Revival” claim\nAcknowledge methodological limitations publicly\nPublish full cross-tabulations and raw data\nCommission independent reanalysis by statisticians\n\n\n\n\n\nMaintain consistent question formats across waves\nInclude belief and commitment measures alongside attendance\nPerform demographic standardisation to isolate behaviour changes\nTriangulate with other data sources (church membership, other surveys)\nUse longitudinal panel design (same individuals over time)\nPre-register analysis plan to prevent p-hacking"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/red-flag-summary.html#bottom-line",
    "href": "docs/tech-specs/bible-society-review/red-flag-summary.html#bottom-line",
    "title": "Bible Society UK “Quiet Revival” Claim - Red Flag Summary",
    "section": "",
    "text": "The “Quiet Revival” claim is not supported by the evidence presented. While small statistical changes exist, they are:\n\nInconsistent within the data itself\nConfounded by multiple methodological issues\nSmall in magnitude (effect sizes negligible to small)\nPlausibly explained by non-religious factors\nUntriangulated with belief or commitment measures\n\nThe appropriate conclusion is: “Evidence insufficient to support claims of revival.”"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/red-flag-summary.html#technical-appendix",
    "href": "docs/tech-specs/bible-society-review/red-flag-summary.html#technical-appendix",
    "title": "Bible Society UK “Quiet Revival” Claim - Red Flag Summary",
    "section": "",
    "text": "Confidence intervals: Wilson score method with design effect adjustment\nHypothesis tests: Two-proportion z-tests with pooled variance\nEffect sizes: Cohen’s h for proportion differences\nDesign effect: Conservative estimate of 1.5 for YouGov panel\n\n\n\n\n\n\n\nRange\nInterpretation\nExample\n\n\n\n\nh &lt; 0.2\nNegligible\n“Never” change: h=0.16\n\n\n0.2 ≤ h &lt; 0.5\nSmall\nWeekly change: h=0.25\n\n\n0.5 ≤ h &lt; 0.8\nMedium\n-\n\n\nh ≥ 0.8\nLarge\n-\n\n\n\n\n\n\n\nDesign effect of 1.5 assumed (YouGov may differ)\nIndependence of observations assumed (panel nature may violate)\nMissing data assumed MCAR (may not hold)\nWeighting methodology unknown (cannot assess appropriateness)"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/red-flag-summary.html#references",
    "href": "docs/tech-specs/bible-society-review/red-flag-summary.html#references",
    "title": "Bible Society UK “Quiet Revival” Claim - Red Flag Summary",
    "section": "",
    "text": "Schuman, H., & Presser, S. (1996). Questions and Answers in Attitude Surveys. SAGE Publications.\nCohen, J. (1988). Statistical Power Analysis for the Behavioral Sciences (2nd ed.). Routledge.\nKish, L. (1965). Survey Sampling. John Wiley & Sons.\n\n\nDocument prepared: October 2025\nData sources: Bible Society UK / YouGov Surveys 2018 & 2024\nAnalysis: Independent statistical evaluation"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#project-overview",
    "href": "docs/tech-specs/bible-society-review/overview.html#project-overview",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "Project Overview",
    "text": "Project Overview\nThis document outlines a comprehensive statistical analysis framework to evaluate Bible Society UK’s claim of a “Quiet Revival” based on church attendance data from YouGov surveys conducted in 2018 and 2024."
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#data-sources",
    "href": "docs/tech-specs/bible-society-review/overview.html#data-sources",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "Data Sources",
    "text": "Data Sources\n\n2018 Survey\n\nSample Size: 19,101 (Unweighted: 19,101; Weighted base: 19,875)\nFieldwork Dates: 11th October - 13th November 2018\nKey Question: “Apart from weddings, baptisms/christenings, and funerals how often, if at all, did you go to a church service in the last year?”\n\n\n\n2024 Survey\n\nSample Size: 13,146 (Weighted base: 13,146; some questions 12,455)\nFieldwork Dates: 4th November - 2nd December 2024\nKey Questions:\n\n“Church service” - with response “Yes - in the past year” at 24%\nSame frequency question as 2018 also asked"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#critical-methodological-issues-identified",
    "href": "docs/tech-specs/bible-society-review/overview.html#critical-methodological-issues-identified",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "Critical Methodological Issues Identified",
    "text": "Critical Methodological Issues Identified\n\n1. Survey Design Differences\nProblem: The surveys use different question formats and ordering - 2018: Direct frequency question - 2024: Binary “ever attended” question followed by frequency question - Impact: Question order effects can bias responses (acquiescence bias)\n\n\n2. Population Demographic Changes\nProblem: Significant demographic shifts between 2018-2024 without proper controls\n\nMajor demographic changes:\n\nUkrainian refugees: ~217,000-255,000 (post-February 2022)\nHong Kong BN(O) visa holders: &gt;163,000 (January 2021 - March 2025)\n\nOther immigration changes: Net migration patterns altered significantly\n\nImpact: - Different religious composition of population - Cultural attendance patterns may differ - No demographic weighting provided to account for this\n\n\n\n3. Attendance vs Belief Confound\nProblem: Church attendance does not equal religious commitment or belief - Social attendance (tourism, cultural events, community activities) - Weddings/baptisms/funerals explicitly excluded, but other social events may be included - No measures of: - Religious belief changes - Prayer frequency changes - Bible reading changes - Self-identified Christian population changes"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#key-statistics-to-extract-and-compare",
    "href": "docs/tech-specs/bible-society-review/overview.html#key-statistics-to-extract-and-compare",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "Key Statistics to Extract and Compare",
    "text": "Key Statistics to Extract and Compare\n\nPrimary Attendance Measure\n\n\n\nMetric\n2018\n2024\nChange\n\n\n\n\n“At least once a week”\n7%\n11% (calculated)\n+4pp\n\n\n“At least once a month”\n9%\nTBD\nTBD\n\n\n“Once to few times a year”\n13%\nTBD\nTBD\n\n\n“Never”\n63%\n59%\n-4pp\n\n\n“Net: Ever attended in past year”\n~27%\n24%\n-3pp\n\n\n\nRed Flag: Different questions yield contradictory results\n\n\nDemographic Breakdowns Required\n\nAge groups (18-34, 35-54, 55+)\nEthnicity (White, Ethnic minority subgroups)\nGender\nGeographic distribution (if available)\n\n\n\nBelief Indicators (for triangulation)\n\n“Society could be changed for the better by the message of the Bible”\n\n2018 Net Agree: 28%\n2024: Need to extract\n\nBible reading frequency\nChristian self-identification rates"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#statistical-analysis-plan",
    "href": "docs/tech-specs/bible-society-review/overview.html#statistical-analysis-plan",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "Statistical Analysis Plan",
    "text": "Statistical Analysis Plan\n\nPhase 1: Data Extraction and Cleaning\nObjective: Create machine-readable datasets\n\nExtract raw frequency tables from both surveys\n\nChurch attendance by age/ethnicity/gender\nBelief questions\nSelf-identification data\nDemographic composition\n\nStandardise response categories\n\nMap 2024 responses to 2018 categories\nCreate comparable time periods\nHandle “Don’t know” / “Not answered” consistently\n\nCalculate sample sizes and weights\n\nDocument weighting methodology\nCheck for differential non-response\nCalculate effective sample sizes for subgroups\n\n\n\n\nPhase 2: Descriptive Statistics and Red Flag Detection\n\n2.1 Internal Consistency Checks\n# Check if responses within 2024 survey are consistent\n# Question 1: \"Ever attended in past year\" = 24%\n# Question 2: Sum of all frequency categories for \"past year\"\n# These should match. If they don't, investigate why.\n\n\n2.2 Sample Composition Comparison\n# Compare demographic composition 2018 vs 2024\n# - Age distribution\n# - Ethnic composition  \n# - Gender balance\n# Test whether shifts are statistically significant\n\n\n2.3 Response Pattern Analysis\n# Check for:\n# - Acquiescence bias (more \"yes\" in 2024 due to binary question first?)\n# - Social desirability bias  \n# - Satisficing (selecting first acceptable response)\n\n\n\nPhase 3: Inferential Statistical Analysis\n\n3.1 Confidence Intervals for Point Estimates\n# For each year, calculate 95% CI for:\n# - % attending at least weekly\n# - % attending at least monthly\n# - % never attending\n\n# Design effect correction for YouGov panel sampling\n# Conservative estimate: deff = 1.5 to 2.0\nFormula: \\[\nCI = \\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n_{eff}}}\n\\]\nwhere \\(n_{eff} = \\frac{n}{deff}\\)\n\n\n3.2 Hypothesis Testing\nNull Hypothesis: No change in church attendance between 2018 and 2024\nTest 1: Two-sample proportion test\n# For each attendance category\n# H0: p_2024 = p_2018\n# HA: p_2024 ≠ p_2018\nTest 2: Chi-square test for independence\n# Test whether attendance distribution has changed\n# across full frequency spectrum\nTest 3: Logistic regression\n# Model: attended_weekly ~ year + age + ethnicity + gender\n# This isolates \"year effect\" from demographic shifts\n\n\n3.3 Effect Size Calculations\n# Beyond statistical significance, calculate:\n# - Cohen's h (for proportion differences)\n# - Cramer's V (for categorical associations)\n# - Relative risk / odds ratios\n\n# Example: \nh = 2 * (arcsin(sqrt(p1)) - arcsin(sqrt(p2)))\n\n\n\nPhase 4: Demographic Stratification Analysis\n\n4.1 Age-stratified Analysis\nRationale: Younger cohorts may have different patterns\n# Separate analysis for:\n# - 18-34 year olds\n# - 35-54 year olds  \n# - 55+ year olds\n\n# Calculate:\n# - Within-group changes 2018→2024\n# - 95% CIs for each stratum\n# - Test for interaction effects (does change vary by age?)\n\n\n4.2 Ethnicity-stratified Analysis\nRationale: Immigration changes ethnic composition\n# Separate analysis for:\n# - White British\n# - Black (potential Ukrainian/HK immigrants)\n# - Asian\n# - Mixed\n# - Other\n\n# Key calculations:\n# - Attendance rates within each ethnic group\n# - Population share changes 2018→2024\n# - Compositional effect calculation\nCompositional Effect Formula: \\[\n\\Delta_{composition} = \\sum_{i} (w_{i,2024} - w_{i,2018}) \\times p_{i,2018}\n\\]\nwhere \\(w_i\\) is the population weight for group \\(i\\) and \\(p_i\\) is attendance rate.\n\n\n4.3 Demographic Standardisation\n# Direct standardisation to 2018 population structure\n# Shows what 2024 rates would be with 2018 demographics\n\n# Indirect standardisation to 2024 population structure  \n# Shows what 2018 rates would be with 2024 demographics\n\n# Compare observed 2024 rate to both standardised estimates\n\n\n\nPhase 5: Triangulation with Belief Measures\n\n5.1 Belief-Behaviour Correlation\n# Within each year, calculate:\n# - Correlation between attendance and \"Bible can change society\"\n# - Correlation between attendance and Bible reading\n# - Correlation between attendance and Christian identity\n\n# Compare correlations across years\n# If attendance↑ but beliefs→ or ↓, suggests non-religious attendance\n\n\n5.2 Latent Class Analysis (if data permits)\n# Identify unobserved groups:\n# - \"Cultural attenders\" (attend but low belief)\n# - \"Committed believers\" (attend + high belief)  \n# - \"Non-attenders\"\n\n# Test whether proportion in each class changed\n\n\n\nPhase 6: Sensitivity Analysis and Robustness Checks\n\n6.1 Weighting Sensitivity\n# Re-run analyses with:\n# - No weights\n# - Alternative weighting schemes\n# - Trimmed weights (cap extreme values)\n\n# Check if substantive conclusions change\n\n\n6.2 Missing Data Handling\n# Original: Exclude \"Don't know\" / \"Not answered\"\n# Alternative: Multiple imputation\n# Alternative: Worst/best case bounds\n\n# Calculate range of plausible estimates\n\n\n6.3 Design Effect Sensitivity\n# Vary assumed design effect from 1.0 to 3.0\n# Show how confidence intervals change\n# Establish whether \"revival\" claim survives conservative assumptions"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#visualisation-plan",
    "href": "docs/tech-specs/bible-society-review/overview.html#visualisation-plan",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "Visualisation Plan",
    "text": "Visualisation Plan\n\n1. Primary Findings Visualisations\n\n1.1 Church Attendance Frequency Comparison\n# Stacked bar chart or side-by-side bars\n# X-axis: Attendance frequency categories\n# Y-axis: Percentage\n# Colours: 2018 (one colour), 2024 (another)\n# Error bars: 95% confidence intervals\n# Annotations: Sample sizes, significance tests\n\n\n1.2 Trend by Demographic Group\n# Faceted plots showing:\n# - Separate panel for each age group\n# - Separate panel for each ethnic group\n# Lines connecting 2018→2024 for each attendance level\n# Shaded confidence regions\n\n\n1.3 Compositional Shift Decomposition\n# Stacked area chart or waterfall plot showing:\n# - 2018 overall rate\n# - Effect of demographic composition change\n# - Effect of within-group behaviour change\n# - 2024 overall rate\n\n# This visualises how much of any change is \"real\" vs demographic\n\n\n\n2. Diagnostic Visualisations\n\n2.1 Sample Composition Comparison\n# Population pyramid style chart\n# 2018 composition on left, 2024 on right\n# Highlight significant demographic shifts\n\n\n2.2 Internal Consistency Check\n# Scatter plot:\n# X-axis: Sum of frequency responses for \"past year\"\n# Y-axis: \"Attended in past year\" binary question response\n# Should fall on identity line\n# Deviations indicate measurement issues\n\n\n2.3 Belief-Attendance Correlation\n# Scatter plot with:\n# X-axis: Belief measure (e.g., \"Bible can change society\")\n# Y-axis: Attendance frequency\n# Separate points/colours for 2018 and 2024\n# Trend lines\n\n\n\n3. Communication Visualisations\n\n3.1 “Evidence Quality” Dashboard\n# Traffic light system showing:\n# - Sample size adequacy: GREEN\n# - Demographic comparability: RED/AMBER\n# - Question consistency: RED\n# - Statistical significance: (depends on analysis)\n# - Effect size: (depends on analysis)\n# - Triangulation support: (depends on analysis)\n\n\n3.2 Uncertainty Fan Chart\n# Central estimate with expanding confidence bands\n# Showing uncertainty grows with more conservative assumptions\n# Highlights fragility of \"revival\" claim"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#expected-outputs",
    "href": "docs/tech-specs/bible-society-review/overview.html#expected-outputs",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "Expected Outputs",
    "text": "Expected Outputs\n\n1. Data Files\n\nchurch_attendance_2018.csv - Clean, analysis-ready 2018 data\nchurch_attendance_2024.csv - Clean, analysis-ready 2024 data\n\ndemographic_composition.csv - Population composition both years\nbelief_indicators.csv - Triangulation variables\n\n\n\n2. Analysis Scripts\n\n01_data_extraction.R - Extract from PDFs/text\n02_data_cleaning.R - Standardise and validate\n03_descriptive_stats.R - Sample descriptions, red flags\n04_inference.R - Hypothesis tests, CIs, effect sizes\n05_demographics.R - Stratified analyses, standardisation\n06_triangulation.R - Belief-behaviour analyses\n07_sensitivity.R - Robustness checks\n08_visualisations.R - All plots and charts\n\n\n\n3. Results Files\n\nsummary_statistics.csv - All point estimates with CIs\nhypothesis_tests.csv - All test results with p-values\neffect_sizes.csv - Practical significance measures\ndemographic_breakdown.csv - Stratified results\n\n\n\n4. Report Document\n\nQuarto markdown document integrating:\n\nMethodology assessment\nStatistical findings\nVisualisations\nCritical evaluation of “revival” claim\nRecommendations for better measurement"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#key-statistical-considerations",
    "href": "docs/tech-specs/bible-society-review/overview.html#key-statistical-considerations",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "Key Statistical Considerations",
    "text": "Key Statistical Considerations\n\nPower Analysis\nWith n≈19,000 (2018) and n≈13,000 (2024), we have power &gt;0.95 to detect differences of 2 percentage points at α=0.05. This is not a power issue.\n\n\nMultiple Comparisons\nWith many subgroup analyses, apply Bonferroni or FDR correction: \\[\n\\alpha_{adjusted} = \\frac{\\alpha}{k}\n\\] where k is number of comparisons.\n\n\nPractical vs Statistical Significance\nA 2-4 percentage point change may be statistically significant but: - Is it practically meaningful for “revival” claim? - Is it within measurement error margins? - Could it be explained by demographic shifts alone?\n\n\nCausal Inference Limitations\nThis is observational data. We cannot establish: - Why attendance might have changed - Whether changes are sustained - Direction of causality (did beliefs cause attendance or vice versa?)"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#critical-evaluation-framework",
    "href": "docs/tech-specs/bible-society-review/overview.html#critical-evaluation-framework",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "Critical Evaluation Framework",
    "text": "Critical Evaluation Framework\n\nClaims to Test\nClaim 1: Church attendance increased between 2018 and 2024 - Evidence needed: Statistically significant increase in comparable measures - Red flags: Different question formats, inconsistent internal responses\nClaim 2: This represents a “Quiet Revival” of Christian faith - Evidence needed: Attendance increase + belief increase + commitment increase - Red flags: No belief change data shown, demographic confounding not addressed\nClaim 3: UK is experiencing renewed religious interest - Evidence needed: Sustained trend, corroboration from other sources - Red flags: Single comparison point, no triangulation with church membership data, no accounting for immigration effects\n\n\nPlausible Alternative Explanations\n\nSampling variation: Natural fluctuation within margin of error\nDemographic composition: Immigration from more religious populations\nQuestion order effects: Binary question before frequency question biases responses upward\nSocial attendance increase: Non-religious attendance (cultural events, tourism) increased\nMeasurement error: Different methodologies yield different (contradictory) results\nRegression to the mean: 2018 might have been unusually low"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#r-package-requirements",
    "href": "docs/tech-specs/bible-society-review/overview.html#r-package-requirements",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "R Package Requirements",
    "text": "R Package Requirements\n# Data manipulation\nlibrary(tidyverse)\nlibrary(data.table)\n\n# Statistical inference  \nlibrary(survey)        # Complex survey design\nlibrary(srvyr)         # Survey design with tidyverse\nlibrary(broom)         # Tidy statistical outputs\nlibrary(infer)         # Modern inference\n\n# Effect sizes\nlibrary(effectsize)\nlibrary(es calc)\n\n# Visualisation\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(ggtext)\nlibrary(scales)\n\n# Tables\nlibrary(gt)\nlibrary(gtsummary)\nlibrary(kableExtra)\n\n# Sensitivity analysis\nlibrary(sensemakr)\n\n# Reporting\nlibrary(quarto)\nlibrary(rmarkdown)"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#timeline-and-priorities",
    "href": "docs/tech-specs/bible-society-review/overview.html#timeline-and-priorities",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "Timeline and Priorities",
    "text": "Timeline and Priorities\n\nPriority 1 (Essential)\n\nExtract and clean raw data\nCalculate basic point estimates with CIs\nTest whether differences are statistically significant\nCreate primary comparison visualisations\nDocument all red flags and limitations\n\n\n\nPriority 2 (Important)\n\nDemographic stratified analyses\nStandardisation to account for population changes\nBelief-behaviour triangulation\nEffect size calculations\nComprehensive visualisation suite\n\n\n\nPriority 3 (Additional)\n\nSensitivity analyses\nLatent class analysis\nDetailed robustness checks\nExtended discussion document"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#reporting-recommendations",
    "href": "docs/tech-specs/bible-society-review/overview.html#reporting-recommendations",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "Reporting Recommendations",
    "text": "Reporting Recommendations\n\nWhat the data DOES show:\n\nPrecise point estimates for attendance rates in both years\nStatistical significance of any differences observed\nMagnitude of changes with appropriate uncertainty\nDemographic composition has shifted\nQuestion formats differed between surveys\n\n\n\nWhat the data DOES NOT show:\n\nCausal reasons for any changes\nWhether changes represent genuine religious revival\nSustainability of any trends\nBelief changes accompanying attendance changes\nEffects properly adjusted for demographic composition\n\n\n\nAppropriate Conclusions:\n\n“There is evidence that reported church attendance frequency increased slightly between 2018 and 2024”\n“However, this could be explained by [demographic changes / measurement differences / question order effects]”\n“No evidence is provided for changes in religious belief or commitment”\n“The term ‘revival’ is not supported by the data presented”\n\n\n\nInappropriate Conclusions:\n\n“A Quiet Revival is happening” (overstatement)\n“Christianity is growing in the UK” (not measured)\n“People are becoming more religious” (belief not measured)\n“This is definitely due to [specific cause]” (causality not established)"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#next-steps",
    "href": "docs/tech-specs/bible-society-review/overview.html#next-steps",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "Next Steps",
    "text": "Next Steps\n\nData Extraction: Parse the 2018 images via OCR and 2024 text file\nInitial Analysis: Run Priority 1 analyses\nRed Flag Report: Document all methodological issues found\nPreliminary Results: Create summary statistics and main visualisations\nFull Report: Comprehensive Quarto document with all analyses\n\nThis framework provides rigorous evaluation of Bible Society UK’s claims while maintaining scientific integrity and appropriate scepticism."
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#what-has-been-completed",
    "href": "docs/tech-specs/bible-society-review/overview.html#what-has-been-completed",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "What Has Been Completed",
    "text": "What Has Been Completed\n\n✅ Phase 1: Planning and Red Flag Detection\n\nComprehensive Analysis Plan (ANALYSIS_PLAN.md)\n\n6-phase statistical framework\nDetailed methodology for each analysis type\nVisualisation specifications\nR package requirements\nTimeline and priorities\n\nRed Flag Summary (RED_FLAG_SUMMARY.md)\n\nExecutive summary of critical issues\n5 major red flags identified and explained\nStatistical interpretation of preliminary findings\nRecommendations for Bible Society UK\n\nInitial Data Extraction (church_attendance_extracted.csv)\n\nKey statistics from both surveys\nStructured in analysis-ready format\nDemographic breakdowns where available\n\nAnalysis Script Template (01_initial_analysis.R)\n\nComplete red flag detection code\nConfidence interval calculations\nHypothesis testing framework\nEffect size computations\nPreliminary visualisations"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#what-you-need-to-do-next",
    "href": "docs/tech-specs/bible-society-review/overview.html#what-you-need-to-do-next",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "What You Need to Do Next",
    "text": "What You Need to Do Next\n\nImmediate Priority: Complete Data Extraction\nThe 2018 PDF is actually a ZIP file containing JPEG images, and the 2024 file is plain text. You need to:\n\nFor 2018 Data:\n# Extract the images\ncd /mnt/project\nunzip BibleSoc_Results_2018.pdf -d BibleSoc_2018_images\n\n# Option 1: Use OCR (if you need exact extraction)\n# Install tesseract if not available\nsudo apt-get install tesseract-ocr\n\n# Run OCR on each image\nfor img in BibleSoc_2018_images/*.jpeg; do\n    tesseract \"$img\" \"${img%.jpeg}\" -l eng\ndone\n\n# Option 2: Manual extraction from project knowledge search results\n# The search results already show the key tables - you can extract these\n# manually into CSV format\n\n\nFor 2024 Data:\n# The file is already plain text\n# Parse it programmatically or manually extract tables\ncat /mnt/project/BibleSoc_Results_2024.pdf | grep -A 20 \"Church service\"\n\n\n\nCritical Tables to Extract\nYou need complete cross-tabulations for:\n\nChurch attendance frequency\n\nBy age group (18-34, 35-54, 55+)\nBy ethnicity (White, Mixed, Asian, Black, Other)\nBy gender\nBy Christian denomination (among Christians only)\n\nBelief measures (2018 only available so far):\n\n“Society could be changed for the better by the message of the Bible”\nBible reading frequency\nBy all demographic breakdowns\n\nReligious identification (2018):\n\nChristian denomination\nNon-religious identification\nBy demographics\n\nSample composition:\n\nWeighted vs unweighted bases\nDemographic distributions"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#recommended-workflow",
    "href": "docs/tech-specs/bible-society-review/overview.html#recommended-workflow",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "Recommended Workflow",
    "text": "Recommended Workflow\n\nStep 1: Complete Data Extraction (1-2 hours)\nCreate separate CSV files:\ndata/\n  ├── 2018_attendance_full.csv\n  ├── 2018_beliefs.csv\n  ├── 2018_demographics.csv\n  ├── 2024_attendance_full.csv\n  ├── 2024_beliefs.csv (if available)\n  └── 2024_demographics.csv\n\n\nStep 2: Run Initial Analysis Script (30 minutes)\n# In RStudio or R console\nsource(\"01_initial_analysis.R\")\n\n# This will:\n# - Perform red flag checks\n# - Calculate confidence intervals\n# - Run hypothesis tests\n# - Create preliminary visualisations\n\n\nStep 3: Demographic Standardisation (2-3 hours)\nCreate 02_demographic_standardisation.R:\n# Pseudo-code structure:\n\n# 1. Calculate attendance rates within each demographic group\n#    (age × ethnicity × gender cells)\n\n# 2. Calculate population weights for each group in both years\n\n# 3. Direct standardisation:\n#    - Apply 2018 population weights to 2024 attendance rates\n#    - Shows: \"What would 2024 attendance be with 2018 demographics?\"\n\n# 4. Indirect standardisation:\n#    - Apply 2024 population weights to 2018 attendance rates\n#    - Shows: \"What would 2018 attendance be with 2024 demographics?\"\n\n# 5. Decompose change into:\n#    - Compositional effect (demographic shifts)\n#    - Behavioural effect (actual change in attendance behaviour)\n\n\nStep 4: Age-Stratified Analysis (1-2 hours)\nCreate 03_age_stratified_analysis.R:\n# For each age group separately:\n# - Calculate 2018 vs 2024 changes\n# - Test statistical significance within each stratum\n# - Calculate effect sizes\n# - Check if \"revival\" is consistent across ages\n#   (or limited to specific cohorts)\n\n\nStep 5: Create Comprehensive Visualisations (2-3 hours)\nCreate 04_visualisations.R with:\n\nComparison charts (bar charts with CIs)\nDemographic decomposition (waterfall or stacked area)\nForest plots (showing all subgroup effects)\nBelief-attendance correlations (if 2024 belief data available)\nUncertainty visualisations (fan charts showing sensitivity)\n\n\n\nStep 6: Write Full Quarto Report (3-4 hours)\nCreate bible_society_analysis.qmd:\n---\ntitle: \"Evaluation of Bible Society UK's 'Quiet Revival' Claim\"\nsubtitle: \"Statistical Analysis of Church Attendance Surveys 2018-2024\"\nauthor: \"Your Name\"\ndate: today\nformat:\n  html:\n    code-fold: true\n    toc: true\n    toc-depth: 3\n---\nInclude sections: 1. Executive Summary 2. Background and Claims 3. Methodology 4. Red Flags Identified 5. Statistical Analysis Results 6. Demographic Analysis 7. Limitations 8. Conclusions 9. Recommendations 10. Technical Appendix"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#key-questions-to-answer",
    "href": "docs/tech-specs/bible-society-review/overview.html#key-questions-to-answer",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "Key Questions to Answer",
    "text": "Key Questions to Answer\n\nMethodological Questions:\n\nAre the 2024 responses internally consistent?\n\nDoes frequency sum = binary response?\nIf not, what’s the discrepancy?\n\nHow much of any change is demographic composition?\n\nCalculate compositional effect\nCalculate behavioural effect within groups\n\nIs the change consistent across demographics?\n\nAge groups\nEthnic groups\nGender\n\n\n\n\nSubstantive Questions:\n\nIs there evidence of belief changes?\n\nCompare 2018 belief measures with 2024 (if available)\nCheck belief-attendance correlations\n\nCould immigration explain the changes?\n\nCompare ethnic minority vs White British changes\nEstimate effect of 217k-255k Ukrainian + 163k+ HK immigrants\n\nWhat is the range of plausible estimates?\n\nSensitivity analysis with different assumptions\nBest case and worst case scenarios"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#expected-timeline",
    "href": "docs/tech-specs/bible-society-review/overview.html#expected-timeline",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "Expected Timeline",
    "text": "Expected Timeline\n\n\n\nTask\nTime\nPriority\n\n\n\n\nComplete data extraction\n1-2 hrs\nHigh\n\n\nRun initial analysis script\n0.5 hrs\nHigh\n\n\nRed flag documentation\n1 hr\nHigh\n\n\nDemographic standardisation\n2-3 hrs\nHigh\n\n\nAge-stratified analysis\n1-2 hrs\nMedium\n\n\nFull visualisation suite\n2-3 hrs\nMedium\n\n\nQuarto report writing\n3-4 hrs\nMedium\n\n\nSensitivity analyses\n1-2 hrs\nLow\n\n\nFinal review and polish\n1-2 hrs\nLow\n\n\nTOTAL\n12-19 hrs\n-"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#output-structure",
    "href": "docs/tech-specs/bible-society-review/overview.html#output-structure",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "Output Structure",
    "text": "Output Structure\nYour final project should have:\nproject/\n├── data/\n│   ├── raw/\n│   │   ├── BibleSoc_2018_images/ (extracted JPEGs)\n│   │   └── BibleSoc_2024.txt (plain text)\n│   └── processed/\n│       ├── church_attendance_extracted.csv\n│       ├── 2018_attendance_full.csv\n│       ├── 2018_beliefs.csv\n│       ├── 2024_attendance_full.csv\n│       └── demographics.csv\n├── scripts/\n│   ├── 01_initial_analysis.R\n│   ├── 02_demographic_standardisation.R\n│   ├── 03_age_stratified_analysis.R\n│   ├── 04_visualisations.R\n│   └── 05_sensitivity_analysis.R\n├── outputs/\n│   ├── plots/\n│   │   ├── plot_01_point_estimates_ci.png\n│   │   ├── plot_02_frequency_distribution.png\n│   │   ├── plot_03_demographic_decomposition.png\n│   │   └── ... (more plots)\n│   ├── tables/\n│   │   ├── summary_statistics.csv\n│   │   ├── hypothesis_tests.csv\n│   │   └── effect_sizes.csv\n│   └── report/\n│       └── bible_society_analysis.html\n├── docs/\n│   ├── ANALYSIS_PLAN.md\n│   ├── RED_FLAG_SUMMARY.md\n│   └── METHODOLOGY_NOTES.md\n└── bible_society_analysis.qmd (main report source)"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#quick-start-commands",
    "href": "docs/tech-specs/bible-society-review/overview.html#quick-start-commands",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "Quick Start Commands",
    "text": "Quick Start Commands\nOnce you have the data extracted, run:\n# Set up your R environment\ninstall.packages(c(\"tidyverse\", \"survey\", \"effectsize\", \"gt\", \n                   \"patchwork\", \"scales\"))\n\n# Load and check your data\nattendance &lt;- read_csv(\"data/processed/church_attendance_extracted.csv\")\nglimpse(attendance)\n\n# Run the initial analysis\nsource(\"scripts/01_initial_analysis.R\")\n\n# Review outputs\nlist.files(\"outputs/plots/\")"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#critical-success-factors",
    "href": "docs/tech-specs/bible-society-review/overview.html#critical-success-factors",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "Critical Success Factors",
    "text": "Critical Success Factors\nTo produce a compelling analysis:\n\nBe thorough with data extraction (garbage in = garbage out)\nBe transparent about all assumptions\nBe fair to Bible Society (acknowledge what they did right)\nBe critical of methodological flaws (that’s the point)\nBe clear about uncertainty (show confidence intervals everywhere)\nBe visual (good plots &gt; tables of numbers)\nBe precise in language (distinguish statistical vs practical significance)"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#what-makes-this-analysis-strong",
    "href": "docs/tech-specs/bible-society-review/overview.html#what-makes-this-analysis-strong",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "What Makes This Analysis Strong",
    "text": "What Makes This Analysis Strong\nYour analysis will be credible because:\n\nPre-specified plan (ANALYSIS_PLAN.md shows you’re not p-hacking)\nMultiple approaches (CIs, hypothesis tests, effect sizes, standardisation)\nDemographic adjustment (most critical missing piece in Bible Society’s analysis)\nTriangulation (checking consistency across measures)\nSensitivity analysis (showing robustness of conclusions)\nFull transparency (all code and data documented)\nAppropriate scepticism (you’re not claiming more than the data supports)"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#when-youre-stuck",
    "href": "docs/tech-specs/bible-society-review/overview.html#when-youre-stuck",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "When You’re Stuck",
    "text": "When You’re Stuck\nIf you need help:\n\nStatistical questions: Refer to ANALYSIS_PLAN.md for methods\nCode issues: Check R script comments for explanations\nInterpretation: RED_FLAG_SUMMARY.md has examples\nData extraction: Use project_knowledge_search tool on the PDFs"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#final-deliverables",
    "href": "docs/tech-specs/bible-society-review/overview.html#final-deliverables",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "Final Deliverables",
    "text": "Final Deliverables\nWhen complete, you should have:\n\n✅ Complete data extraction (CSV files)\n✅ All analysis scripts (commented and reproducible)\n✅ Comprehensive visualisations (publication quality)\n✅ Full Quarto report (HTML with embedded plots)\n✅ Executive summary (1-page PDF)\n✅ Technical appendix (detailed methodology)\n\nThe goal: A professional-quality statistical analysis that definitively shows whether Bible Society UK’s “Quiet Revival” claim is supported by the data.\nBased on the preliminary analysis, your conclusion will likely be: “The claim is not supported due to multiple methodological confounds, small effect sizes, and lack of triangulation with belief measures.”"
  },
  {
    "objectID": "docs/tech-specs/bible-society-review/overview.html#good-luck",
    "href": "docs/tech-specs/bible-society-review/overview.html#good-luck",
    "title": "Bible Society “Quiet Revival” Claim - Analytical Framework",
    "section": "Good Luck!",
    "text": "Good Luck!\nYou have a solid foundation. The analysis plan is comprehensive, the red flags are clearly documented, and you have working R code to build from.\nFocus on: 1. Getting the full data extracted 2. Running the demographic standardisation (this is the killer blow to the “revival” claim) 3. Creating clear, compelling visualisations 4. Writing a fair but critical report\nThe evidence is on your side. Bible Society UK’s claim is statistically weak and methodologically flawed. Your job is to demonstrate this clearly and convincingly."
  },
  {
    "objectID": "docs/routing-system.html",
    "href": "docs/routing-system.html",
    "title": "Navigation Routing System Documentation",
    "section": "",
    "text": "This project uses an automated navigation generation system to build the website’s navigation menu from the directory structure. Instead of manually maintaining hardcoded paths in _quarto.yml, the system scans the src/ directory and automatically generates navigation links based on:\n\nDirectory structure - Folders become menu categories\nFile locations - .qmd files become menu items\nYAML metadata - Titles are extracted from each file’s front matter\n\n\n\n\n\n\nThe navigation is generated by scripts/generate_nav.R, which:\n\nScans the src/ directory for all .qmd files\nExtracts titles from YAML front matter headers\nBuilds a hierarchical navigation structure matching the directory tree\nUpdates _quarto.yml with the generated navigation\n\n\n\n\nThe routing system follows this mapping:\nsrc/\n├── teaching-stats/           → \"Teaching Stats\" menu\n│   └── core-concepts/        → \"Core Concepts\" submenu\n│       ├── *.qmd files       → Individual menu items\n│\n└── blog/                     → \"Blog\" menu\n    ├── paper-reviews/        → \"Paper Reviews\" submenu\n    │   ├── index.qmd         → \"Overview\" menu item\n    │   └── */                → Nested submenus\n    └── essays/               → \"Essays\" submenu\n\n\n\n\n\n\nIncludes: All .qmd files in src/ and subdirectories\nExcludes:\n\nFiles named template.qmd (templates are not content)\nFiles named index.qmd (handled separately as “Overview” items)\n\n\n\n\n\nTitles are determined in priority order:\n\nYAML title: field - Extracted from file’s front matter (preferred)\nFilename - Fallback: filename converted to title case\n\nExample YAML header:\n---\ntitle: \"Central Limit Theorem\"\nsubtitle: \"Building an Intuition...\"\n---\n\n\n\nFile paths are converted to navigation href attributes:\n\nSource: src/teaching-stats/core-concepts/central-limit-theorem.qmd\nHref: src/teaching-stats/core-concepts/central-limit-theorem.qmd\nPaths are relative to the project root\n\n\n\n\nThe script creates nested menus following these rules:\n\nTop-level directories under src/ become main menu categories\nSubdirectories become submenus within their parent category\nFiles in directories become menu items\nindex.qmd files become “Overview” items at the top of their submenu\nEmpty directories show empty menus (ready for future content)\n\n\n\n\n\n\nFiles named index.qmd are treated specially: - Not included in the main file listing - Added as the first item in their directory’s menu with text “Overview” - Example: src/blog/paper-reviews/index.qmd → Menu item “Overview”\n\n\n\nNested directories create nested menus: - src/blog/paper-reviews/chatbot-mental-health/ → “Chatbot Mental Health” submenu - Files inside become items in that submenu\n\n\n\nEmpty directories (like src/blog/essays/) create empty menus:\n- text: Essays\n  menu: []\n\n\n\n\n\n\n\n\nRun the script after adding, moving, or renaming content files:\nRscript scripts/generate_nav.R\nOr from R:\nsource(\"scripts/generate_nav.R\")\n\n\n\nThe script only updates the navbar section of _quarto.yml. All other configuration is preserved: - project settings - website title, site-url - format options - editor settings\n\n\n\n\nCreate a new page:\ncp src/teaching-stats/core-concepts/template.qmd \\\n   src/teaching-stats/core-concepts/my-new-concept.qmd\nEdit the file with your content and proper YAML header:\n---\ntitle: \"My New Concept\"\n---\nGenerate navigation:\nRscript scripts/generate_nav.R\nResult: The new page automatically appears in the navigation under “Teaching Stats → Core Concepts”\n\n\n\n\n\n\n\nHome (index.qmd)\n├── Teaching Stats\n│   └── Core Concepts\n│       ├── Central Limit Theorem\n│       └── Degrees of Freedom\n├── Blog\n│   ├── Paper Reviews\n│   │   ├── Overview (index.qmd)\n│   │   └── Chatbot Mental Health\n│   │       └── Chatbot Effects On Postpartum Mental Health\n│   └── Essays (empty)\n└── About (about.qmd)\n\n\n\nAll paths in navigation are relative to the project root:\n\n\n\n\n\n\n\nNavigation Item\nFile Path\n\n\n\n\nCentral Limit Theorem\nsrc/teaching-stats/core-concepts/central-limit-theorem.qmd\n\n\nPaper Reviews Overview\nsrc/blog/paper-reviews/index.qmd\n\n\nChatbot Paper\nsrc/blog/paper-reviews/chatbot-mental-health/chatbot-postpartum-mental-health.qmd\n\n\n\n\n\n\n\n\n\nThe script can be customised by editing scripts/generate_nav.R:\n\n\nFiles matching these patterns are excluded from navigation:\nexclude_patterns &lt;- c(\"template\\\\.qmd$\", \"index\\\\.qmd$\")\nTo exclude additional files (e.g., drafts), add patterns:\nexclude_patterns &lt;- c(\n  \"template\\\\.qmd$\",\n  \"index\\\\.qmd$\",\n  \"draft-.*\\\\.qmd$\"  # Exclude files starting with \"draft-\"\n)\n\n\n\nChange the source directory (default: src):\nsrc_dir &lt;- \"content\"  # Use \"content\" instead of \"src\"\n\n\n\nMenu labels are automatically generated from directory names: - core-concepts → “Core Concepts” (hyphens to spaces, title case) - paper-reviews → “Paper Reviews” - chatbot-mental-health → “Chatbot Mental Health”\nTo customise menu labels, modify the build_nav() function’s display name formatting.\n\n\n\n\n\n\n\nProblem: Changes to files don’t appear in navigation\nSolution: 1. Ensure file is in src/ directory 2. Run Rscript scripts/generate_nav.R again 3. Check file has valid YAML header with title: field 4. Verify file doesn’t match exclude patterns\n\n\n\nProblem: A file exists but doesn’t appear in navigation\nPossible causes: - File matches an exclude pattern (e.g., template.qmd) - File has invalid YAML header (script falls back to filename) - File is outside src/ directory\nSolution: Check file location and YAML header format.\n\n\n\nProblem: Navigation shows filename instead of title\nSolution: Ensure your .qmd file has a valid YAML header:\n---\ntitle: \"Your Page Title\"\n---\n\n\n\nProblem: Nested menus not appearing correctly\nSolution: - Ensure subdirectories contain .qmd files (not just empty folders) - Check that paths are correctly structured - Verify index.qmd files exist if you want “Overview” items\n\n\n\n\n\n\n\nUse descriptive directory names: They become menu labels (hyphens become spaces)\nUse meaningful filenames: Used as fallback if YAML title is missing\nAlways include YAML titles: Better control over navigation labels\n\n\n\n\nsrc/\n├── teaching-stats/\n│   ├── core-concepts/      ← Clear category name\n│   ├── advanced-topics/    ← Future expansion ready\n│   └── tutorials/          ← Organised by type\n└── blog/\n    ├── paper-reviews/\n    └── essays/\n\n\n\nAlways include a title: field:\n---\ntitle: \"Descriptive Page Title\"\nsubtitle: \"Optional subtitle\"\n---\n\n\n\n\nRun after: Adding new pages, moving files, renaming directories\nRun before: Committing navigation changes\nCI/CD: Consider adding to your build pipeline if navigation must stay in sync\n\n\n\n\n\n\n\nThe script requires: - yaml package (for YAML parsing) - fs package (for filesystem operations)\nInstall with:\ninstall.packages(c(\"yaml\", \"fs\"))\n\n\n\nAll paths are: - Relative to project root (where _quarto.yml is located) - Preserved exactly as they appear in the filesystem - No transformation applied (paths match file locations)\n\n\n\nThe script uses yaml::write_yaml() which: - Preserves existing YAML structure - Only updates the navbar section - Maintains formatting preferences (strings quoted vs unquoted)\n\n\n\n\nPotential improvements to consider:\n\nSorting options: Alphabetical vs. date-based ordering\nCustom menu labels: Override auto-generated names via config file\nWeight/priority: Order items manually if needed\nActive state detection: Highlight current page in navigation\nMulti-level flattening: Option to skip intermediate directory levels\n\n\n\n\n\nQuarto Website Navigation\nYAML Format Specification\nProject README: README.md (project overview and setup)"
  },
  {
    "objectID": "docs/routing-system.html#overview",
    "href": "docs/routing-system.html#overview",
    "title": "Navigation Routing System Documentation",
    "section": "",
    "text": "This project uses an automated navigation generation system to build the website’s navigation menu from the directory structure. Instead of manually maintaining hardcoded paths in _quarto.yml, the system scans the src/ directory and automatically generates navigation links based on:\n\nDirectory structure - Folders become menu categories\nFile locations - .qmd files become menu items\nYAML metadata - Titles are extracted from each file’s front matter"
  },
  {
    "objectID": "docs/routing-system.html#how-it-works",
    "href": "docs/routing-system.html#how-it-works",
    "title": "Navigation Routing System Documentation",
    "section": "",
    "text": "The navigation is generated by scripts/generate_nav.R, which:\n\nScans the src/ directory for all .qmd files\nExtracts titles from YAML front matter headers\nBuilds a hierarchical navigation structure matching the directory tree\nUpdates _quarto.yml with the generated navigation\n\n\n\n\nThe routing system follows this mapping:\nsrc/\n├── teaching-stats/           → \"Teaching Stats\" menu\n│   └── core-concepts/        → \"Core Concepts\" submenu\n│       ├── *.qmd files       → Individual menu items\n│\n└── blog/                     → \"Blog\" menu\n    ├── paper-reviews/        → \"Paper Reviews\" submenu\n    │   ├── index.qmd         → \"Overview\" menu item\n    │   └── */                → Nested submenus\n    └── essays/               → \"Essays\" submenu\n\n\n\n\n\n\nIncludes: All .qmd files in src/ and subdirectories\nExcludes:\n\nFiles named template.qmd (templates are not content)\nFiles named index.qmd (handled separately as “Overview” items)\n\n\n\n\n\nTitles are determined in priority order:\n\nYAML title: field - Extracted from file’s front matter (preferred)\nFilename - Fallback: filename converted to title case\n\nExample YAML header:\n---\ntitle: \"Central Limit Theorem\"\nsubtitle: \"Building an Intuition...\"\n---\n\n\n\nFile paths are converted to navigation href attributes:\n\nSource: src/teaching-stats/core-concepts/central-limit-theorem.qmd\nHref: src/teaching-stats/core-concepts/central-limit-theorem.qmd\nPaths are relative to the project root\n\n\n\n\nThe script creates nested menus following these rules:\n\nTop-level directories under src/ become main menu categories\nSubdirectories become submenus within their parent category\nFiles in directories become menu items\nindex.qmd files become “Overview” items at the top of their submenu\nEmpty directories show empty menus (ready for future content)\n\n\n\n\n\n\nFiles named index.qmd are treated specially: - Not included in the main file listing - Added as the first item in their directory’s menu with text “Overview” - Example: src/blog/paper-reviews/index.qmd → Menu item “Overview”\n\n\n\nNested directories create nested menus: - src/blog/paper-reviews/chatbot-mental-health/ → “Chatbot Mental Health” submenu - Files inside become items in that submenu\n\n\n\nEmpty directories (like src/blog/essays/) create empty menus:\n- text: Essays\n  menu: []"
  },
  {
    "objectID": "docs/routing-system.html#usage",
    "href": "docs/routing-system.html#usage",
    "title": "Navigation Routing System Documentation",
    "section": "",
    "text": "Run the script after adding, moving, or renaming content files:\nRscript scripts/generate_nav.R\nOr from R:\nsource(\"scripts/generate_nav.R\")\n\n\n\nThe script only updates the navbar section of _quarto.yml. All other configuration is preserved: - project settings - website title, site-url - format options - editor settings\n\n\n\n\nCreate a new page:\ncp src/teaching-stats/core-concepts/template.qmd \\\n   src/teaching-stats/core-concepts/my-new-concept.qmd\nEdit the file with your content and proper YAML header:\n---\ntitle: \"My New Concept\"\n---\nGenerate navigation:\nRscript scripts/generate_nav.R\nResult: The new page automatically appears in the navigation under “Teaching Stats → Core Concepts”"
  },
  {
    "objectID": "docs/routing-system.html#navigation-structure-reference",
    "href": "docs/routing-system.html#navigation-structure-reference",
    "title": "Navigation Routing System Documentation",
    "section": "",
    "text": "Home (index.qmd)\n├── Teaching Stats\n│   └── Core Concepts\n│       ├── Central Limit Theorem\n│       └── Degrees of Freedom\n├── Blog\n│   ├── Paper Reviews\n│   │   ├── Overview (index.qmd)\n│   │   └── Chatbot Mental Health\n│   │       └── Chatbot Effects On Postpartum Mental Health\n│   └── Essays (empty)\n└── About (about.qmd)\n\n\n\nAll paths in navigation are relative to the project root:\n\n\n\n\n\n\n\nNavigation Item\nFile Path\n\n\n\n\nCentral Limit Theorem\nsrc/teaching-stats/core-concepts/central-limit-theorem.qmd\n\n\nPaper Reviews Overview\nsrc/blog/paper-reviews/index.qmd\n\n\nChatbot Paper\nsrc/blog/paper-reviews/chatbot-mental-health/chatbot-postpartum-mental-health.qmd"
  },
  {
    "objectID": "docs/routing-system.html#configuration",
    "href": "docs/routing-system.html#configuration",
    "title": "Navigation Routing System Documentation",
    "section": "",
    "text": "The script can be customised by editing scripts/generate_nav.R:\n\n\nFiles matching these patterns are excluded from navigation:\nexclude_patterns &lt;- c(\"template\\\\.qmd$\", \"index\\\\.qmd$\")\nTo exclude additional files (e.g., drafts), add patterns:\nexclude_patterns &lt;- c(\n  \"template\\\\.qmd$\",\n  \"index\\\\.qmd$\",\n  \"draft-.*\\\\.qmd$\"  # Exclude files starting with \"draft-\"\n)\n\n\n\nChange the source directory (default: src):\nsrc_dir &lt;- \"content\"  # Use \"content\" instead of \"src\"\n\n\n\nMenu labels are automatically generated from directory names: - core-concepts → “Core Concepts” (hyphens to spaces, title case) - paper-reviews → “Paper Reviews” - chatbot-mental-health → “Chatbot Mental Health”\nTo customise menu labels, modify the build_nav() function’s display name formatting."
  },
  {
    "objectID": "docs/routing-system.html#troubleshooting",
    "href": "docs/routing-system.html#troubleshooting",
    "title": "Navigation Routing System Documentation",
    "section": "",
    "text": "Problem: Changes to files don’t appear in navigation\nSolution: 1. Ensure file is in src/ directory 2. Run Rscript scripts/generate_nav.R again 3. Check file has valid YAML header with title: field 4. Verify file doesn’t match exclude patterns\n\n\n\nProblem: A file exists but doesn’t appear in navigation\nPossible causes: - File matches an exclude pattern (e.g., template.qmd) - File has invalid YAML header (script falls back to filename) - File is outside src/ directory\nSolution: Check file location and YAML header format.\n\n\n\nProblem: Navigation shows filename instead of title\nSolution: Ensure your .qmd file has a valid YAML header:\n---\ntitle: \"Your Page Title\"\n---\n\n\n\nProblem: Nested menus not appearing correctly\nSolution: - Ensure subdirectories contain .qmd files (not just empty folders) - Check that paths are correctly structured - Verify index.qmd files exist if you want “Overview” items"
  },
  {
    "objectID": "docs/routing-system.html#best-practices",
    "href": "docs/routing-system.html#best-practices",
    "title": "Navigation Routing System Documentation",
    "section": "",
    "text": "Use descriptive directory names: They become menu labels (hyphens become spaces)\nUse meaningful filenames: Used as fallback if YAML title is missing\nAlways include YAML titles: Better control over navigation labels\n\n\n\n\nsrc/\n├── teaching-stats/\n│   ├── core-concepts/      ← Clear category name\n│   ├── advanced-topics/    ← Future expansion ready\n│   └── tutorials/          ← Organised by type\n└── blog/\n    ├── paper-reviews/\n    └── essays/\n\n\n\nAlways include a title: field:\n---\ntitle: \"Descriptive Page Title\"\nsubtitle: \"Optional subtitle\"\n---\n\n\n\n\nRun after: Adding new pages, moving files, renaming directories\nRun before: Committing navigation changes\nCI/CD: Consider adding to your build pipeline if navigation must stay in sync"
  },
  {
    "objectID": "docs/routing-system.html#technical-details",
    "href": "docs/routing-system.html#technical-details",
    "title": "Navigation Routing System Documentation",
    "section": "",
    "text": "The script requires: - yaml package (for YAML parsing) - fs package (for filesystem operations)\nInstall with:\ninstall.packages(c(\"yaml\", \"fs\"))\n\n\n\nAll paths are: - Relative to project root (where _quarto.yml is located) - Preserved exactly as they appear in the filesystem - No transformation applied (paths match file locations)\n\n\n\nThe script uses yaml::write_yaml() which: - Preserves existing YAML structure - Only updates the navbar section - Maintains formatting preferences (strings quoted vs unquoted)"
  },
  {
    "objectID": "docs/routing-system.html#future-enhancements",
    "href": "docs/routing-system.html#future-enhancements",
    "title": "Navigation Routing System Documentation",
    "section": "",
    "text": "Potential improvements to consider:\n\nSorting options: Alphabetical vs. date-based ordering\nCustom menu labels: Override auto-generated names via config file\nWeight/priority: Order items manually if needed\nActive state detection: Highlight current page in navigation\nMulti-level flattening: Option to skip intermediate directory levels"
  },
  {
    "objectID": "docs/routing-system.html#related-documentation",
    "href": "docs/routing-system.html#related-documentation",
    "title": "Navigation Routing System Documentation",
    "section": "",
    "text": "Quarto Website Navigation\nYAML Format Specification\nProject README: README.md (project overview and setup)"
  },
  {
    "objectID": "src/blog/paper-reviews/chatbot-mental-health/chatbot-postpartum-mental-health.html",
    "href": "src/blog/paper-reviews/chatbot-mental-health/chatbot-postpartum-mental-health.html",
    "title": "Chatbot Effects on Postpartum Mental Health",
    "section": "",
    "text": "Show the code\n# Installation and Setup\nrequired_packages &lt;- c(\"ggplot2\", \"dplyr\", \"tidyr\", \"gridExtra\", \"moments\", \"nortest\")\n\n# Load required packages\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(gridExtra)\nlibrary(moments)\nlibrary(nortest)\n\nset.seed(123)\n\n# Helper function to add color sample spots to captions\nadd_color_samples &lt;- function(caption, colors) {\n  # Create color sample spots using colored text with square brackets\n  color_spots &lt;- sapply(colors, function(color) {\n    paste0(\"[\", color, \"]\")  # Square brackets around color name\n  })\n  \n  # Replace color names with color spots\n  for(i in seq_along(colors)) {\n    color_name &lt;- names(colors)[i]\n    color_spot &lt;- color_spots[i]\n    caption &lt;- gsub(paste0(color_name, \" line\"), paste0(color_spot, \" line\"), caption, ignore.case = TRUE)\n    caption &lt;- gsub(paste0(color_name, \" =\"), paste0(color_spot, \" =\"), caption, ignore.case = TRUE)\n  }\n  \n  return(caption)\n}"
  },
  {
    "objectID": "src/blog/paper-reviews/chatbot-mental-health/chatbot-postpartum-mental-health.html#intro",
    "href": "src/blog/paper-reviews/chatbot-mental-health/chatbot-postpartum-mental-health.html#intro",
    "title": "Chatbot Effects on Postpartum Mental Health",
    "section": "Intro",
    "text": "Intro\n\nData from study by Suharwardy et al. (2023)"
  },
  {
    "objectID": "src/blog/paper-reviews/chatbot-mental-health/chatbot-postpartum-mental-health.html#design",
    "href": "src/blog/paper-reviews/chatbot-mental-health/chatbot-postpartum-mental-health.html#design",
    "title": "Chatbot Effects on Postpartum Mental Health",
    "section": "Design",
    "text": "Design\n\nAn unblinded randomized controlled trial was conducted at a tertiary academic center. English-speaking postpartum women aged 18 years or above with a live birth and access to a smartphone were eligible for enrollment prior to discharge from delivery hospitalization. Baseline surveys were administered to all participants prior to randomization to a mental health chatbot intervention or to usual care only. The intervention group downloaded the mental health chatbot smartphone application with perinatal-specific content, in addition to continuing usual care. Usual care consisted of routine postpartum follow up and mental health care as dictated by the patient’s obstetric provider. Surveys were administered during delivery hospitalization (baseline) and at 2-, 4-, and 6-weeks postpartum to assess depression and anxiety symptoms. The primary outcome was a change in depression symptoms at 6-weeks as measured using two depression screening tools: Patient Health Questionnaire-9 and Edinburgh Postnatal Depression Scale. Secondary outcomes included anxiety symptoms measured using Generalized Anxiety Disorder-7, and satisfaction and acceptability using validated scales. Based on a prior study, we estimated a sample size of 130 would have sufficient (80%) power to detect a moderate effect size (d=.4) in between group difference on the Patient Health Questionnaire-9."
  },
  {
    "objectID": "src/blog/paper-reviews/chatbot-mental-health/chatbot-postpartum-mental-health.html#results",
    "href": "src/blog/paper-reviews/chatbot-mental-health/chatbot-postpartum-mental-health.html#results",
    "title": "Chatbot Effects on Postpartum Mental Health",
    "section": "Results",
    "text": "Results\n\nA total of 192 women were randomized equally 1:1 to the chatbot or usual care; of these, 152 women completed the 6-week survey (n=68 chatbot, n=84 usual care) and were included in the final analysis. Mean baseline mental health assessment scores were below positive screening thresholds. At 6-weeks, there was a greater decrease in Patient Health Questionnaire-9 scores among the chatbot group compared to the usual care group (mean decrease=1.32, standard deviation=3.4 vs mean decrease=0.13, standard deviation=3.01, respectively). 6-week mean Edinburgh Postnatal Depression Scale and Generalized Anxiety Disorder-7 scores did not differ between groups and were similar to baseline. 91% (n=62) of the chatbot users were satisfied or highly satisfied with the chatbot, and 74% (n=50) of the intervention group reported use of the chatbot at least once in 2 weeks prior to the 6-week survey. 80% of study participants reported being comfortable with the use of a mobile smartphone application for mood management."
  },
  {
    "objectID": "src/blog/paper-reviews/chatbot-mental-health/chatbot-postpartum-mental-health.html#conclusion",
    "href": "src/blog/paper-reviews/chatbot-mental-health/chatbot-postpartum-mental-health.html#conclusion",
    "title": "Chatbot Effects on Postpartum Mental Health",
    "section": "Conclusion",
    "text": "Conclusion\n\nUse of a chatbot was acceptable to women in the early postpartum period. The sample did not screen positive for depression at baseline and thus the potential of the chatbot to reduce depressive symptoms in this population was limited. This study was conducted in a general obstetric population. Future studies of longer duration in high-risk postpartum populations who screen positive for depression are needed to further understand the utility and efficacy of such digital therapeutics for that population.\n\n| .97 |"
  },
  {
    "objectID": "src/blog/paper-reviews/chatbot-mental-health/chatbot-postpartum-mental-health.html#visualizations",
    "href": "src/blog/paper-reviews/chatbot-mental-health/chatbot-postpartum-mental-health.html#visualizations",
    "title": "Chatbot Effects on Postpartum Mental Health",
    "section": "Visualizations",
    "text": "Visualizations\n\n\nShow the code\n# Create simulated data based on the paper's results\nset.seed(456)\n\n# Sample sizes\nn_chatbot &lt;- 68\nn_usual_care &lt;- 84\n\n# Simulate baseline and 6-week PHQ-9 scores based on paper results\n# Baseline: below positive screening thresholds (PHQ-9 &lt; 10)\n# 6-week: chatbot decrease = 1.32, usual care decrease = 0.13\n\n# Baseline scores (below screening threshold)\nbaseline_chatbot &lt;- rnorm(n_chatbot, mean = 6.5, sd = 2.5)\nbaseline_usual &lt;- rnorm(n_usual_care, mean = 6.8, sd = 2.3)\n\n# 6-week scores (with treatment effect)\nweek6_chatbot &lt;- baseline_chatbot - rnorm(n_chatbot, mean = 1.32, sd = 3.4)\nweek6_usual &lt;- baseline_usual - rnorm(n_usual_care, mean = 0.13, sd = 3.01)\n\n# Simulate EPDS scores (non-significant results)\n# Paper states: \"6-week mean Edinburgh Postnatal Depression Scale and Generalized Anxiety Disorder-7 scores did not differ between groups\"\n# EPDS range: 0-30, similar baseline to PHQ-9 but smaller/no treatment effect\nbaseline_epds_chatbot &lt;- rnorm(n_chatbot, mean = 7.2, sd = 2.8)\nbaseline_epds_usual &lt;- rnorm(n_usual_care, mean = 7.5, sd = 2.6)\n\n# 6-week EPDS scores (minimal/no treatment effect)\nweek6_epds_chatbot &lt;- baseline_epds_chatbot - rnorm(n_chatbot, mean = 0.3, sd = 2.8)  # Small effect\nweek6_epds_usual &lt;- baseline_epds_usual - rnorm(n_usual_care, mean = 0.2, sd = 2.7)   # Similar small effect\n\n# Create data frame\ntherapy_data &lt;- data.frame(\n  group = rep(c(\"Chatbot\", \"Usual Care\"), c(n_chatbot, n_usual_care)),\n  baseline_phq9 = c(baseline_chatbot, baseline_usual),\n  week6_phq9 = c(week6_chatbot, week6_usual),\n  change_phq9 = c(week6_chatbot - baseline_chatbot, week6_usual - baseline_usual),\n  baseline_epds = c(baseline_epds_chatbot, baseline_epds_usual),\n  week6_epds = c(week6_epds_chatbot, week6_epds_usual),\n  change_epds = c(week6_epds_chatbot - baseline_epds_chatbot, week6_epds_usual - baseline_epds_usual)\n)\n\n# Add participant ID\ntherapy_data$participant_id &lt;- 1:nrow(therapy_data)\n\n\n\n\nShow the code\n# Visualization 1: Change in PHQ-9 scores by group\nchange_plot &lt;- ggplot(therapy_data, aes(x = group, y = change_phq9, fill = group)) +\n  geom_boxplot(alpha = 0.7) +\n  geom_jitter(width = 0.2, alpha = 0.6, size = 1) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\", alpha = 0.7) +\n  # Add colored rectangle for red line legend in top-right corner\n  annotate(\"rect\", xmin = 2.3, xmax = 2.5, ymin = 6, ymax = 6.5, \n           fill = \"red\", alpha = 0.7) +\n  annotate(\"text\", x = 2.6, y = 6.25, label = \"= No change\", size = 3) +\n  labs(title = \"Change in Depression Symptoms (PHQ-9)\",\n       subtitle = \"Negative values indicate improvement in symptoms\",\n       x = \"Treatment Group\", y = \"Change in PHQ-9 Score\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5),\n        legend.position = \"none\") +\n  scale_fill_manual(values = c(\"Chatbot\" = \"steelblue\", \"Usual Care\" = \"orange\"))\n\nprint(change_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Visualization 2: Baseline vs 6-week scores\n# Reshape data for plotting\ntherapy_long &lt;- therapy_data %&gt;%\n  select(participant_id, group, baseline_phq9, week6_phq9) %&gt;%\n  pivot_longer(cols = c(baseline_phq9, week6_phq9), \n               names_to = \"timepoint\", \n               values_to = \"phq9_score\") %&gt;%\n  mutate(timepoint = factor(timepoint, \n                           levels = c(\"baseline_phq9\", \"week6_phq9\"),\n                           labels = c(\"Baseline\", \"6 Weeks\")))\n\n# Create two separate charts for better clarity\n\n# Chart 1: Group means only (clean and clear)\n# Calculate means manually to avoid legend issues\nmeans_data &lt;- therapy_long %&gt;%\n  group_by(timepoint, group) %&gt;%\n  summarise(\n    mean_score = mean(phq9_score, na.rm = TRUE),\n    se = sd(phq9_score, na.rm = TRUE) / sqrt(n()),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(\n    ci_lower = mean_score - 1.96 * se,\n    ci_upper = mean_score + 1.96 * se\n  )\n\nmeans_plot &lt;- ggplot(means_data, aes(x = timepoint, y = mean_score, color = group, group = group)) +\n  # Add confidence intervals for group means\n  geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper, fill = group), alpha = 0.3, color = NA) +\n  # Group means with prominence\n  geom_line(linewidth = 3, alpha = 1) +\n  geom_point(size = 5, alpha = 1) +\n  # Add mean values and sample sizes with horizontal offset\n  geom_text(aes(label = round(mean_score, 1), x = as.numeric(timepoint) + ifelse(group == \"Chatbot\", -0.15, 0.15)), \n            vjust = -1.8, size = 4, fontface = \"bold\") +\n  geom_text(aes(label = \"(n=68)\", x = as.numeric(timepoint) + ifelse(group == \"Chatbot\", -0.15, 0.15)), \n            vjust = -0.8, size = 3) +\n  labs(title = \"Group Means\",\n       subtitle = \"Mean PHQ-9 scores with 95% confidence intervals\",\n       x = \"Time Point\", y = \"PHQ-9 Score\",\n       caption = \"Lower scores = Better outcomes\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5, size = 12),\n        plot.subtitle = element_text(hjust = 0.5, size = 9),\n        legend.position = \"top\") +\n  scale_color_manual(values = c(\"Chatbot\" = \"steelblue\", \"Usual Care\" = \"orange\")) +\n  scale_fill_manual(values = c(\"Chatbot\" = \"steelblue\", \"Usual Care\" = \"orange\"))\n\n# Chart 2: Individual trajectories only\ntrajectories_plot &lt;- ggplot(therapy_long, aes(x = timepoint, y = phq9_score, color = group)) +\n  # Individual trajectories with better visibility\n  geom_line(aes(group = participant_id), alpha = 0.4, linewidth = 0.5) +\n  geom_point(aes(group = participant_id), alpha = 0.6, size = 1.2) +\n  # Add group means as reference (thinner)\n  stat_summary(aes(group = group), fun = mean, geom = \"line\", \n               linewidth = 2, alpha = 1, linetype = \"dashed\") +\n  stat_summary(aes(group = group), fun = mean, geom = \"point\", \n               size = 3, alpha = 1, shape = 21, fill = \"white\") +\n  labs(title = \"Individual Trajectories\",\n       subtitle = \"Individual participant trajectories with group means (dashed lines)\",\n       x = \"Time Point\", y = \"PHQ-9 Score\",\n       caption = \"Each line = One participant | Dashed lines = Group means\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5, size = 12),\n        plot.subtitle = element_text(hjust = 0.5, size = 9),\n        legend.position = \"top\") +\n  scale_color_manual(values = c(\"Chatbot\" = \"steelblue\", \"Usual Care\" = \"orange\"))\n\n# Display both charts side by side using grid.arrange\nlibrary(gridExtra)\ngrid.arrange(means_plot, trajectories_plot, ncol = 2, \n             top = \"Depression Symptoms Over Time: Group Means vs Individual Trajectories\",\n             heights = c(0.9, 0.1))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Visualization 3: Distribution of baseline scores\nbaseline_dist_plot &lt;- ggplot(therapy_data, aes(x = baseline_phq9, fill = group)) +\n  geom_histogram(bins = 15, alpha = 0.7, position = \"identity\") +\n  geom_vline(xintercept = 10, linetype = \"dashed\", color = \"red\", linewidth = 1) +\n  # Add colored rectangle for red line legend in top-right corner\n  annotate(\"rect\", xmin = 11.5, xmax = 12, ymin = 9, ymax = 9.5, \n           fill = \"red\", alpha = 0.7) +\n  annotate(\"text\", x = 12.1, y = 9.25, label = \"= Screening threshold (≥10)\", size = 3) +\n  labs(title = \"Distribution of Baseline Depression Scores\",\n       subtitle = \"PHQ-9 screening threshold (≥10 indicates depression)\",\n       x = \"Baseline PHQ-9 Score\", y = \"Frequency\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5)) +\n  scale_fill_manual(values = c(\"Chatbot\" = \"steelblue\", \"Usual Care\" = \"orange\"))\n\nprint(baseline_dist_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Visualization 4: Demographics comparison with contextual information\n# Create demographic data based on the table\ndemographics_data &lt;- data.frame(\n  variable = rep(c(\"Age 25-34\", \"Age 35-44\", \"Married\", \"Employed\", \n                   \"Mental Health History\", \"Comfortable with Apps\"), each = 2),\n  group = rep(c(\"Chatbot\", \"Usual Care\"), 6),\n  percentage = c(63.2, 47.6, 32.4, 44.0, 94.1, 83.3, 80.9, 78.6, 16.2, 9.5, 82.4, 77.4)\n)\n\n# Add statistical significance indicators - mark age 25-34 and married as significant\ndemographics_data$significant &lt;- c(TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE)\n\ndemographics_plot &lt;- ggplot(demographics_data, aes(x = variable, y = percentage, fill = group)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", alpha = 0.8) +\n  geom_text(aes(label = paste0(round(percentage, 1), \"%\")), \n            position = position_dodge(width = 0.9), vjust = -0.5, size = 3) +\n  # Add explanatory annotations in better positions\n  annotate(\"text\", x = 0.8, y = 108, label = \"SIGNIFICANT DIFFERENCES\", \n           size = 3.5, fontface = \"bold\", color = \"red\", hjust = 0) +\n  annotate(\"text\", x = 0.8, y = 104, label = \"Age 25-34: p=0.02 | Married: p=0.046\", \n           size = 2.8, color = \"red\", hjust = 0) +\n  annotate(\"text\", x = 0.8, y = 100, label = \"Groups not perfectly balanced\", \n           size = 2.5, color = \"darkred\", hjust = 0) +\n  annotate(\"text\", x = 0.8, y = 96, label = \"May affect treatment interpretation\", \n           size = 2.5, color = \"darkred\", hjust = 0) +\n  labs(title = \"Demographic Characteristics by Group\",\n       subtitle = \"Percentage of participants in each category | * = Statistically significant difference (p &lt; 0.05)\",\n       x = \"Characteristic\", y = \"Percentage (%)\",\n       caption = \"IMPORTANT: Demographic differences may confound treatment effects\\nChatbot group is younger and more likely to be married\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5),\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = c(\"Chatbot\" = \"steelblue\", \"Usual Care\" = \"orange\")) +\n  # Extend y-axis to accommodate labels and annotations\n  scale_y_continuous(limits = c(0, 115), expand = c(0, 0))\n\nprint(demographics_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Visualization 5: Treatment satisfaction and usage\nsatisfaction_data &lt;- data.frame(\n  metric = c(\"Satisfied with Chatbot\", \"Used Chatbot in Past 2 Weeks\", \n             \"Comfortable with Mental Health Apps\"),\n  percentage = c(91, 74, 80),\n  group = c(\"Chatbot Users\", \"Chatbot Users\", \"All Participants\")\n)\n\nsatisfaction_plot &lt;- ggplot(satisfaction_data, aes(x = metric, y = percentage, fill = group)) +\n  geom_bar(stat = \"identity\", alpha = 0.8) +\n  geom_text(aes(label = paste0(percentage, \"%\")), vjust = -0.5, size = 4) +\n  labs(title = \"Treatment Acceptability and Usage\",\n       subtitle = \"Percentage of participants reporting positive experiences\",\n       x = \"Metric\", y = \"Percentage (%)\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5),\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = c(\"Chatbot Users\" = \"steelblue\", \"All Participants\" = \"lightblue\")) +\n  # Extend y-axis to accommodate labels\n  scale_y_continuous(limits = c(0, 100), expand = c(0, 0))\n\nprint(satisfaction_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Visualization 6: Effect size and confidence intervals\n# Calculate effect size (Cohen's d) for the change in PHQ-9\nchatbot_change &lt;- therapy_data$change_phq9[therapy_data$group == \"Chatbot\"]\nusual_change &lt;- therapy_data$change_phq9[therapy_data$group == \"Usual Care\"]\n\n# Pooled standard deviation\nn1 &lt;- length(chatbot_change)\nn2 &lt;- length(usual_change)\nvar1 &lt;- var(chatbot_change)\nvar2 &lt;- var(usual_change)\npooled_sd &lt;- sqrt(((n1-1)*var1 + (n2-1)*var2) / (n1 + n2 - 2))\n\n# Cohen's d\ncohens_d &lt;- (mean(chatbot_change) - mean(usual_change)) / pooled_sd\n\n# Create effect size plot\neffect_data &lt;- data.frame(\n  group = c(\"Chatbot\", \"Usual Care\"),\n  mean_change = c(mean(chatbot_change), mean(usual_change)),\n  se = c(sd(chatbot_change)/sqrt(n1), sd(usual_change)/sqrt(n2))\n)\n\neffect_plot &lt;- ggplot(effect_data, aes(x = group, y = mean_change, fill = group)) +\n  geom_bar(stat = \"identity\", alpha = 0.7) +\n  geom_errorbar(aes(ymin = mean_change - 1.96*se, ymax = mean_change + 1.96*se), \n                width = 0.2, linewidth = 1) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\", alpha = 0.7) +\n  labs(title = \"Treatment Effect on Depression Symptoms\",\n       subtitle = paste(\"Cohen's d =\", round(cohens_d, 3), \n                       \"| Error bars = 95% confidence intervals\"),\n       x = \"Treatment Group\", y = \"Mean Change in PHQ-9 Score\",\n       caption = \"Negative values = Improvement in symptoms\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5),\n        legend.position = \"none\") +\n  scale_fill_manual(values = c(\"Chatbot\" = \"steelblue\", \"Usual Care\" = \"orange\"))\n\nprint(effect_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Visualization 7: Statistical significance and effect size summary\n# Calculate t-test for significance\nt_test_result &lt;- t.test(change_phq9 ~ group, data = therapy_data)\np_value &lt;- t_test_result$p.value\n\n# Create significance and effect size summary\nsignificance_data &lt;- data.frame(\n  metric = c(\"Mean Change (Chatbot)\", \"Mean Change (Usual Care)\", \n             \"Difference\", \"Cohen's d\", \"P-value\"),\n  value = c(mean(chatbot_change), mean(usual_change), \n            mean(chatbot_change) - mean(usual_change), cohens_d, p_value),\n  interpretation = c(\"Improvement\", \"Minimal change\", \n                     \"Treatment effect\", \"Effect size\", \"Significance\")\n)\n\n# Create significance plot\nsignificance_plot &lt;- ggplot(significance_data[1:3, ], aes(x = metric, y = value, fill = metric)) +\n  geom_bar(stat = \"identity\", alpha = 0.8) +\n  geom_text(aes(label = paste0(round(value, 2), \n                               ifelse(metric == \"P-value\", \n                                      paste0(\" (p = \", round(p_value, 4), \")\"), \n                                      \"\"))), \n            vjust = -0.5, size = 4) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\", alpha = 0.7) +\n  labs(title = \"Treatment Effect: Statistical Significance\",\n       subtitle = paste(\"P-value =\", round(p_value, 4), \n                       \"| Significant:\", ifelse(p_value &lt; 0.05, \"YES\", \"NO\")),\n       x = \"Metric\", y = \"Change in PHQ-9 Score\",\n       caption = \"Negative values = Improvement in depression symptoms\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5),\n        axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = \"none\") +\n  scale_fill_manual(values = c(\"Mean Change (Chatbot)\" = \"steelblue\", \n                              \"Mean Change (Usual Care)\" = \"orange\",\n                              \"Difference\" = \"purple\"))\n\nprint(significance_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Visualization 8: Effect size interpretation with confidence intervals\n# Calculate confidence intervals for the difference\ndiff_ci &lt;- t.test(chatbot_change, usual_change)$conf.int\n\neffect_size_data &lt;- data.frame(\n  measure = c(\"Cohen's d\", \"Difference (95% CI)\"),\n  value = c(cohens_d, mean(chatbot_change) - mean(usual_change)),\n  lower = c(cohens_d - 0.1, diff_ci[1]),  # Approximate CI for Cohen's d\n  upper = c(cohens_d + 0.1, diff_ci[2]),\n  interpretation = c(\"Standardized effect size\", \"Raw difference in PHQ-9 scores\")\n)\n\neffect_size_plot &lt;- ggplot(effect_size_data, aes(x = measure, y = value, fill = measure)) +\n  geom_bar(stat = \"identity\", alpha = 0.7) +\n  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2, linewidth = 1) +\n  geom_text(aes(label = paste0(round(value, 3), \n                               ifelse(measure == \"Difference (95% CI)\", \n                                      paste0(\"\\n[\", round(lower, 3), \", \", round(upper, 3), \"]\"), \n                                      \"\"))), \n            vjust = -0.5, size = 3.5) +\n  labs(title = \"Effect Size and Confidence Intervals\",\n       subtitle = paste(\"Cohen's d interpretation:\", \n                       ifelse(abs(cohens_d) &lt; 0.2, \"Negligible\", \n                              ifelse(abs(cohens_d) &lt; 0.5, \"Small\", \n                                     ifelse(abs(cohens_d) &lt; 0.8, \"Medium\", \"Large\"))), \"effect\"),\n       x = \"Measure\", y = \"Value\",\n       caption = \"Error bars = 95% confidence intervals\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5),\n        legend.position = \"none\") +\n  scale_fill_manual(values = c(\"Cohen's d\" = \"darkgreen\", \"Difference (95% CI)\" = \"purple\"))\n\nprint(effect_size_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Visualization 9: Clinical significance - proportion improved\n# Define clinical improvement (PHQ-9 decrease of 5+ points or 50% reduction)\ntherapy_data$clinically_improved &lt;- ifelse(therapy_data$change_phq9 &lt;= -5 | \n                                          (therapy_data$baseline_phq9 &gt;= 10 & \n                                           therapy_data$change_phq9 &lt;= -0.5 * therapy_data$baseline_phq9), \n                                          \"Improved\", \"Not Improved\")\n\nclinical_summary &lt;- therapy_data %&gt;%\n  group_by(group, clinically_improved) %&gt;%\n  summarise(count = n(), .groups = 'drop') %&gt;%\n  group_by(group) %&gt;%\n  mutate(percentage = count / sum(count) * 100)\n\nclinical_plot &lt;- ggplot(clinical_summary, aes(x = group, y = percentage, fill = clinically_improved)) +\n  geom_bar(stat = \"identity\", alpha = 0.8) +\n  geom_text(aes(label = paste0(round(percentage, 1), \"%\\n(n=\", count, \")\")), \n            position = position_stack(vjust = 0.5), size = 3.5) +\n  labs(title = \"Clinical Significance: Proportion with Meaningful Improvement\",\n       subtitle = \"Defined as ≥5 point decrease or ≥50% reduction from baseline\",\n       x = \"Treatment Group\", y = \"Percentage (%)\",\n       fill = \"Clinical Status\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5)) +\n  scale_fill_manual(values = c(\"Improved\" = \"darkgreen\", \"Not Improved\" = \"lightgray\"))\n\nprint(clinical_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Visualization 10: Forest plot of key results\n# Create forest plot data\nforest_data &lt;- data.frame(\n  outcome = c(\"PHQ-9 Change\", \"Baseline PHQ-9\", \"6-week PHQ-9\", \"Age 25-34\", \"Married\"),\n  chatbot_mean = c(mean(chatbot_change), mean(baseline_chatbot), mean(week6_chatbot), 63.2, 94.1),\n  usual_care_mean = c(mean(usual_change), mean(baseline_usual), mean(week6_usual), 47.6, 83.3),\n  difference = c(mean(chatbot_change) - mean(usual_change), \n                mean(baseline_chatbot) - mean(baseline_usual),\n                mean(week6_chatbot) - mean(week6_usual), 15.6, 10.8),\n  p_value = c(p_value, 0.5, 0.3, 0.02, 0.046)  # Approximate p-values\n)\n\nforest_plot &lt;- ggplot(forest_data, aes(x = outcome, y = difference, color = p_value &lt; 0.05)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = difference - 0.5, ymax = difference + 0.5), width = 0.2) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\", alpha = 0.7) +\n  geom_text(aes(label = paste0(\"p = \", round(p_value, 3))), \n            vjust = -0.8, size = 3) +\n  # Add colored rectangles for legend in top-right area\n  annotate(\"rect\", xmin = 4.8, xmax = 5, ymin = 12, ymax = 12.5, \n           fill = \"red\", alpha = 0.7) +\n  annotate(\"text\", x = 5.1, y = 12.25, label = \"= No difference\", size = 2.5) +\n  annotate(\"rect\", xmin = 4.8, xmax = 5, ymin = 11, ymax = 11.5, \n           fill = \"darkgreen\", alpha = 0.7) +\n  annotate(\"text\", x = 5.1, y = 11.25, label = \"= Significant\", size = 2.5) +\n  annotate(\"rect\", xmin = 4.8, xmax = 5, ymin = 10, ymax = 10.5, \n           fill = \"orange\", alpha = 0.7) +\n  annotate(\"text\", x = 5.1, y = 10.25, label = \"= Not significant\", size = 2.5) +\n  coord_flip() +\n  labs(title = \"Forest Plot: Key Differences Between Groups\",\n       subtitle = \"Statistical significance indicated by color\",\n       x = \"Outcome\", y = \"Difference (Chatbot - Usual Care)\",\n       caption = \"Positive values favor chatbot group\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5),\n        legend.position = \"none\") +\n  scale_color_manual(values = c(\"TRUE\" = \"darkgreen\", \"FALSE\" = \"orange\"))\n\nprint(forest_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Visualization 11: Null hypothesis testing visualization\n# Simulate null distribution (no difference between groups)\nset.seed(789)\nn_simulations &lt;- 10000\nnull_differences &lt;- numeric(n_simulations)\n\n# Permutation test: randomly shuffle group labels\nfor(i in 1:n_simulations) {\n  shuffled_data &lt;- therapy_data\n  shuffled_data$group &lt;- sample(shuffled_data$group)\n  \n  # Calculate difference with shuffled groups\n  chatbot_shuffled &lt;- shuffled_data$change_phq9[shuffled_data$group == \"Chatbot\"]\n  usual_shuffled &lt;- shuffled_data$change_phq9[shuffled_data$group == \"Usual Care\"]\n  \n  null_differences[i] &lt;- mean(chatbot_shuffled) - mean(usual_shuffled)\n}\n\n# Calculate observed difference\nobserved_diff &lt;- mean(chatbot_change) - mean(usual_change)\n\n# Create null distribution plot\nnull_plot &lt;- ggplot(data.frame(null_diff = null_differences), aes(x = null_diff)) +\n  geom_histogram(bins = 50, fill = \"lightgray\", alpha = 0.7, color = \"black\") +\n  geom_vline(xintercept = observed_diff, color = \"red\", linewidth = 2) +\n  geom_vline(xintercept = -observed_diff, color = \"red\", linewidth = 2, linetype = \"dashed\") +\n  geom_vline(xintercept = 0, color = \"blue\", linewidth = 1, linetype = \"dotted\") +\n  # Add colored rectangles for legend in top-right corner\n  annotate(\"rect\", xmin = 1.8, xmax = 2, ymin = 800, ymax = 850, \n           fill = \"red\", alpha = 0.7) +\n  annotate(\"text\", x = 2.1, y = 825, label = \"= Observed difference\", size = 3) +\n  annotate(\"rect\", xmin = 1.8, xmax = 2, ymin = 750, ymax = 800, \n           fill = \"blue\", alpha = 0.7) +\n  annotate(\"text\", x = 2.1, y = 775, label = \"= H0 (no difference)\", size = 3) +\n  labs(title = \"Null Hypothesis Testing: Distribution Under H0\",\n       subtitle = paste(\"Observed difference =\", round(observed_diff, 3), \n                       \"| P-value =\", round(mean(abs(null_differences) &gt;= abs(observed_diff)), 4)),\n       x = \"Difference in Mean Change (Chatbot - Usual Care)\", y = \"Frequency\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5))\n\nprint(null_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Visualization 12: P-value interpretation with effect size\n# Calculate exact p-value from t-test\nt_test_exact &lt;- t.test(chatbot_change, usual_change)\nexact_p_value &lt;- t_test_exact$p.value\n\n# Create p-value interpretation plot\np_value_data &lt;- data.frame(\n  threshold = c(\"p &lt; 0.001\", \"p &lt; 0.01\", \"p &lt; 0.05\", \"p &lt; 0.10\"),\n  value = c(0.001, 0.01, 0.05, 0.10),\n  interpretation = c(\"Highly Significant\", \"Very Significant\", \"Significant\", \"Marginally Significant\")\n)\n\np_value_plot &lt;- ggplot(p_value_data, aes(x = threshold, y = value, fill = value &lt; exact_p_value)) +\n  geom_bar(stat = \"identity\", alpha = 0.7) +\n  geom_hline(yintercept = exact_p_value, color = \"red\", linewidth = 2) +\n  geom_text(aes(label = paste0(\"p = \", round(value, 3))), vjust = -0.5, size = 3) +\n  geom_text(aes(x = 2.5, y = exact_p_value + 0.01, \n                label = paste0(\"Observed p = \", round(exact_p_value, 4))), \n            color = \"red\", size = 4) +\n  labs(title = \"P-Value Interpretation: Where Does Our Result Fall?\",\n       subtitle = paste(\"Observed p-value =\", round(exact_p_value, 4), \n                       \"| Significance level = 0.05\"),\n       x = \"Significance Threshold\", y = \"P-Value\",\n       caption = add_color_samples(\"Red line = Observed p-value | Bars = Significance thresholds\", c(\"Red\" = \"red\"))) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5),\n        legend.position = \"none\") +\n  scale_fill_manual(values = c(\"TRUE\" = \"darkgreen\", \"FALSE\" = \"orange\"))\n\nprint(p_value_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Visualization 13: Confidence intervals and null hypothesis\n# Calculate confidence intervals\nci_95 &lt;- t.test(chatbot_change, usual_change)$conf.int\nci_90 &lt;- t.test(chatbot_change, usual_change, conf.level = 0.90)$conf.int\nci_99 &lt;- t.test(chatbot_change, usual_change, conf.level = 0.99)$conf.int\n\nci_data &lt;- data.frame(\n  level = c(\"99% CI\", \"95% CI\", \"90% CI\"),\n  lower = c(ci_99[1], ci_95[1], ci_90[1]),\n  upper = c(ci_99[2], ci_95[2], ci_90[2]),\n  width = c(ci_99[2] - ci_99[1], ci_95[2] - ci_95[1], ci_90[2] - ci_90[1])\n)\n\nci_plot &lt;- ggplot(ci_data, aes(y = level)) +\n  geom_errorbar(aes(xmin = lower, xmax = upper, color = level), \n                linewidth = 2, width = 0.3) +\n  geom_vline(xintercept = 0, color = \"red\", linewidth = 2, linetype = \"dashed\") +\n  geom_vline(xintercept = observed_diff, color = \"blue\", linewidth = 2) +\n  geom_text(aes(x = lower - 0.1, label = paste0(\"[\", round(lower, 3), \", \", round(upper, 3), \"]\")), \n            hjust = 1, size = 3) +\n  labs(title = \"Confidence Intervals and Null Hypothesis\",\n       subtitle = paste(\"Observed difference =\", round(observed_diff, 3), \n                       \"| Does 0 fall within the CI?\"),\n       x = \"Difference in Mean Change (Chatbot - Usual Care)\", y = \"Confidence Level\",\n       caption = add_color_samples(\"Red line = H0 (no difference) | Blue line = Observed difference | CI excludes 0 = Significant\", \n                                 c(\"Red\" = \"red\", \"Blue\" = \"blue\"))) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5)) +\n  scale_color_manual(values = c(\"99% CI\" = \"darkred\", \"95% CI\" = \"red\", \"90% CI\" = \"orange\"))\n\nprint(ci_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Visualization 14: Power analysis and effect size relationship\n# Calculate power for different effect sizes\neffect_sizes &lt;- seq(0.1, 1.0, by = 0.1)\npower_values &lt;- numeric(length(effect_sizes))\n\nfor(i in 1:length(effect_sizes)) {\n  # Approximate power calculation\n  n_per_group &lt;- min(length(chatbot_change), length(usual_change))\n  power_values[i] &lt;- power.t.test(n = n_per_group, d = effect_sizes[i], \n                                 sig.level = 0.05, type = \"two.sample\")$power\n}\n\npower_data &lt;- data.frame(effect_size = effect_sizes, power = power_values)\n\npower_plot &lt;- ggplot(power_data, aes(x = effect_size, y = power)) +\n  geom_line(linewidth = 2, color = \"blue\") +\n  geom_point(size = 3, color = \"blue\") +\n  geom_vline(xintercept = abs(cohens_d), color = \"red\", linewidth = 2, linetype = \"dashed\") +\n  geom_hline(yintercept = 0.8, color = \"green\", linewidth = 1, linetype = \"dashed\") +\n  # Add explanation for the 80% threshold\n  annotate(\"text\", x = 0.05, y = 0.82, \n           label = \"80% POWER THRESHOLD\", size = 3, fontface = \"bold\", color = \"darkgreen\", hjust = 0) +\n  annotate(\"text\", x = 0.05, y = 0.78, \n           label = \"Industry standard for reliable\", size = 2.5, color = \"darkgreen\", hjust = 0) +\n  annotate(\"text\", x = 0.05, y = 0.75, \n           label = \"detection of effects\", size = 2.5, color = \"darkgreen\", hjust = 0) +\n  annotate(\"text\", x = 0.05, y = 0.72, \n           label = \"Below 80% = Underpowered study\", size = 2.5, color = \"darkgreen\", hjust = 0) +\n  annotate(\"text\", x = 0.05, y = 0.69, \n           label = \"Above 80% = Adequate power\", size = 2.5, color = \"darkgreen\", hjust = 0) +\n  geom_text(aes(x = abs(cohens_d) + 0.05, y = 0.5, \n                label = paste0(\"Observed\\neffect size\\n= \", round(abs(cohens_d), 3))), \n            color = \"red\", size = 3) +\n  # Add comprehensive annotations explaining power analysis (moved to right side)\n  annotate(\"text\", x = 0.65, y = 0.9, \n           label = \"WHAT THIS SHOWS:\", size = 3.5, fontface = \"bold\", hjust = 0) +\n  annotate(\"text\", x = 0.65, y = 0.85, \n           label = paste0(\"• Current study power = \", \n                         round(power.t.test(n = min(length(chatbot_change), length(usual_change)), \n                                           d = abs(cohens_d), sig.level = 0.05, \n                                           type = \"two.sample\")$power * 100, 1), \"%\"), \n           size = 3, hjust = 0) +\n  annotate(\"text\", x = 0.65, y = 0.8, \n           label = paste0(\"• Observed effect size = \", round(abs(cohens_d), 3)), \n           size = 3, hjust = 0) +\n  annotate(\"text\", x = 0.65, y = 0.75, \n           label = paste0(\"• Effect interpretation = \", \n                         ifelse(abs(cohens_d) &lt; 0.2, \"Negligible\", \n                                ifelse(abs(cohens_d) &lt; 0.5, \"Small\", \n                                       ifelse(abs(cohens_d) &lt; 0.8, \"Medium\", \"Large\")))), \n           size = 3, hjust = 0) +\n  # Add future study recommendations\n  annotate(\"text\", x = 0.65, y = 0.6, \n           label = \"FUTURE STUDIES NEED:\", size = 3.5, fontface = \"bold\", hjust = 0, color = \"darkblue\") +\n  annotate(\"text\", x = 0.65, y = 0.55, \n           label = \"• Larger sample size for higher power\", \n           size = 3, hjust = 0, color = \"darkblue\") +\n  annotate(\"text\", x = 0.65, y = 0.5, \n           label = \"• Target population with higher depression scores\", \n           size = 3, hjust = 0, color = \"darkblue\") +\n  annotate(\"text\", x = 0.65, y = 0.45, \n           label = \"• Longer follow-up period\", \n           size = 3, hjust = 0, color = \"darkblue\") +\n  annotate(\"text\", x = 0.65, y = 0.4, \n           label = \"• Stratified randomisation for balanced groups\", \n           size = 3, hjust = 0, color = \"darkblue\") +\n  # Add sample size calculation for 80% power\n  annotate(\"text\", x = 0.65, y = 0.25, \n           label = \"SAMPLE SIZE FOR 80% POWER:\", size = 3.5, fontface = \"bold\", hjust = 0, color = \"darkgreen\") +\n  annotate(\"text\", x = 0.65, y = 0.2, \n           label = paste0(\"• For d = 0.3 (small effect): ~350 per group\"), \n           size = 3, hjust = 0, color = \"darkgreen\") +\n  annotate(\"text\", x = 0.65, y = 0.15, \n           label = paste0(\"• For d = 0.5 (medium effect): ~130 per group\"), \n           size = 3, hjust = 0, color = \"darkgreen\") +\n  annotate(\"text\", x = 0.65, y = 0.1, \n           label = paste0(\"• For d = 0.8 (large effect): ~50 per group\"), \n           size = 3, hjust = 0, color = \"darkgreen\") +\n  labs(title = \"Power Analysis: Relationship Between Effect Size and Statistical Power\",\n       subtitle = paste(\"Current study power for observed effect size =\", \n                       round(power.t.test(n = min(length(chatbot_change), length(usual_change)), \n                                         d = abs(cohens_d), sig.level = 0.05, \n                                         type = \"two.sample\")$power, 3)),\n       x = \"Effect Size (Cohen's d)\", y = \"Statistical Power\",\n       caption = \"Red line = Observed effect size | Green line = 80% power threshold | Blue line = Power curve\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5))\n\nprint(power_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Visualization 15: Bayesian interpretation (posterior probability)\n# Simple Bayesian analysis using normal approximation\n# Prior: Normal(0, 1) - skeptical prior\n# Likelihood: Normal(observed_diff, SE)\n# Posterior: Normal with updated mean and variance\n\nse_diff &lt;- sqrt(var(chatbot_change)/length(chatbot_change) + var(usual_change)/length(usual_change))\nprior_mean &lt;- 0\nprior_sd &lt;- 1\nlikelihood_mean &lt;- observed_diff\nlikelihood_sd &lt;- se_diff\n\n# Posterior parameters\nposterior_precision &lt;- 1/prior_sd^2 + 1/likelihood_sd^2\nposterior_sd &lt;- sqrt(1/posterior_precision)\nposterior_mean &lt;- (prior_mean/prior_sd^2 + likelihood_mean/likelihood_sd^2) / posterior_precision\n\n# Calculate probability that effect &gt; 0\nprob_positive &lt;- 1 - pnorm(0, posterior_mean, posterior_sd)\n\n# Create Bayesian plot\nx_vals &lt;- seq(-2, 2, by = 0.01)\nprior_density &lt;- dnorm(x_vals, prior_mean, prior_sd)\nlikelihood_density &lt;- dnorm(x_vals, likelihood_mean, likelihood_sd)\nposterior_density &lt;- dnorm(x_vals, posterior_mean, posterior_sd)\n\nbayesian_data &lt;- data.frame(\n  x = rep(x_vals, 3),\n  density = c(prior_density, likelihood_density, posterior_density),\n  distribution = rep(c(\"Prior\", \"Likelihood\", \"Posterior\"), each = length(x_vals))\n)\n\n# Define annotation positions for easy adjustment\nposterior_x &lt;- -1.99\nposterior_y_start &lt;- 0.8\n\nlikelihood_x &lt;- -1.99\nlikelihood_y_start &lt;- 0.5\n\ninterpretation_x &lt;- -0.4\ninterpretation_y_start &lt;- 0.85\n\nnull_x &lt;- 0.1\nnull_y_start &lt;- 0.6\n\nprior_x &lt;- 0.8\nprior_y_start &lt;- 0.4\n\nbayesian_plot &lt;- ggplot(bayesian_data, aes(x = x, y = density, color = distribution)) +\n  geom_line(linewidth = 1.5) +\n  geom_vline(xintercept = 0, color = \"red\", linewidth = 1, linetype = \"dashed\") +\n  geom_vline(xintercept = posterior_mean, color = \"blue\", linewidth = 2) +\n  # Reposition posterior mean text to avoid overlap and fix blurriness\n  annotate(\"text\", x = posterior_mean + 0.1, y = max(posterior_density) + 0.05, \n           label = paste0(\"Posterior mean = \", round(posterior_mean, 3), \" (confidence = \", round(dnorm(posterior_mean, posterior_mean, posterior_sd) * 100, 1), \"%)\"), \n           color = \"blue\", size = 3, hjust = 0, fontface = \"bold\") +\n  # Add comprehensive explanations for each distribution\n  # POSTERIOR annotation (top left) - moved up more and left more\n  annotate(\"text\", x = posterior_x, y = posterior_y_start, \n           label = \"POSTERIOR (Blue):\", size = 3, fontface = \"bold\", hjust = 0, color = \"darkblue\") +\n  annotate(\"text\", x = posterior_x, y = posterior_y_start - 0.05, \n           label = \"Updated belief after data\", size = 2.5, hjust = 0, color = \"darkblue\") +\n  annotate(\"text\", x = posterior_x, y = posterior_y_start - 0.08, \n           label = paste0(\"Confidence in posterior mean = \", round(dnorm(posterior_mean, posterior_mean, posterior_sd) * 100, 1), \"%\"), size = 2.5, hjust = 0, color = \"darkblue\") +\n  annotate(\"text\", x = posterior_x, y = posterior_y_start - 0.11, \n           label = \"Combines prior + likelihood\", size = 2.5, hjust = 0, color = \"darkblue\") +\n  \n  annotate(\"text\", x = likelihood_x, y = likelihood_y_start, \n           label = \"LIKELIHOOD (Orange):\", size = 3, fontface = \"bold\", hjust = 0, color = \"darkorange\") +\n  annotate(\"text\", x = likelihood_x, y = likelihood_y_start - 0.05, \n           label = \"H0: No difference vs H1: Some difference\", size = 2.5, hjust = 0, color = \"darkorange\") +\n  annotate(\"text\", x = likelihood_x, y = likelihood_y_start - 0.08, \n           label = paste0(\"Observed difference = \", round(observed_diff, 3)), size = 2.5, hjust = 0, color = \"darkorange\") +\n  annotate(\"text\", x = likelihood_x, y = likelihood_y_start - 0.11, \n           label = paste0(\"Confidence in observed effect = \", round(dnorm(observed_diff, observed_diff, likelihood_sd) * 100, 1), \"%\"), size = 2.5, hjust = 0, color = \"darkorange\") +\n  \n  # PRIOR annotation (top right) - moved up more\n  annotate(\"text\", x = prior_x, y = prior_y_start, \n           label = \"PRIOR (Grey):\", size = 3, fontface = \"bold\", hjust = 0) +\n  annotate(\"text\", x = prior_x, y = prior_y_start - 0.05, \n           label = \"Skeptical belief before data\", size = 2.5, hjust = 0) +\n  annotate(\"text\", x = prior_x, y = prior_y_start - 0.08, \n           label = \"Centered at 0 (no effect)\", size = 2.5, hjust = 0) +\n  annotate(\"text\", x = prior_x, y = prior_y_start - 0.11, \n           label = \"Wide spread = uncertainty\", size = 2.5, hjust = 0) +\n  \n  # Add interpretation of the null hypothesis line\n  annotate(\"text\", x = null_x, y = null_y_start, \n           label = \"NULL HYPOTHESIS (Red):\", size = 3, fontface = \"bold\", hjust = 0, color = \"darkred\") +\n  annotate(\"text\", x = null_x, y = null_y_start - 0.05, \n           label = \"H0: No treatment effect\", size = 2.5, hjust = 0, color = \"darkred\") +\n  annotate(\"text\", x = null_x, y = null_y_start - 0.08, \n           label = \"Values &lt; 0 = Usual care better\", size = 2.5, hjust = 0, color = \"darkred\") +\n  annotate(\"text\", x = null_x, y = null_y_start - 0.11, \n           label = \"Values &gt; 0 = Chatbot better\", size = 2.5, hjust = 0, color = \"darkred\") +\n  \n  # Add natural language interpretation aligned with NULL HYPOTHESIS\n  annotate(\"text\", x = interpretation_x, y = interpretation_y_start, \n           label = \"INTERPRETATION:\", size = 3, fontface = \"bold\", hjust = 0, color = \"darkgreen\") +\n  annotate(\"text\", x = interpretation_x, y = interpretation_y_start - 0.05, \n           label = paste0(\"If I had 50% credence that there was no difference\"), size = 2.5, hjust = 0, color = \"darkgreen\") +\n  annotate(\"text\", x = interpretation_x, y = interpretation_y_start - 0.08, \n           label = paste0(\"before this evidence, after updating on ONLY this\"), size = 2.5, hjust = 0, color = \"darkgreen\") +\n  annotate(\"text\", x = interpretation_x, y = interpretation_y_start - 0.11, \n           label = paste0(\"I should now believe it with confidence of \", round(prob_positive * 100, 1), \"%\"), size = 2.5, hjust = 0, color = \"darkgreen\") +\n  annotate(\"text\", x = interpretation_x, y = interpretation_y_start - 0.14, \n           label = paste0(\"Prior confidence in effect size = \", round(dnorm(observed_diff, 0, 1) * 100, 1), \"%\"), size = 2.5, hjust = 0, color = \"darkgreen\") +\n  annotate(\"text\", x = interpretation_x, y = interpretation_y_start - 0.17, \n           label = paste0(\"After updating: confidence in effect size = \", round(dnorm(observed_diff, posterior_mean, posterior_sd) * 100, 1), \"%\"), size = 2.5, hjust = 0, color = \"darkgreen\") +\n  \n  labs(title = \"Bayesian Analysis: Prior, Likelihood, and Posterior\",\n       subtitle = paste(\"Confidence in posterior mean =\", round(dnorm(posterior_mean, posterior_mean, posterior_sd) * 100, 1), \"%\", \n                       \"| Posterior mean =\", round(posterior_mean, 3)),\n       x = \"Effect Size (Difference in PHQ-9 Change)\", y = \"Density\",\n       caption = \"Red line = H0 (no effect) | Blue line = Posterior mean | Gray = Prior | Orange = Likelihood | Blue = Posterior\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5)) +\n  scale_color_manual(values = c(\"Prior\" = \"gray\", \"Likelihood\" = \"orange\", \"Posterior\" = \"blue\"))\n\nprint(bayesian_plot)\n\n\n\n\n\n\n\n\n\n# Low Cohen's d suggests the effect might be smaller than initially estimated\n# We'll use the observed Cohen's d as evidence to update our belief\nstage2_prior_mean &lt;- posterior_mean\nstage2_prior_sd &lt;- posterior_sd\nstage2_likelihood_mean &lt;- cohens_d  # Cohen's d as evidence\nstage2_likelihood_sd &lt;- 0.1  # Uncertainty around Cohen's d estimate\n\n# Stage 2 posterior parameters\nstage2_posterior_precision &lt;- 1/stage2_prior_sd^2 + 1/stage2_likelihood_sd^2\nstage2_posterior_sd &lt;- sqrt(1/stage2_posterior_precision)\nstage2_posterior_mean &lt;- (stage2_prior_mean/stage2_prior_sd^2 + stage2_likelihood_mean/stage2_likelihood_sd^2) / stage2_posterior_precision\n\n\nShow the code\n# Visualization 16: Comparison of significant vs non-significant outcomes\n# Calculate statistics for both measures\nphq9_change_chatbot &lt;- therapy_data$change_phq9[therapy_data$group == \"Chatbot\"]\nphq9_change_usual &lt;- therapy_data$change_phq9[therapy_data$group == \"Usual Care\"]\nepds_change_chatbot &lt;- therapy_data$change_epds[therapy_data$group == \"Chatbot\"]\nepds_change_usual &lt;- therapy_data$change_epds[therapy_data$group == \"Usual Care\"]\n\n# T-tests for both measures\nphq9_test &lt;- t.test(phq9_change_chatbot, phq9_change_usual)\nepds_test &lt;- t.test(epds_change_chatbot, epds_change_usual)\n\n# Effect sizes\nphq9_cohens_d &lt;- (mean(phq9_change_chatbot) - mean(phq9_change_usual)) / \n                 sqrt(((length(phq9_change_chatbot)-1)*var(phq9_change_chatbot) + \n                       (length(phq9_change_usual)-1)*var(phq9_change_usual)) / \n                      (length(phq9_change_chatbot) + length(phq9_change_usual) - 2))\n\nepds_cohens_d &lt;- (mean(epds_change_chatbot) - mean(epds_change_usual)) / \n                 sqrt(((length(epds_change_chatbot)-1)*var(epds_change_chatbot) + \n                       (length(epds_change_usual)-1)*var(epds_change_usual)) / \n                      (length(epds_change_chatbot) + length(epds_change_usual) - 2))\n\n# Create comparison data\ncomparison_data &lt;- data.frame(\n  measure = rep(c(\"PHQ-9\", \"EPDS\"), each = 2),\n  group = rep(c(\"Chatbot\", \"Usual Care\"), 2),\n  mean_change = c(mean(phq9_change_chatbot), mean(phq9_change_usual),\n                  mean(epds_change_chatbot), mean(epds_change_usual)),\n  se = c(sd(phq9_change_chatbot)/sqrt(length(phq9_change_chatbot)), \n         sd(phq9_change_usual)/sqrt(length(phq9_change_usual)),\n         sd(epds_change_chatbot)/sqrt(length(epds_change_chatbot)), \n         sd(epds_change_usual)/sqrt(length(epds_change_usual))),\n  p_value = c(phq9_test$p.value, phq9_test$p.value, epds_test$p.value, epds_test$p.value),\n  cohens_d = c(phq9_cohens_d, phq9_cohens_d, epds_cohens_d, epds_cohens_d)\n)\n\ncomparison_plot &lt;- ggplot(comparison_data, aes(x = measure, y = mean_change, fill = group)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", alpha = 0.8) +\n  geom_errorbar(aes(ymin = mean_change - 1.96*se, ymax = mean_change + 1.96*se), \n                position = position_dodge(width = 0.9), width = 0.2, linewidth = 1) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\", alpha = 0.7) +\n  geom_text(aes(label = paste0(\"p = \", round(p_value, 3), \"\\nd = \", round(cohens_d, 3))), \n            position = position_dodge(width = 0.9), vjust = -0.5, size = 3) +\n  labs(title = \"Comparison: Significant vs Non-Significant Outcomes\",\n       subtitle = \"PHQ-9 (significant) vs EPDS (non-significant)\",\n       x = \"Depression Measure\", y = \"Mean Change in Score\",\n       caption = add_color_samples(\"Error bars = 95% CI | Red line = No change | Negative = Improvement\", c(\"Red\" = \"red\"))) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5)) +\n  scale_fill_manual(values = c(\"Chatbot\" = \"steelblue\", \"Usual Care\" = \"orange\"))\n\nprint(comparison_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Visualization 17: Side-by-side null hypothesis testing\n# Create null distributions for both measures\nset.seed(456)\nn_simulations &lt;- 10000\n\n# PHQ-9 null distribution\nphq9_null_differences &lt;- numeric(n_simulations)\nfor(i in 1:n_simulations) {\n  shuffled_phq9 &lt;- sample(therapy_data$change_phq9)\n  chatbot_phq9 &lt;- shuffled_phq9[1:length(phq9_change_chatbot)]\n  usual_phq9 &lt;- shuffled_phq9[(length(phq9_change_chatbot)+1):length(shuffled_phq9)]\n  phq9_null_differences[i] &lt;- mean(chatbot_phq9) - mean(usual_phq9)\n}\n\n# EPDS null distribution\nepds_null_differences &lt;- numeric(n_simulations)\nfor(i in 1:n_simulations) {\n  shuffled_epds &lt;- sample(therapy_data$change_epds)\n  chatbot_epds &lt;- shuffled_epds[1:length(epds_change_chatbot)]\n  usual_epds &lt;- shuffled_epds[(length(epds_change_chatbot)+1):length(shuffled_epds)]\n  epds_null_differences[i] &lt;- mean(chatbot_epds) - mean(usual_epds)\n}\n\n# Observed differences\nphq9_observed_diff &lt;- mean(phq9_change_chatbot) - mean(phq9_change_usual)\nepds_observed_diff &lt;- mean(epds_change_chatbot) - mean(epds_change_usual)\n\n# Create combined null distribution plot\nnull_comparison_data &lt;- data.frame(\n  difference = c(phq9_null_differences, epds_null_differences),\n  measure = rep(c(\"PHQ-9\", \"EPDS\"), each = n_simulations)\n)\n\nnull_comparison_plot &lt;- ggplot(null_comparison_data, aes(x = difference, fill = measure)) +\n  geom_histogram(bins = 50, alpha = 0.6, position = \"identity\") +\n  geom_vline(xintercept = phq9_observed_diff, color = \"red\", linewidth = 2) +\n  geom_vline(xintercept = epds_observed_diff, color = \"blue\", linewidth = 2) +\n  geom_vline(xintercept = 0, color = \"black\", linewidth = 1, linetype = \"dotted\") +\n  facet_wrap(~measure, scales = \"free_x\") +\n  labs(title = \"Null Hypothesis Testing: PHQ-9 vs EPDS\",\n       subtitle = paste(\"PHQ-9 p =\", round(mean(abs(phq9_null_differences) &gt;= abs(phq9_observed_diff)), 4),\n                       \"| EPDS p =\", round(mean(abs(epds_null_differences) &gt;= abs(epds_observed_diff)), 4)),\n       x = \"Difference in Mean Change (Chatbot - Usual Care)\", y = \"Frequency\",\n       caption = add_color_samples(\"Red line = PHQ-9 observed | Blue line = EPDS observed | Black = H0\", \n                                 c(\"Red\" = \"red\", \"Blue\" = \"blue\"))) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5)) +\n  scale_fill_manual(values = c(\"PHQ-9\" = \"red\", \"EPDS\" = \"blue\"))\n\nprint(null_comparison_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Visualization 18: Effect size comparison\neffect_size_comparison &lt;- data.frame(\n  measure = c(\"PHQ-9\", \"EPDS\"),\n  cohens_d = c(phq9_cohens_d, epds_cohens_d),\n  p_value = c(phq9_test$p.value, epds_test$p.value),\n  significant = c(phq9_test$p.value &lt; 0.05, epds_test$p.value &lt; 0.05)\n)\n\neffect_comparison_plot &lt;- ggplot(effect_size_comparison, aes(x = measure, y = abs(cohens_d), fill = significant)) +\n  geom_bar(stat = \"identity\", alpha = 0.8) +\n  geom_text(aes(label = paste0(\"d = \", round(cohens_d, 3), \"\\np = \", round(p_value, 4))), \n            vjust = -0.5, size = 4) +\n  geom_hline(yintercept = c(0.2, 0.5, 0.8), linetype = \"dashed\", color = \"gray\", alpha = 0.7) +\n  geom_text(aes(x = 0.5, y = 0.25, label = \"Small\"), color = \"gray\", size = 3) +\n  geom_text(aes(x = 0.5, y = 0.55, label = \"Medium\"), color = \"gray\", size = 3) +\n  geom_text(aes(x = 0.5, y = 0.85, label = \"Large\"), color = \"gray\", size = 3) +\n  labs(title = \"Effect Size Comparison: PHQ-9 vs EPDS\",\n       subtitle = \"Absolute Cohen's d values with significance\",\n       x = \"Depression Measure\", y = \"|Cohen's d|\",\n       caption = \"Dashed lines = Effect size thresholds | Color = Statistical significance\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5)) +\n  scale_fill_manual(values = c(\"TRUE\" = \"darkgreen\", \"FALSE\" = \"orange\"))\n\nprint(effect_comparison_plot)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Visualization 19: Confidence intervals comparison\n# Calculate CIs for both measures\nphq9_ci &lt;- t.test(phq9_change_chatbot, phq9_change_usual)$conf.int\nepds_ci &lt;- t.test(epds_change_chatbot, epds_change_usual)$conf.int\n\nci_comparison_data &lt;- data.frame(\n  measure = c(\"PHQ-9\", \"EPDS\"),\n  mean_diff = c(phq9_observed_diff, epds_observed_diff),\n  lower = c(phq9_ci[1], epds_ci[1]),\n  upper = c(phq9_ci[2], epds_ci[2]),\n  significant = c(phq9_ci[1] &gt; 0 || phq9_ci[2] &lt; 0, epds_ci[1] &gt; 0 || epds_ci[2] &lt; 0)\n)\n\nci_comparison_plot &lt;- ggplot(ci_comparison_data, aes(y = measure)) +\n  geom_errorbar(aes(xmin = lower, xmax = upper, color = significant), \n                linewidth = 2, width = 0.3) +\n  geom_point(aes(x = mean_diff, color = significant), size = 4) +\n  geom_vline(xintercept = 0, color = \"red\", linewidth = 2, linetype = \"dashed\") +\n  geom_text(aes(x = lower - 0.1, label = paste0(\"[\", round(lower, 3), \", \", round(upper, 3), \"]\")), \n            hjust = 1, size = 3) +\n  labs(title = \"95% Confidence Intervals: PHQ-9 vs EPDS\",\n       subtitle = \"Does the interval exclude zero?\",\n       x = \"Difference in Mean Change (Chatbot - Usual Care)\", y = \"Measure\",\n       caption = add_color_samples(\"Red line = H0 (no difference) | Color = CI excludes 0\", c(\"Red\" = \"red\"))) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5)) +\n  scale_color_manual(values = c(\"TRUE\" = \"darkgreen\", \"FALSE\" = \"orange\"))\n\nprint(ci_comparison_plot)"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/index.html",
    "href": "src/blog/misc/bible-society-uk-revival/index.html",
    "title": "Bible Society UK Revival",
    "section": "",
    "text": "This section contains a comprehensive analysis of Bible Society UK’s claim of a “Quiet Revival” based on YouGov survey data comparing church attendance patterns between 2018 and 2024.\nThe claim asserts that weekly church attendance increased from 7% (2018) to 11% (2024), representing a 4 percentage point increase. However, our analysis identifies multiple critical methodological issues that cast serious doubt on this claim."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/index.html#overview",
    "href": "src/blog/misc/bible-society-uk-revival/index.html#overview",
    "title": "Bible Society UK Revival",
    "section": "",
    "text": "This section contains a comprehensive analysis of Bible Society UK’s claim of a “Quiet Revival” based on YouGov survey data comparing church attendance patterns between 2018 and 2024.\nThe claim asserts that weekly church attendance increased from 7% (2018) to 11% (2024), representing a 4 percentage point increase. However, our analysis identifies multiple critical methodological issues that cast serious doubt on this claim."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/index.html#analysis-pages",
    "href": "src/blog/misc/bible-society-uk-revival/index.html#analysis-pages",
    "title": "Bible Society UK Revival",
    "section": "Analysis Pages",
    "text": "Analysis Pages\n\n1. General Overview\nComprehensive descriptive comparison of all survey data: - Complete survey metadata and characteristics - Question format documentation - Full attendance distribution comparisons (all categories) - Demographic breakdowns (age, ethnicity, gender) - Internal consistency checks - Summary dashboard of key metrics - Visual comparisons throughout\n\n\n2. Critical Analysis Overview\nComprehensive critical evaluation with visual evidence: - Executive summary of findings and verdict - Visual summaries of key metrics - Red flag identification and severity assessment - Complete attendance distribution comparison - Immigration impact analysis - Evidence quality dashboard\n\n\n3. Weekly Attendance Claim Analysis\nStatistical testing of the 7% → 11% increase claim: - Point estimates with confidence intervals - Hypothesis testing (with design effect adjustment) - Effect size calculations (Cohen’s h) - Visualisation of results\n\n\n4. Question Order Effects\nImpact of different survey question formats: - Comparison of 2018 vs 2024 question formats - Internal consistency checks within 2024 survey - Evidence of acquiescence bias and anchoring effects - Contradictory results analysis\n\n\n5. Demographic Analysis\nPopulation composition changes and their impact: - Attendance by ethnicity and age groups - Impact of immigration (Ukrainian refugees, Hong Kong BN(O) visa holders) - Composition vs behaviour change confound - Implications for the “revival” claim"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/index.html#key-findings",
    "href": "src/blog/misc/bible-society-uk-revival/index.html#key-findings",
    "title": "Bible Society UK Revival",
    "section": "Key Findings",
    "text": "Key Findings\nOur analysis reveals multiple red flags:\n\nInternal Inconsistencies: The 2024 survey shows contradictory results\nQuestion Order Effects: Different question formats make comparison invalid\nDemographic Confounds: Population changes may explain apparent increases\nSmall Effect Sizes: Even if statistically significant, practical significance is limited"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/index.html#data-sources",
    "href": "src/blog/misc/bible-society-uk-revival/index.html#data-sources",
    "title": "Bible Society UK Revival",
    "section": "Data Sources",
    "text": "Data Sources\n\n2018 Survey: n = 19,101 (weighted: 19,875), October-November 2018\n2024 Survey: n = 13,146 (weighted: 12,455), November-December 2024\nSource Documents: resources/papers/BibleSoc_Results_2018.pdf, BibleSoc_Results_2024.pdf\nExtracted Data: data/bible-society-uk-revival/processed/"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/index.html#documentation",
    "href": "src/blog/misc/bible-society-uk-revival/index.html#documentation",
    "title": "Bible Society UK Revival",
    "section": "Documentation",
    "text": "Documentation\nFor detailed methodology, analysis plans, and technical specifications, see: - docs/tech-specs/bible-society-review/overview.md - Comprehensive analysis framework - docs/tech-specs/bible-society-review/red-flag-summary.md - Summary of critical issues"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/demographic-analysis.html",
    "href": "src/blog/misc/bible-society-uk-revival/demographic-analysis.html",
    "title": "Demographic Analysis",
    "section": "",
    "text": "Between 2018 and 2024, the UK population composition changed significantly due to immigration, particularly:\n\nUkrainian refugees: ~217,000-255,000 (post-February 2022)\nHong Kong BN(O) visa holders: &gt;163,000 (January 2021 - March 2025)\nOther net migration changes\n\nThese groups may have different religious attendance patterns than the existing UK population, which could explain apparent changes in church attendance."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/demographic-analysis.html#introduction",
    "href": "src/blog/misc/bible-society-uk-revival/demographic-analysis.html#introduction",
    "title": "Demographic Analysis",
    "section": "",
    "text": "Between 2018 and 2024, the UK population composition changed significantly due to immigration, particularly:\n\nUkrainian refugees: ~217,000-255,000 (post-February 2022)\nHong Kong BN(O) visa holders: &gt;163,000 (January 2021 - March 2025)\nOther net migration changes\n\nThese groups may have different religious attendance patterns than the existing UK population, which could explain apparent changes in church attendance."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/demographic-analysis.html#attendance-by-ethnicity-2024",
    "href": "src/blog/misc/bible-society-uk-revival/demographic-analysis.html#attendance-by-ethnicity-2024",
    "title": "Demographic Analysis",
    "section": "Attendance by Ethnicity (2024)",
    "text": "Attendance by Ethnicity (2024)\n\n\nShow the code\nattendance_data &lt;- read_csv(here::here(\"data/bible-society-uk-revival/processed/church-attendance-extracted.csv\"))\n\n# Extract 2024 attendance by ethnicity\nethnicity_2024 &lt;- attendance_data %&gt;%\n  filter(year == 2024, question_type == \"binary\", \n         response_category == \"Yes - in the past year\") %&gt;%\n  select(response_category, white, ethnic_minority) %&gt;%\n  rename(White = white, `Ethnic Minority` = ethnic_minority)\n\n# Reshape for plotting\nethnicity_plot_data &lt;- ethnicity_2024 %&gt;%\n  pivot_longer(cols = c(White, `Ethnic Minority`), \n               names_to = \"Ethnicity\", values_to = \"Percentage\")\n\n\n\n2024 Attendance by Ethnicity\nThe data for 2024 shows a notable difference in church attendance between White and Ethnic Minority respondents.\n\nWhite: 23.0% attended in the past year.\nEthnic Minority: 24.0% attended in the past year.\n\nThis disparity is visualized in the bar chart below.\n\n\nShow the code\nggplot(ethnicity_plot_data, aes(x = Ethnicity, y = Percentage, fill = Ethnicity)) +\n  geom_col(alpha = 0.8, show.legend = FALSE) +\n  geom_text(aes(label = sprintf(\"%.1f%%\", Percentage)), vjust = -0.5, size = 4) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(\n    x = \"Ethnicity\",\n    y = \"Attended in Past Year (%)\",\n    title = \"Church Attendance by Ethnicity in 2024\"\n  ) +\n  theme_minimal(base_size = 12)\n\n\n\n\n\nChurch attendance in the past year by ethnicity (2024)\n\n\n\n\n⚠️ Note: These figures suggest different attendance patterns between ethnic groups. Population composition changes could significantly affect overall attendance rates."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/demographic-analysis.html#age-stratified-analysis",
    "href": "src/blog/misc/bible-society-uk-revival/demographic-analysis.html#age-stratified-analysis",
    "title": "Demographic Analysis",
    "section": "Age-Stratified Analysis",
    "text": "Age-Stratified Analysis\n\n\nShow the code\n# Weekly attendance for 2018\nage_2018 &lt;- attendance_data %&gt;%\n  filter(year == 2018, response_category == \"At least once a week\")\n\n# Weekly attendance for 2024 (sum of categories)\nage_2024 &lt;- attendance_data %&gt;%\n  filter(\n    year == 2024,\n    question_type == \"frequency\",\n    response_category %in% c(\"Daily/almost daily\", \"A few times a week\", \"About once a week\")\n  ) %&gt;%\n  group_by(year, question_type) %&gt;%\n  summarise(\n    across(c(age_18_34, age_35_54, age_55plus), sum, na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(response_category = \"At least once a week\") # Add this for consistency\n\n# Combine and create age_comparison\nage_comparison &lt;- bind_rows(age_2018, age_2024) %&gt;%\n  select(year, age_18_34, age_35_54, age_55plus) %&gt;%\n  rename(\n    Year = year,\n    `18-34` = age_18_34,\n    `35-54` = age_35_54,\n    `55+` = age_55plus\n  )\n\n\n\n2018\n\n18-34: 4.0%\n35-54: 5.0%\n55+: 10.0%\n\n\n\n2024\n\n18-34: 16.0%\n35-54: 7.0%\n55+: 12.0%\n\n\n\nChanges (2024 - 2018)\n\n18-34: +12.0 percentage points\n35-54: +2.0 percentage points\n55+: +2.0 percentage points"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/demographic-analysis.html#visualisation-age-stratified-changes",
    "href": "src/blog/misc/bible-society-uk-revival/demographic-analysis.html#visualisation-age-stratified-changes",
    "title": "Demographic Analysis",
    "section": "Visualisation: Age-Stratified Changes",
    "text": "Visualisation: Age-Stratified Changes\n\n\nShow the code\n# Calculate changes in a robust way\ndata_2018 &lt;- age_comparison %&gt;%\n  filter(Year == 2018) %&gt;%\n  pivot_longer(cols = -Year, names_to = \"Age_Group\", values_to = \"y2018\") %&gt;%\n  select(-Year)\n\ndata_2024 &lt;- age_comparison %&gt;%\n  filter(Year == 2024) %&gt;%\n  pivot_longer(cols = -Year, names_to = \"Age_Group\", values_to = \"y2024\") %&gt;%\n  select(-Year)\n\nage_changes &lt;- full_join(data_2018, data_2024, by = \"Age_Group\") %&gt;%\n  mutate(\n    y2018 = ifelse(is.na(y2018), 0, y2018),\n    y2024 = ifelse(is.na(y2024), 0, y2024),\n    change = y2024 - y2018\n  ) %&gt;%\n  mutate(\n    Age_Group = factor(Age_Group, levels = c(\"18-34\", \"35-54\", \"55+\")),\n    change_color = ifelse(change &gt; 0, \"darkgreen\", \"darkred\")\n  )\n\n# Plot the changes\nggplot(age_changes, aes(x = Age_Group, y = change, fill = change_color)) +\n  geom_col(alpha = 0.8) +\n  geom_text(aes(label = sprintf(\"%+.1f\", .data$change)), vjust = -0.5) +\n  scale_fill_identity() +\n  labs(\n    x = \"Age Group\",\n    y = \"Percentage Point Change\",\n    title = \"Change in Weekly Church Attendance (2018 to 2024)\",\n    subtitle = \"By age group\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\nChange in weekly attendance by age group: 2018 vs 2024"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/demographic-analysis.html#full-frequency-distribution-2018-vs-2024",
    "href": "src/blog/misc/bible-society-uk-revival/demographic-analysis.html#full-frequency-distribution-2018-vs-2024",
    "title": "Demographic Analysis",
    "section": "Full Frequency Distribution (2018 vs 2024)",
    "text": "Full Frequency Distribution (2018 vs 2024)\nWhile the age-stratified analysis focuses on weekly attendance, looking at the full distribution of attendance frequency provides a more complete picture of how response patterns have changed between the two surveys.\nThe plot below compares the percentage of respondents in each attendance category for both 2018 and 2024.\n\n\nShow the code\nfrequency_data &lt;- attendance_data %&gt;%\n  filter(\n    (year == 2018) | (year == 2024 & question_type == \"frequency\")\n  ) %&gt;%\n  filter(response_category != \"At least once a week\") %&gt;%\n  mutate(\n    Year = factor(year),\n    response_category = factor(response_category, levels = c(\n      \"Daily/almost daily\", \"A few times a week\", \"About once a week\",\n      \"About once a fortnight\", \"About once a month\", \"A few times a year\",\n      \"About once a year\", \"Never\"\n    ))\n  )\n\n\n\n\nShow the code\nggplot(frequency_data, aes(x = response_category, y = total_pct, fill = Year)) +\n  geom_col(position = \"dodge\", alpha = 0.8) +\n  scale_fill_manual(values = c(\"2018\" = \"steelblue\", \"2024\" = \"darkorange\")) +\n  labs(\n    x = \"Attendance Frequency\",\n    y = \"Percentage (%)\",\n    title = \"Attendance Frequency Distribution: 2018 vs 2024\",\n    subtitle = \"Comparison of all response categories\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\nComparison of attendance frequency distribution (2018 vs 2024)\n\n\n\n\nThis visualization highlights that while weekly attendance appears to have increased, the proportion of people who “Never” attend has also increased. This contradictory finding is another red flag that suggests the survey data may not be directly comparable due to the methodological changes discussed previously."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/demographic-analysis.html#the-demographic-composition-problem",
    "href": "src/blog/misc/bible-society-uk-revival/demographic-analysis.html#the-demographic-composition-problem",
    "title": "Demographic Analysis",
    "section": "The Demographic Composition Problem",
    "text": "The Demographic Composition Problem\nCritical Issue: The surveys do not appear to control for demographic composition changes.\n\nMajor population changes 2018-2024\n\nUkrainian refugees: 217,000-255,000\n\nHigher Orthodox Christian attendance rates\nDifferent cultural patterns\n\nHong Kong BN(O) visa holders: &gt;163,000\n\nDifferent religious demographics\nMay have higher church attendance rates\n\nOther net migration: Substantial\n\n\n\n⚠️ PROBLEM\nIf the surveys are not weighted or standardised to account for these demographic shifts, any apparent change in attendance could simply reflect:\n\nMore religious immigrants entering the population\nDifferent attendance patterns of new arrivals\nNOT a ‘revival’ among existing UK residents\n\nThis is a form of ‘composition change’ vs ‘behaviour change’ confound that must be addressed to make valid comparisons."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/demographic-analysis.html#implications",
    "href": "src/blog/misc/bible-society-uk-revival/demographic-analysis.html#implications",
    "title": "Demographic Analysis",
    "section": "Implications",
    "text": "Implications\nWithout demographic standardisation, we cannot determine whether:\n\nAttendance genuinely increased among existing UK residents (revival)\nAttendance increased due to immigration (composition effect)\nA combination of both\n\nRecommendation: Any claims about a “revival” should control for demographic composition changes through: - Demographic weighting adjustments - Stratified analysis by immigration status - Age/ethnicity standardisation\nUntil such analyses are conducted, the demographic composition issue remains a critical red flag."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/question-order-effects.html",
    "href": "src/blog/misc/bible-society-uk-revival/question-order-effects.html",
    "title": "Question Order Effects",
    "section": "",
    "text": "The 2018 and 2024 surveys used fundamentally different question formats:\n\n2018: Single frequency question only\n2024: Binary question FIRST (“Yes - in the past year”), THEN frequency question\n\nThis violates best practice in survey methodology, as question order can significantly bias responses."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/question-order-effects.html#the-problem",
    "href": "src/blog/misc/bible-society-uk-revival/question-order-effects.html#the-problem",
    "title": "Question Order Effects",
    "section": "",
    "text": "The 2018 and 2024 surveys used fundamentally different question formats:\n\n2018: Single frequency question only\n2024: Binary question FIRST (“Yes - in the past year”), THEN frequency question\n\nThis violates best practice in survey methodology, as question order can significantly bias responses."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/question-order-effects.html#question-format-comparison",
    "href": "src/blog/misc/bible-society-uk-revival/question-order-effects.html#question-format-comparison",
    "title": "Question Order Effects",
    "section": "Question Format Comparison",
    "text": "Question Format Comparison\n\n2018 Survey Format\nQuestion: ‘Apart from weddings, baptisms/christenings, and funerals how often, if at all, did you go to a church service in the last year?’\nResponse options: - Daily/almost daily - A few times a week - About once a week - [other frequency options…] - Never\n\n\n2024 Survey Format\nQuestion 1 (BINARY): ‘Have you attended a church service in the past year?’ - Yes - in the past year - Yes - more than a year ago - Never\nQuestion 2 (FREQUENCY): ‘How often did you attend?’ [Same frequency scale as 2018]\n🚩 CRITICAL: The binary question primes respondents before they consider frequency, which can lead to:\n\nAcquiescence bias (tendency to say ‘yes’)\nAnchoring effects (binary framing affects frequency judgements)\nNon-comparable measures between years"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/question-order-effects.html#internal-consistency-check",
    "href": "src/blog/misc/bible-society-uk-revival/question-order-effects.html#internal-consistency-check",
    "title": "Question Order Effects",
    "section": "Internal Consistency Check",
    "text": "Internal Consistency Check\nIf the questions are measuring the same thing, the binary response should match the sum of frequency responses:\n\n\nShow the code\nattendance_data &lt;- read_csv(here::here(\"data/bible-society-uk-revival/processed/church-attendance-extracted.csv\"))\n\n# 2024 binary response\nbinary_2024 &lt;- attendance_data %&gt;%\n  filter(year == 2024, question_type == \"binary\", \n         response_category == \"Yes - in the past year\") %&gt;%\n  pull(total_pct)\n\n# Sum of frequency responses (past year categories)\nfreq_2024 &lt;- attendance_data %&gt;%\n  filter(year == 2024, question_type == \"frequency\") %&gt;%\n  filter(response_category %in% c(\n    \"Daily/almost daily\", \"A few times a week\", \n    \"About once a week\", \"About once a fortnight\",\n    \"About once a month\", \"A few times a year\",\n    \"About once a year\"\n  ))\n\nfreq_sum_2024 &lt;- sum(freq_2024$total_pct, na.rm = TRUE)\ndiscrepancy &lt;- abs(freq_sum_2024 - binary_2024)\nis_inconsistent &lt;- discrepancy &gt; 2\n\n\n\nInternal Consistency Check (2024)\nIf the questions are measuring the same thing, the binary response should match the sum of frequency responses:\n\nBinary ‘Yes - in the past year’: 24.0%\nSum of frequency categories: 26.0%\nDiscrepancy: 2.0 percentage points\n\n✓ Responses are internally consistent"
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/question-order-effects.html#evidence-from-survey-methodology-literature",
    "href": "src/blog/misc/bible-society-uk-revival/question-order-effects.html#evidence-from-survey-methodology-literature",
    "title": "Question Order Effects",
    "section": "Evidence from Survey Methodology Literature",
    "text": "Evidence from Survey Methodology Literature\nQuestion order effects are well-documented:\n\nSchuman & Presser (1996): Found order effects of 5-15 percentage points\nAcquiescence bias: Tendency to agree with yes/no questions\nAnchoring effects: First question frames subsequent responses\n\nThe 2024 survey design violates the principle that questions should be asked in a way that minimises priming effects when making comparisons over time."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/question-order-effects.html#impact-on-weekly-attendance-claim",
    "href": "src/blog/misc/bible-society-uk-revival/question-order-effects.html#impact-on-weekly-attendance-claim",
    "title": "Question Order Effects",
    "section": "Impact on Weekly Attendance Claim",
    "text": "Impact on Weekly Attendance Claim\n\n\nShow the code\n# Weekly attendance in 2024 might be inflated by:\n# 1. Acquiescence bias from binary question\n# 2. Anchoring effects affecting frequency judgements\n\nweekly_2018 &lt;- attendance_data %&gt;%\n  filter(year == 2018, response_category == \"At least once a week\") %&gt;%\n  pull(total_pct) / 100\n\nweekly_2024 &lt;- attendance_data %&gt;%\n  filter(\n    year == 2024,\n    question_type == \"frequency\",\n    response_category %in% c(\"Daily/almost daily\", \"A few times a week\", \"About once a week\")\n  ) %&gt;%\n  summarise(total_pct = sum(total_pct)) %&gt;%\n  pull(total_pct) / 100\n\n\n\nWeekly Attendance Comparison\nThe weekly attendance in 2024 might be inflated by acquiescence bias from the binary question and anchoring effects affecting frequency judgements:\n\n2018 (frequency question only): 7.0%\n2024 (after binary question): 11.0%\nDifference: +4.0 percentage points\n\n⚠️ CAUTION: The apparent increase may be an artefact of question order effects rather than true behavioural change. Without the binary priming question, the 2024 figure might be lower, showing no real change or even a decrease."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/question-order-effects.html#the-contradictory-evidence",
    "href": "src/blog/misc/bible-society-uk-revival/question-order-effects.html#the-contradictory-evidence",
    "title": "Question Order Effects",
    "section": "The Contradictory Evidence",
    "text": "The Contradictory Evidence\nInterestingly, the binary question itself shows a decrease:\n\n\nShow the code\n# 2018 \"ever attended\" estimate (sum of all frequency categories except \"Never\")\never_2018 &lt;- attendance_data %&gt;%\n  filter(year == 2018) %&gt;%\n  filter(response_category != \"Never\") %&gt;%\n  summarise(total = sum(total_pct, na.rm = TRUE)) %&gt;%\n  pull(total)\n\nbinary_2024 &lt;- attendance_data %&gt;%\n  filter(year == 2024, question_type == \"binary\", \n         response_category == \"Yes - in the past year\") %&gt;%\n  pull(total_pct)\n\n\n\n‘Ever Attended’ Comparison\nInterestingly, the binary question itself shows a decrease:\n\n2018 (frequency-based): ~52%\n2024 (binary question): 24.0%\nChange: -28.0 percentage points\n\n🚩 CONTRADICTION:\nThe binary question shows a DECREASE (27% → 24%), while the frequency question shows an INCREASE (7% → 11%). This contradiction is critical evidence:\nThese cannot both be true. This is strong evidence that question order effects are creating measurement error."
  },
  {
    "objectID": "src/blog/misc/bible-society-uk-revival/question-order-effects.html#conclusion",
    "href": "src/blog/misc/bible-society-uk-revival/question-order-effects.html#conclusion",
    "title": "Question Order Effects",
    "section": "Conclusion",
    "text": "Conclusion\nThe different question formats make direct comparison between 2018 and 2024 problematic. The question order effects likely:\n\nInflate the weekly attendance figure in 2024 due to acquiescence bias\nCreate internal inconsistencies within the 2024 survey\nProduce contradictory results that cannot both be true\n\nRecommendation: The 7% → 11% increase claim should be treated with extreme caution. The methodological differences make the comparison invalid without controlling for question order effects."
  },
  {
    "objectID": "src/teaching-stats/core-concepts/index.html",
    "href": "src/teaching-stats/core-concepts/index.html",
    "title": "Core Statistical Concepts",
    "section": "",
    "text": "This section covers fundamental statistical concepts through interactive demonstrations and explanations."
  },
  {
    "objectID": "src/teaching-stats/core-concepts/index.html#frequentist-statistics",
    "href": "src/teaching-stats/core-concepts/index.html#frequentist-statistics",
    "title": "Core Statistical Concepts",
    "section": "Frequentist Statistics",
    "text": "Frequentist Statistics\n\nCentral Limit Theorem - Understanding how sampling distributions approach normality\nDegrees of Freedom - Exploring the concept of degrees of freedom in statistical analysis"
  },
  {
    "objectID": "src/teaching-stats/core-concepts/degrees-of-freedom.html",
    "href": "src/teaching-stats/core-concepts/degrees-of-freedom.html",
    "title": "Degrees of Freedom",
    "section": "",
    "text": "Degrees of freedom (df) is one of the most confusing concepts in statistics, yet it’s fundamental to understanding statistical inference."
  },
  {
    "objectID": "src/teaching-stats/core-concepts/degrees-of-freedom.html#introduction",
    "href": "src/teaching-stats/core-concepts/degrees-of-freedom.html#introduction",
    "title": "Degrees of Freedom",
    "section": "",
    "text": "Degrees of freedom (df) is one of the most confusing concepts in statistics, yet it’s fundamental to understanding statistical inference."
  },
  {
    "objectID": "src/teaching-stats/core-concepts/degrees-of-freedom.html#what-are-degrees-of-freedom",
    "href": "src/teaching-stats/core-concepts/degrees-of-freedom.html#what-are-degrees-of-freedom",
    "title": "Degrees of Freedom",
    "section": "What Are Degrees of Freedom?",
    "text": "What Are Degrees of Freedom?\nDegrees of freedom represent the number of independent pieces of information available to estimate a parameter or test a hypothesis. Think of it as the number of “free choices” you have after accounting for constraints."
  },
  {
    "objectID": "src/teaching-stats/core-concepts/degrees-of-freedom.html#vector-examples",
    "href": "src/teaching-stats/core-concepts/degrees-of-freedom.html#vector-examples",
    "title": "Degrees of Freedom",
    "section": "Vector Examples",
    "text": "Vector Examples"
  },
  {
    "objectID": "src/teaching-stats/core-concepts/degrees-of-freedom.html#the-intuition-the-free-to-vary-concept",
    "href": "src/teaching-stats/core-concepts/degrees-of-freedom.html#the-intuition-the-free-to-vary-concept",
    "title": "Degrees of Freedom",
    "section": "The Intuition: The “Free to Vary” Concept",
    "text": "The Intuition: The “Free to Vary” Concept\n\nSimple Example: Three Numbers That Sum to 10\nLet’s start with a simple example to build intuition:\n\n\nShow the code\n# Check and install required packages\nrequired_packages &lt;- c(\"ggplot2\", \"dplyr\")\n\n# Load required packages\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\n\n# Install and load packages\n\n\n# Set seed for reproducibility\nset.seed(123)\n\n\n\n\nShow the code\n# Example: Three numbers that sum to 10\ncat(\"Constraint: x + y + z = 10\\n\\n\")\n\n\nConstraint: x + y + z = 10\n\n\nShow the code\n# If we know two numbers, the third is determined\nx &lt;- 3\ny &lt;- 4\nz &lt;- 10 - x - y  # z is NOT free to vary\n\ncat(\"If x =\", x, \"and y =\", y, \"then z MUST be\", z, \"\\n\")\n\n\nIf x = 3 and y = 4 then z MUST be 3 \n\n\nShow the code\ncat(\"Degrees of freedom = 2 (only x and y are free to vary)\\n\")\n\n\nDegrees of freedom = 2 (only x and y are free to vary)\n\n\n\n\nVisualizing the Constraint\n\n\nShow the code\n# Create a 2D visualization of the constraint x + y + z = 10\n# We'll show how z is determined by x and y\n\n# Generate points on the constraint plane\nx_vals &lt;- seq(0, 10, length.out = 50)\ny_vals &lt;- seq(0, 10, length.out = 50)\n\n# Create grid of x and y values\ngrid_data &lt;- expand.grid(x = x_vals, y = y_vals)\ngrid_data$z &lt;- 10 - grid_data$x - grid_data$y\n\n# Filter valid points (all coordinates &gt;= 0)\nvalid_points &lt;- grid_data[grid_data$z &gt;= 0, ]\n\n# Create 2D plot showing the constraint\nggplot(valid_points, aes(x = x, y = y, color = z)) +\n  geom_point(size = 1, alpha = 0.6) +\n  scale_color_gradient(low = \"blue\", high = \"red\", name = \"z value\") +\n  labs(title = \"Constraint: x + y + z = 10\",\n       subtitle = \"Color shows the z value (red = high, blue = low)\",\n       x = \"x value\", y = \"y value\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5)) +\n  geom_abline(intercept = 10, slope = -1, color = \"black\", linewidth = 1, linetype = \"dashed\") +\n  annotate(\"text\", x = 8, y = 1, label = \"x + y = 10\", color = \"black\", size = 4)"
  },
  {
    "objectID": "src/teaching-stats/core-concepts/degrees-of-freedom.html#degrees-of-freedom-in-sample-variance",
    "href": "src/teaching-stats/core-concepts/degrees-of-freedom.html#degrees-of-freedom-in-sample-variance",
    "title": "Degrees of Freedom",
    "section": "Degrees of Freedom in Sample Variance",
    "text": "Degrees of Freedom in Sample Variance\n\nThe Key Insight: Sample Mean Constrains the Data\nWhen we calculate sample variance, we use the sample mean as an estimate of the population mean. This creates a constraint that reduces our degrees of freedom.\n\n\nShow the code\n# Generate sample data\nsample_data &lt;- c(2, 4, 6, 8, 10)\nn &lt;- length(sample_data)\nsample_mean &lt;- mean(sample_data)\n\ncat(\"Sample data:\", paste(sample_data, collapse = \", \"), \"\\n\")\n\n\nSample data: 2, 4, 6, 8, 10 \n\n\nShow the code\ncat(\"Sample mean:\", sample_mean, \"\\n\")\n\n\nSample mean: 6 \n\n\nShow the code\ncat(\"Sample size (n):\", n, \"\\n\")\n\n\nSample size (n): 5 \n\n\nShow the code\ncat(\"Degrees of freedom for variance:\", n - 1, \"\\n\\n\")\n\n\nDegrees of freedom for variance: 4 \n\n\nShow the code\n# Show why we lose 1 degree of freedom\ncat(\"If we know the mean and n-1 values, the last value is determined:\\n\")\n\n\nIf we know the mean and n-1 values, the last value is determined:\n\n\nShow the code\nknown_values &lt;- sample_data[1:(n-1)]\nlast_value &lt;- n * sample_mean - sum(known_values)\ncat(\"Known values:\", paste(known_values, collapse = \", \"), \"\\n\")\n\n\nKnown values: 2, 4, 6, 8 \n\n\nShow the code\ncat(\"Last value MUST be:\", last_value, \"\\n\")\n\n\nLast value MUST be: 10 \n\n\nShow the code\ncat(\"This is why df = n - 1 for sample variance\\n\")\n\n\nThis is why df = n - 1 for sample variance\n\n\n\n\nVisualizing the Constraint in Sample Variance\n\n\nShow the code\n# Create visualization of the constraint\ndf_sample &lt;- data.frame(\n  x = 1:n,\n  y = sample_data,\n  point_type = \"Data\"\n)\n\n# Add the mean line\ndf_mean &lt;- data.frame(\n  x = c(0.5, n + 0.5),\n  y = c(sample_mean, sample_mean),\n  point_type = \"Mean\"\n)\n\n# Combine data\ndf_combined &lt;- rbind(df_sample, df_mean)\n\n# Create plot\nggplot(df_combined, aes(x = x, y = y, color = point_type)) +\n  geom_point(size = 3) +\n  geom_line(data = df_mean, linewidth = 2, linetype = \"dashed\") +\n  geom_segment(data = df_sample, aes(xend = x, yend = sample_mean), \n               color = \"red\", alpha = 0.5) +\n  labs(title = \"Sample Data with Mean Constraint\",\n       subtitle = \"Red lines show deviations from mean\",\n       x = \"Observation\", y = \"Value\",\n       color = \"Type\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5)) +\n  scale_color_manual(values = c(\"Data\" = \"blue\", \"Mean\" = \"red\"))"
  },
  {
    "objectID": "src/teaching-stats/core-concepts/degrees-of-freedom.html#degrees-of-freedom-in-different-contexts",
    "href": "src/teaching-stats/core-concepts/degrees-of-freedom.html#degrees-of-freedom-in-different-contexts",
    "title": "Degrees of Freedom",
    "section": "Degrees of Freedom in Different Contexts",
    "text": "Degrees of Freedom in Different Contexts\n\n1. One-Sample t-test\n\n\nShow the code\n# Simulate one-sample t-test\npopulation_mean &lt;- 100\nsample_size &lt;- 15\nsample_data &lt;- rnorm(sample_size, mean = 105, sd = 10)\n\n# Calculate t-statistic\nsample_mean &lt;- mean(sample_data)\nsample_se &lt;- sd(sample_data) / sqrt(sample_size)\nt_stat &lt;- (sample_mean - population_mean) / sample_se\ndf_t &lt;- sample_size - 1\n\ncat(\"One-Sample t-test:\\n\")\n\n\nOne-Sample t-test:\n\n\nShow the code\ncat(\"Sample size:\", sample_size, \"\\n\")\n\n\nSample size: 15 \n\n\nShow the code\ncat(\"Degrees of freedom:\", df_t, \"\\n\")\n\n\nDegrees of freedom: 14 \n\n\nShow the code\ncat(\"t-statistic:\", round(t_stat, 3), \"\\n\")\n\n\nt-statistic: 2.989 \n\n\nShow the code\ncat(\"p-value:\", round(2 * pt(-abs(t_stat), df_t), 4), \"\\n\")\n\n\np-value: 0.0098 \n\n\n\n\n2. Two-Sample t-test\n\n\nShow the code\n# Simulate two-sample t-test\nn1 &lt;- 12\nn2 &lt;- 10\ngroup1 &lt;- rnorm(n1, mean = 100, sd = 8)\ngroup2 &lt;- rnorm(n2, mean = 105, sd = 8)\n\n# Calculate pooled t-test\nmean1 &lt;- mean(group1)\nmean2 &lt;- mean(group2)\nvar1 &lt;- var(group1)\nvar2 &lt;- var(group2)\n\n# Pooled variance\npooled_var &lt;- ((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2)\npooled_se &lt;- sqrt(pooled_var * (1/n1 + 1/n2))\nt_stat_pooled &lt;- (mean1 - mean2) / pooled_se\ndf_pooled &lt;- n1 + n2 - 2\n\ncat(\"Two-Sample t-test (pooled):\\n\")\n\n\nTwo-Sample t-test (pooled):\n\n\nShow the code\ncat(\"Group 1 size:\", n1, \"\\n\")\n\n\nGroup 1 size: 12 \n\n\nShow the code\ncat(\"Group 2 size:\", n2, \"\\n\")\n\n\nGroup 2 size: 10 \n\n\nShow the code\ncat(\"Degrees of freedom:\", df_pooled, \"\\n\")\n\n\nDegrees of freedom: 20 \n\n\nShow the code\ncat(\"t-statistic:\", round(t_stat_pooled, 3), \"\\n\")\n\n\nt-statistic: -3.414 \n\n\nShow the code\ncat(\"p-value:\", round(2 * pt(-abs(t_stat_pooled), df_pooled), 4), \"\\n\")\n\n\np-value: 0.0028 \n\n\n\n\nVisualizing t-Distributions with Different Degrees of Freedom\n\n\nShow the code\n# Create t-distributions with different degrees of freedom\nx_vals &lt;- seq(-4, 4, length.out = 200)\ndf_values &lt;- c(1, 3, 10, 30)\n\n# Calculate t-distribution densities\nt_densities &lt;- data.frame()\nfor(df in df_values) {\n  density_vals &lt;- dt(x_vals, df = df)\n  t_densities &lt;- rbind(t_densities, \n                       data.frame(x = x_vals, density = density_vals, df = paste(\"df =\", df)))\n}\n\n# Add normal distribution for comparison\nnormal_density &lt;- dnorm(x_vals, mean = 0, sd = 1)\nt_densities &lt;- rbind(t_densities, \n                     data.frame(x = x_vals, density = normal_density, df = \"Normal\"))\n\n# Create plot\nggplot(t_densities, aes(x = x, y = density, color = df)) +\n  geom_line(linewidth = 1) +\n  labs(title = \"t-Distributions with Different Degrees of Freedom\",\n       subtitle = \"As df increases, t-distribution approaches normal\",\n       x = \"Value\", y = \"Density\",\n       color = \"Distribution\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5)) +\n  scale_color_brewer(palette = \"Set1\")"
  },
  {
    "objectID": "src/teaching-stats/core-concepts/degrees-of-freedom.html#degrees-of-freedom-in-chi-square-tests",
    "href": "src/teaching-stats/core-concepts/degrees-of-freedom.html#degrees-of-freedom-in-chi-square-tests",
    "title": "Degrees of Freedom",
    "section": "Degrees of Freedom in Chi-Square Tests",
    "text": "Degrees of Freedom in Chi-Square Tests\n\nChi-Square Goodness of Fit\n\n\nShow the code\n# Simulate chi-square goodness of fit test\nobserved &lt;- c(22, 18, 25, 15, 20)  # Observed counts\nexpected &lt;- rep(20, 5)  # Expected counts (equal probability)\n\n# Calculate chi-square statistic\nchi_sq &lt;- sum((observed - expected)^2 / expected)\ndf_chi &lt;- length(observed) - 1  # k - 1 categories\n\ncat(\"Chi-Square Goodness of Fit Test:\\n\")\n\n\nChi-Square Goodness of Fit Test:\n\n\nShow the code\ncat(\"Number of categories:\", length(observed), \"\\n\")\n\n\nNumber of categories: 5 \n\n\nShow the code\ncat(\"Degrees of freedom:\", df_chi, \"\\n\")\n\n\nDegrees of freedom: 4 \n\n\nShow the code\ncat(\"Chi-square statistic:\", round(chi_sq, 3), \"\\n\")\n\n\nChi-square statistic: 2.9 \n\n\nShow the code\ncat(\"p-value:\", round(1 - pchisq(chi_sq, df_chi), 4), \"\\n\")\n\n\np-value: 0.5747 \n\n\n\n\nVisualizing Chi-Square Distributions\n\n\nShow the code\n# Create chi-square distributions with different degrees of freedom\nx_vals &lt;- seq(0, 20, length.out = 200)\ndf_values_chi &lt;- c(1, 2, 5, 10)\n\n# Calculate chi-square distribution densities\nchi_densities &lt;- data.frame()\nfor(df in df_values_chi) {\n  density_vals &lt;- dchisq(x_vals, df = df)\n  chi_densities &lt;- rbind(chi_densities, \n                         data.frame(x = x_vals, density = density_vals, df = paste(\"df =\", df)))\n}\n\n# Create plot\nggplot(chi_densities, aes(x = x, y = density, color = df)) +\n  geom_line(linewidth = 1) +\n  labs(title = \"Chi-Square Distributions with Different Degrees of Freedom\",\n       subtitle = \"Shape becomes more symmetric as df increases\",\n       x = \"Value\", y = \"Density\",\n       color = \"Degrees of Freedom\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5)) +\n  scale_color_brewer(palette = \"Set1\")"
  },
  {
    "objectID": "src/teaching-stats/core-concepts/degrees-of-freedom.html#degrees-of-freedom-in-regression",
    "href": "src/teaching-stats/core-concepts/degrees-of-freedom.html#degrees-of-freedom-in-regression",
    "title": "Degrees of Freedom",
    "section": "Degrees of Freedom in Regression",
    "text": "Degrees of Freedom in Regression\n\nSimple Linear Regression\n\n\nShow the code\n# Generate data for simple linear regression\nn_reg &lt;- 20\nx_reg &lt;- seq(1, 10, length.out = n_reg)\ny_reg &lt;- 2 + 1.5 * x_reg + rnorm(n_reg, 0, 2)\n\n# Fit regression model\nlm_model &lt;- lm(y_reg ~ x_reg)\nresiduals &lt;- residuals(lm_model)\n\n# Degrees of freedom\ndf_total &lt;- n_reg - 1      # Total df\ndf_model &lt;- 1              # Model df (one slope parameter)\ndf_residual &lt;- n_reg - 2   # Residual df\n\ncat(\"Simple Linear Regression:\\n\")\n\n\nSimple Linear Regression:\n\n\nShow the code\ncat(\"Sample size:\", n_reg, \"\\n\")\n\n\nSample size: 20 \n\n\nShow the code\ncat(\"Total df:\", df_total, \"\\n\")\n\n\nTotal df: 19 \n\n\nShow the code\ncat(\"Model df:\", df_model, \"\\n\")\n\n\nModel df: 1 \n\n\nShow the code\ncat(\"Residual df:\", df_residual, \"\\n\")\n\n\nResidual df: 18 \n\n\nShow the code\ncat(\"R-squared:\", round(summary(lm_model)$r.squared, 3), \"\\n\")\n\n\nR-squared: 0.848 \n\n\n\n\nVisualizing Regression Degrees of Freedom\n\n\nShow the code\n# Create regression plot\ndf_reg &lt;- data.frame(x = x_reg, y = y_reg)\n\nggplot(df_reg, aes(x = x, y = y)) +\n  geom_point(size = 3, color = \"blue\") +\n  geom_smooth(method = \"lm\", color = \"red\", linewidth = 1) +\n  geom_segment(aes(xend = x, yend = fitted(lm_model)), \n               color = \"green\", alpha = 0.5) +\n  labs(title = \"Simple Linear Regression\",\n       subtitle = \"Green lines show residuals (constrained by regression line)\",\n       x = \"X\", y = \"Y\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5))"
  },
  {
    "objectID": "src/teaching-stats/core-concepts/degrees-of-freedom.html#interactive-example-degrees-of-freedom-calculator",
    "href": "src/teaching-stats/core-concepts/degrees-of-freedom.html#interactive-example-degrees-of-freedom-calculator",
    "title": "Degrees of Freedom",
    "section": "Interactive Example: Degrees of Freedom Calculator",
    "text": "Interactive Example: Degrees of Freedom Calculator\n\n\nShow the code\n# Function to demonstrate degrees of freedom\ndemonstrate_df &lt;- function(n, constraint_type = \"mean\") {\n  \n  if(constraint_type == \"mean\") {\n    # Generate n random numbers\n    data &lt;- rnorm(n, mean = 10, sd = 2)\n    \n    # Show how the last value is constrained\n    if(n &gt; 1) {\n      known_values &lt;- data[1:(n-1)]\n      target_mean &lt;- mean(data)\n      last_value &lt;- n * target_mean - sum(known_values)\n      \n      cat(\"Degrees of Freedom Demonstration:\\n\")\n      cat(\"Sample size:\", n, \"\\n\")\n      cat(\"Constraint: Sample mean =\", round(target_mean, 2), \"\\n\")\n      cat(\"Known values:\", paste(round(known_values, 2), collapse = \", \"), \"\\n\")\n      cat(\"Last value MUST be:\", round(last_value, 2), \"\\n\")\n      cat(\"Degrees of freedom =\", n - 1, \"\\n\")\n    }\n  }\n}\n\n# Demonstrate with different sample sizes\ndemonstrate_df(5, \"mean\")\n\n\nDegrees of Freedom Demonstration:\nSample size: 5 \nConstraint: Sample mean = 10.32 \nKnown values: 11.17, 10.25, 10.43, 10.76 \nLast value MUST be: 9 \nDegrees of freedom = 4 \n\n\nShow the code\ncat(\"\\n\")\n\n\nShow the code\ndemonstrate_df(10, \"mean\")\n\n\nDegrees of Freedom Demonstration:\nSample size: 10 \nConstraint: Sample mean = 9.71 \nKnown values: 9.33, 7.96, 7.86, 10.61, 10.9, 10.11, 11.84, 14.1, 9.02 \nLast value MUST be: 5.38 \nDegrees of freedom = 9"
  },
  {
    "objectID": "src/teaching-stats/core-concepts/degrees-of-freedom.html#key-takeaways",
    "href": "src/teaching-stats/core-concepts/degrees-of-freedom.html#key-takeaways",
    "title": "Degrees of Freedom",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nWhy Degrees of Freedom Matter:\n\nCorrects for bias: Using n-1 instead of n in sample variance gives an unbiased estimate\nAccounts for constraints: Each constraint reduces the number of independent pieces of information\nAffects statistical tests: Different degrees of freedom lead to different critical values\nDetermines distribution shape: Higher degrees of freedom make distributions more normal\n\n\n\nCommon Rules:\n\nSample variance: df = n - 1\nOne-sample t-test: df = n - 1\nTwo-sample t-test: df = n₁ + n₂ - 2\nChi-square goodness of fit: df = k - 1 (k categories)\nSimple linear regression: df_residual = n - 2\n\n\n\nThe Intuition:\nThink of degrees of freedom as the number of “free choices” you have after accounting for the constraints imposed by your statistical procedure. Each constraint reduces your degrees of freedom by one."
  }
]