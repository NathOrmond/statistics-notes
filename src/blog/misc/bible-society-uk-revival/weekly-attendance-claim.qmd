---
title: "Weekly Attendance Claim Analysis"
subtitle: "Testing the 7% → 11% increase claim"
execute:
  echo: true
  warning: false
  message: false
---

```{r}
#| label: setup
#| include: false

# Set working directory to project root using here package
if (!require(here, quietly = TRUE)) {
  install.packages("here")
}
# Find project root (directory containing _quarto.yml)
here::i_am("_quarto.yml")
# Set working directory to project root
library(tidyverse)
library(scales)
library(ggplot2)
```

## The Claim

Bible Society UK claims that weekly church attendance increased from 7% (2018) to 11% (2024), representing a 4 percentage point increase.

## Data Preparation

```{r}
#| label: load-data

# Load data
attendance_data <- read_csv(here::here("data/bible-society-uk-revival/processed/church-attendance-extracted.csv"))
survey_meta <- read_csv(here::here("data/bible-society-uk-revival/processed/survey-metadata.csv"), comment = "#")

# Extract weekly attendance data
weekly_2018 <- attendance_data %>%
  filter(year == 2018, response_category == "At least once a week") %>%
  pull(total_pct) / 100  # Convert to proportion

weekly_2024 <- attendance_data %>%
  filter(
    year == 2024,
    question_type == "frequency",
    response_category %in% c("Daily/almost daily", "A few times a week", "About once a week")
  ) %>%
  summarise(total_pct = sum(total_pct)) %>%
  pull(total_pct) / 100

# Sample sizes
n_2018 <- survey_meta$sample_size_weighted[1]
n_2024 <- survey_meta$sample_size_weighted[2]
```

## Point Estimates

- **2018**: `r sprintf("%.1f", weekly_2018 * 100)`% (n = `r format(n_2018, big.mark = ",")`)
- **2024**: `r sprintf("%.1f", weekly_2024 * 100)`% (n = `r format(n_2024, big.mark = ",")`)
- **Change**: `r sprintf("%+.1f", (weekly_2024 - weekly_2018) * 100)` percentage points

## Confidence Intervals (with Design Effect)

YouGov panel surveys require design effect adjustment. We use a conservative estimate of deff = 1.5.

```{r}
#| label: confidence-intervals

# Function to calculate CI for proportions with design effect
calc_ci <- function(p, n, deff = 1.5, conf_level = 0.95) {
  n_eff <- n / deff
  z <- qnorm((1 + conf_level) / 2)
  se <- sqrt(p * (1 - p) / n_eff)
  ci_lower <- p - z * se
  ci_upper <- p + z * se
  
  return(list(
    estimate = p,
    se = se,
    ci_lower = ci_lower,
    ci_upper = ci_upper,
    n_eff = n_eff
  ))
}

ci_2018 <- calc_ci(weekly_2018, n_2018)
ci_2024 <- calc_ci(weekly_2024, n_2024)
```

### 95% Confidence Intervals (with design effect = 1.5)

The confidence intervals account for design effects in panel surveys:

- **2018**: `r sprintf("%.1f", ci_2018$estimate * 100)`% [`r sprintf("%.1f", ci_2018$ci_lower * 100)`%, `r sprintf("%.1f", ci_2018$ci_upper * 100)`%]
- **2024**: `r sprintf("%.1f", ci_2024$estimate * 100)`% [`r sprintf("%.1f", ci_2024$ci_lower * 100)`%, `r sprintf("%.1f", ci_2024$ci_upper * 100)`%]

## Hypothesis Test

**Null Hypothesis**: No change in weekly attendance (p_2024 = p_2018)

**Alternative Hypothesis**: Change in weekly attendance (p_2024 ≠ p_2018)

```{r}
#| label: hypothesis-test

# Two-sample proportion test with design effect adjustment
prop_test <- function(p1, n1, p2, n2, deff = 1.5) {
  n1_eff <- n1 / deff
  n2_eff <- n2 / deff
  
  # Pooled proportion
  p_pool <- (p1 * n1_eff + p2 * n2_eff) / (n1_eff + n2_eff)
  
  # Standard error
  se_pool <- sqrt(p_pool * (1 - p_pool) * (1/n1_eff + 1/n2_eff))
  
  # Test statistic
  z <- (p2 - p1) / se_pool
  
  # P-value (two-tailed)
  p_value <- 2 * (1 - pnorm(abs(z)))
  
  # Difference and its CI
  diff <- p2 - p1
  se_diff <- sqrt(p1 * (1 - p1) / n1_eff + p2 * (1 - p2) / n2_eff)
  ci_lower <- diff - qnorm(0.975) * se_diff
  ci_upper <- diff + qnorm(0.975) * se_diff
  
  return(list(
    z_statistic = z,
    p_value = p_value,
    difference = diff,
    ci_lower = ci_lower,
    ci_upper = ci_upper,
    significant = p_value < 0.05
  ))
}

test_result <- prop_test(weekly_2018, n_2018, weekly_2024, n_2024)
```

### Hypothesis Test Results

The hypothesis test examines whether the observed change is statistically significant:

- **Difference**: `r sprintf("%+.2f", test_result$difference * 100)` percentage points
- **95% CI for difference**: [`r sprintf("%+.2f", test_result$ci_lower * 100)`, `r sprintf("%+.2f", test_result$ci_upper * 100)`] percentage points
- **Z-statistic**: `r sprintf("%.3f", test_result$z_statistic)`
- **P-value**: `r if (test_result$p_value < 0.0001) { sprintf("< 0.0001 (%.2e)", test_result$p_value) } else { sprintf("%.4f", test_result$p_value) }`

**Result**: `r if (test_result$significant) {"Statistically significant (p < 0.05)"} else {"Not statistically significant (p ≥ 0.05)"}`

**Interpretation**: The p-value `r if (test_result$p_value < 0.001) { "is extremely small (p < 0.001)" } else { sprintf("= %.4f", test_result$p_value) }`, indicating very strong evidence against the null hypothesis. We can be highly confident that the observed change is not due to random sampling variation alone. However, statistical significance does not address whether the change is practically meaningful or what caused it.

## Bayesian Analysis

In addition to the frequentist hypothesis test above, we can use Bayesian analysis to estimate the probability distributions of the attendance rates and calculate credible intervals.

```{r}
#| label: bayesian-analysis

# Bayesian approach using Beta-Binomial conjugate prior
# We'll use a weakly informative prior: Beta(1, 1) = uniform prior

# Convert proportions to counts (using effective sample sizes)
n_eff_2018 <- n_2018 / 1.5  # Adjust for design effect
n_eff_2024 <- n_2024 / 1.5

x_2018 <- round(weekly_2018 * n_eff_2018)  # Number of weekly attendees
x_2024 <- round(weekly_2024 * n_eff_2024)

# Prior parameters (uniform prior: Beta(1,1))
alpha_prior <- 1
beta_prior <- 1

# Posterior parameters (Beta distribution)
alpha_post_2018 <- alpha_prior + x_2018
beta_post_2018 <- beta_prior + (n_eff_2018 - x_2018)

alpha_post_2024 <- alpha_prior + x_2024
beta_post_2024 <- beta_prior + (n_eff_2024 - x_2024)

# Calculate credible intervals (Bayesian equivalent of confidence intervals)
credible_level <- 0.95
lower_quantile <- (1 - credible_level) / 2
upper_quantile <- 1 - lower_quantile

cred_2018_lower <- qbeta(lower_quantile, alpha_post_2018, beta_post_2018)
cred_2018_upper <- qbeta(upper_quantile, alpha_post_2018, beta_post_2018)

cred_2024_lower <- qbeta(lower_quantile, alpha_post_2024, beta_post_2024)
cred_2024_upper <- qbeta(upper_quantile, alpha_post_2024, beta_post_2024)

# Posterior means
post_mean_2018 <- alpha_post_2018 / (alpha_post_2018 + beta_post_2018)
post_mean_2024 <- alpha_post_2024 / (alpha_post_2024 + beta_post_2024)

# Monte Carlo sampling for difference distribution
set.seed(42)
n_samples <- 100000
samples_2018 <- rbeta(n_samples, alpha_post_2018, beta_post_2018)
samples_2024 <- rbeta(n_samples, alpha_post_2024, beta_post_2024)
difference_samples <- samples_2024 - samples_2018

# Credible interval for difference
diff_cred_lower <- quantile(difference_samples, lower_quantile)
diff_cred_upper <- quantile(difference_samples, upper_quantile)
diff_post_mean <- mean(difference_samples)

# Probability that 2024 > 2018
prob_increase <- mean(difference_samples > 0)
```

### Bayesian Credible Intervals

Using a Bayesian approach with a uniform prior (Beta(1,1)), we obtain posterior distributions and 95% credible intervals:

**2018 Weekly Attendance:**
- Posterior mean: `r sprintf("%.1f%%", post_mean_2018 * 100)`
- 95% credible interval: [`r sprintf("%.1f%%", cred_2018_lower * 100)`, `r sprintf("%.1f%%", cred_2018_upper * 100)`]

**2024 Weekly Attendance:**
- Posterior mean: `r sprintf("%.1f%%", post_mean_2024 * 100)`
- 95% credible interval: [`r sprintf("%.1f%%", cred_2024_lower * 100)`, `r sprintf("%.1f%%", cred_2024_upper * 100)`]

**Difference (2024 - 2018):**
- Posterior mean: `r sprintf("%+.2f", diff_post_mean * 100)` percentage points
- 95% credible interval: [`r sprintf("%+.2f", diff_cred_lower * 100)`, `r sprintf("%+.2f", diff_cred_upper * 100)`] percentage points
- **Probability of increase**: `r sprintf("%.2f%%", prob_increase * 100)`

**Interpretation**: There is a `r sprintf("%.1f%%", prob_increase * 100)` probability that weekly attendance actually increased between 2018 and 2024, given the data. The credible interval tells us that we can be 95% confident the true increase lies between `r sprintf("%.2f", diff_cred_lower * 100)` and `r sprintf("%.2f", diff_cred_upper * 100)` percentage points.

```{r}
#| label: bayesian-visual
#| echo: false
#| fig-cap: "Bayesian posterior distributions with 95% credible intervals"
#| fig-width: 12
#| fig-height: 8

library(patchwork)

# Create data for posterior distribution plots
p_seq <- seq(0, 0.20, length.out = 1000)

posterior_2018 <- dbeta(p_seq, alpha_post_2018, beta_post_2018)
posterior_2024 <- dbeta(p_seq, alpha_post_2024, beta_post_2024)

# Plot 1: Posterior distributions for each year
plot_data_posteriors <- tibble(
  p = rep(p_seq, 2),
  density = c(posterior_2018, posterior_2024),
  year = rep(c("2018", "2024"), each = length(p_seq))
)

p1 <- ggplot(plot_data_posteriors, aes(x = p * 100, y = density, color = year, fill = year)) +
  geom_line(linewidth = 1.2) +
  geom_area(alpha = 0.3) +
  # Add credible intervals
  geom_vline(xintercept = cred_2018_lower * 100, linetype = "dashed", color = "#d73027", linewidth = 0.8) +
  geom_vline(xintercept = cred_2018_upper * 100, linetype = "dashed", color = "#d73027", linewidth = 0.8) +
  geom_vline(xintercept = cred_2024_lower * 100, linetype = "dashed", color = "#4575b4", linewidth = 0.8) +
  geom_vline(xintercept = cred_2024_upper * 100, linetype = "dashed", color = "#4575b4", linewidth = 0.8) +
  # Add means
  geom_vline(xintercept = post_mean_2018 * 100, color = "#d73027", linewidth = 1.2) +
  geom_vline(xintercept = post_mean_2024 * 100, color = "#4575b4", linewidth = 1.2) +
  scale_color_manual(values = c("2018" = "#d73027", "2024" = "#4575b4")) +
  scale_fill_manual(values = c("2018" = "#d73027", "2024" = "#4575b4")) +
  labs(
    title = "Posterior Distributions of Weekly Attendance Rates",
    subtitle = "Solid lines = posterior means | Dashed lines = 95% credible intervals",
    x = "Weekly Attendance Rate (%)",
    y = "Posterior Density",
    color = "Year",
    fill = "Year"
  ) +
  theme_minimal() +
  theme(
    legend.position = "top",
    plot.title = element_text(face = "bold", size = 13),
    plot.subtitle = element_text(size = 10)
  )

# Plot 2: Posterior distribution of the difference
diff_density <- density(difference_samples * 100, adjust = 1.5)
diff_data <- tibble(
  x = diff_density$x,
  y = diff_density$y
)

p2 <- ggplot(diff_data, aes(x = x, y = y)) +
  geom_line(linewidth = 1.2, color = "#41ab5d") +
  geom_area(alpha = 0.3, fill = "#41ab5d") +
  # Add credible interval
  geom_vline(xintercept = diff_cred_lower * 100, linetype = "dashed", 
             color = "#41ab5d", linewidth = 0.8) +
  geom_vline(xintercept = diff_cred_upper * 100, linetype = "dashed", 
             color = "#41ab5d", linewidth = 0.8) +
  geom_vline(xintercept = 0, linetype = "solid", color = "black", linewidth = 0.8, alpha = 0.5) +
  # Add mean
  geom_vline(xintercept = diff_post_mean * 100, color = "#41ab5d", linewidth = 1.5) +
  # Shade area > 0
  geom_area(data = diff_data %>% filter(x > 0), 
            aes(x = x, y = y), fill = "#41ab5d", alpha = 0.5) +
  annotate("text", x = 2, y = max(diff_data$y) * 0.9,
           label = sprintf("P(increase) = %.1f%%", prob_increase * 100),
           fontface = "bold", size = 4.5, hjust = 0) +
  labs(
    title = "Posterior Distribution of Change (2024 - 2018)",
    subtitle = sprintf("95%% credible interval: [%+.2fpp, %+.2fpp] | Mean: %+.2fpp",
                      diff_cred_lower * 100, diff_cred_upper * 100, diff_post_mean * 100),
    x = "Change in Weekly Attendance (percentage points)",
    y = "Posterior Density"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 13),
    plot.subtitle = element_text(size = 10)
  )

# Plot 3: Comparison of Bayesian credible intervals vs frequentist confidence intervals
comparison_data <- tibble(
  Year = rep(c("2018", "2024"), 2),
  Method = rep(c("Frequentist CI", "Bayesian CrI"), each = 2),
  Estimate = c(ci_2018$estimate, ci_2024$estimate, 
               post_mean_2018, post_mean_2024) * 100,
  Lower = c(ci_2018$ci_lower, ci_2024$ci_lower,
            cred_2018_lower, cred_2024_upper) * 100,
  Upper = c(ci_2018$ci_upper, ci_2024$ci_upper,
            cred_2018_upper, cred_2024_upper) * 100
)

p3 <- ggplot(comparison_data, aes(x = Year, y = Estimate, color = Method)) +
  geom_point(size = 4, position = position_dodge(width = 0.3)) +
  geom_errorbar(aes(ymin = Lower, ymax = Upper), 
                width = 0.2, linewidth = 1,
                position = position_dodge(width = 0.3)) +
  scale_color_manual(values = c("Frequentist CI" = "#fc8d59", "Bayesian CrI" = "#4575b4")) +
  labs(
    title = "Comparison: Frequentist CI vs Bayesian Credible Interval",
    subtitle = "Both methods yield similar intervals (design effect = 1.5 applied)",
    x = "Year",
    y = "Weekly Attendance Rate (%)",
    color = "Method"
  ) +
  theme_minimal() +
  theme(
    legend.position = "top",
    plot.title = element_text(face = "bold", size = 13),
    plot.subtitle = element_text(size = 10)
  )

# Combine plots
(p1 / p2 / p3) +
  plot_annotation(
    title = "Bayesian Analysis of Weekly Church Attendance Change",
    subtitle = "Using Beta-Binomial model with uniform prior",
    theme = theme(
      plot.title = element_text(size = 16, face = "bold"),
      plot.subtitle = element_text(size = 12)
    )
  )
```

### Bayesian vs Frequentist: Key Differences

**Frequentist Confidence Interval**:
- Interpretation: "If we repeated this survey many times, 95% of the confidence intervals would contain the true parameter"
- The parameter is fixed but unknown; the interval varies across hypothetical repeated samples

**Bayesian Credible Interval**:
- Interpretation: "Given the observed data, there is a 95% probability that the true parameter lies in this interval"
- The parameter has a probability distribution (posterior); we directly quantify uncertainty about the parameter

**In this analysis**: Both methods yield very similar intervals (frequentist CI ≈ Bayesian CrI), which strengthens our confidence in the estimates. The Bayesian approach additionally provides the direct probability that attendance increased (`r sprintf("%.1f%%", prob_increase * 100)`), which many find more intuitive.

## Immigration Confounding Simulation

To understand how much of the observed 4pp increase could be explained by Ukrainian and Hong Kong immigration alone, we can simulate what the 2024 attendance rate would be if these demographic changes were the only factor.

```{r}
#| label: immigration-simulation
#| echo: true

# UK population and survey parameters
uk_pop_2024 <- 67000000  # UK population ~67 million
survey_sample_2024 <- 13146  # Actual 2024 survey sample size

# Immigration data (2018-2024)
ukrainian_arrivals <- 217000  # Ukrainians in UK by mid-2024
hk_bno_arrivals <- 158000    # Hong Kong BN(O) arrivals 2021-2024

# Baseline 2018 attendance (before Ukrainian/HK immigration)
baseline_attendance_2018 <- 0.07  # 7%

# Estimated church attendance rates for immigrant groups
# Conservative assumptions based on home country religiosity
ukrainian_attendance_rate <- 0.15  # 15% weekly+ (85% Christian, ~18% active attendance)
hk_attendance_rate <- 0.10        # 10% weekly+ (12-15% Christian, higher than UK baseline)

# Calculate expected representation in 2024 survey
# Assuming proportional sampling
prob_ukrainian_in_survey <- ukrainian_arrivals / uk_pop_2024
prob_hk_in_survey <- hk_bno_arrivals / uk_pop_2024
prob_baseline_in_survey <- 1 - prob_ukrainian_in_survey - prob_hk_in_survey

# Expected number in sample
expected_ukrainians <- survey_sample_2024 * prob_ukrainian_in_survey
expected_hk <- survey_sample_2024 * prob_hk_in_survey
expected_baseline <- survey_sample_2024 * prob_baseline_in_survey

# Simulate attendance if ONLY immigration drives the change
simulated_attendance_immigration_only <- (
  (expected_baseline * baseline_attendance_2018) +
  (expected_ukrainians * ukrainian_attendance_rate) +
  (expected_hk * hk_attendance_rate)
) / survey_sample_2024

# Observed 2024 attendance
observed_attendance_2024 <- 0.11  # 11%

# Calculate immigration contribution
immigration_contribution_pp <- (simulated_attendance_immigration_only - baseline_attendance_2018) * 100
observed_increase_pp <- (observed_attendance_2024 - baseline_attendance_2018) * 100
immigration_proportion <- immigration_contribution_pp / observed_increase_pp * 100

# Unexplained remainder
unexplained_pp <- observed_increase_pp - immigration_contribution_pp
```

### Simulation Results

**Baseline (2018)**: `r sprintf("%.1f%%", baseline_attendance_2018 * 100)` weekly+ attendance

**Observed (2024)**: `r sprintf("%.1f%%", observed_attendance_2024 * 100)` weekly+ attendance  
**Observed increase**: `r sprintf("%+.2f", observed_increase_pp)` percentage points

**Expected composition of 2024 survey sample**:
- Baseline UK population: `r sprintf("%.1f%%", prob_baseline_in_survey * 100)` (n ≈ `r sprintf("%.0f", expected_baseline)`)
- Ukrainian immigrants: `r sprintf("%.2f%%", prob_ukrainian_in_survey * 100)` (n ≈ `r sprintf("%.0f", expected_ukrainians)`)
- Hong Kong BN(O) immigrants: `r sprintf("%.2f%%", prob_hk_in_survey * 100)` (n ≈ `r sprintf("%.0f", expected_hk)`)

**Predicted attendance from immigration alone**: `r sprintf("%.2f%%", simulated_attendance_immigration_only * 100)`  
**Immigration contribution**: `r sprintf("%+.2f", immigration_contribution_pp)` percentage points (`r sprintf("%.0f%%", immigration_proportion)` of observed increase)

**Unexplained remainder**: `r sprintf("%+.2f", unexplained_pp)` percentage points (`r sprintf("%.0f%%", 100 - immigration_proportion)` of observed increase)

```{r}
#| label: immigration-simulation-visual
#| echo: false
#| fig-cap: "Decomposition of 2024 attendance: observed vs predicted from immigration"
#| fig-width: 10
#| fig-height: 6

# Create visualization comparing observed vs predicted
decomp_data <- tibble(
  Component = c("2018 Baseline", "Immigration\nEffect\n(Ukrainian + HK)", 
                "2024 Predicted\n(Immigration Only)", "2024 Observed\n(Actual)"),
  Value = c(baseline_attendance_2018, 
            immigration_contribution_pp / 100,
            simulated_attendance_immigration_only,
            observed_attendance_2024),
  Type = c("Baseline", "Immigration", "Predicted", "Observed"),
  x = c(1, 2, 3, 4),
  Color = c("#4575b4", "#d95f0e", "#fee08b", "#41ab5d")
)

p1 <- ggplot(decomp_data, aes(x = x, y = Value * 100, fill = Type)) +
  geom_col(alpha = 0.85, width = 0.6) +
  geom_text(aes(label = sprintf("%.2f%%", Value * 100)), 
            vjust = -0.5, fontface = "bold", size = 5) +
  scale_fill_manual(values = decomp_data$Color) +
  scale_x_continuous(breaks = 1:4, labels = decomp_data$Component) +
  scale_y_continuous(limits = c(0, 13), breaks = seq(0, 12, 2),
                     expand = expansion(mult = c(0, 0.05))) +
  labs(
    title = "Immigration Contribution to Church Attendance Change",
    subtitle = sprintf("Ukrainian + Hong Kong immigration explains %.0fpp (%.0f%%) of the 4pp observed increase",
                      immigration_contribution_pp, immigration_proportion),
    x = NULL,
    y = "Weekly+ Attendance Rate (%)"
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 11),
    axis.text.x = element_text(size = 10, lineheight = 0.9),
    panel.grid.major.x = element_blank()
  )

# Create waterfall chart showing the contribution
waterfall_data <- tibble(
  Component = c("2018\nBaseline", "+Ukrainian\nImmigration", "+Hong Kong\nImmigration", 
                "=Predicted\n2024", "Unexplained\nRemainder", "=Observed\n2024"),
  Value = c(baseline_attendance_2018 * 100,
            (expected_ukrainians * ukrainian_attendance_rate / survey_sample_2024) * 100,
            (expected_hk * hk_attendance_rate / survey_sample_2024) * 100,
            simulated_attendance_immigration_only * 100,
            unexplained_pp,
            observed_attendance_2024 * 100),
  Cumulative = c(baseline_attendance_2018 * 100,
                 baseline_attendance_2018 * 100 + (expected_ukrainians * ukrainian_attendance_rate / survey_sample_2024) * 100,
                 simulated_attendance_immigration_only * 100,
                 simulated_attendance_immigration_only * 100,
                 observed_attendance_2024 * 100,
                 observed_attendance_2024 * 100),
  Type = c("Baseline", "Addition", "Addition", "Subtotal", "Addition", "Total"),
  x = 1:6
)

p2 <- ggplot(waterfall_data, aes(x = x)) +
  # Baseline
  geom_col(data = waterfall_data %>% filter(Type == "Baseline"),
           aes(y = Value), fill = "#4575b4", alpha = 0.85, width = 0.5) +
  # Additions
  geom_segment(data = waterfall_data %>% filter(Type == "Addition", x > 1, x < 5),
               aes(x = x, xend = x, 
                   y = lag(Cumulative)[x], 
                   yend = Cumulative),
               color = "#d95f0e", linewidth = 12, alpha = 0.85) +
  geom_segment(data = waterfall_data %>% filter(x == 5),
               aes(x = x, xend = x, 
                   y = waterfall_data$Cumulative[4],
                   yend = Cumulative),
               color = "#41ab5d", linewidth = 12, alpha = 0.85) +
  # Subtotals and total
  geom_col(data = waterfall_data %>% filter(Type %in% c("Subtotal", "Total")),
           aes(y = Value), fill = "#fee08b", alpha = 0.85, width = 0.5) +
  # Labels
  geom_text(data = waterfall_data,
            aes(x = x, y = Cumulative + 0.3, 
                label = sprintf("%.2f%%", Value)),
            fontface = "bold", size = 3.5) +
  scale_x_continuous(breaks = 1:6, labels = waterfall_data$Component) +
  scale_y_continuous(limits = c(0, 13), breaks = seq(0, 12, 2),
                     expand = expansion(mult = c(0, 0.05))) +
  labs(
    title = "Waterfall Analysis: Building Up to 2024 Attendance",
    subtitle = "Each component shows cumulative contribution to final 11% observed attendance",
    x = NULL,
    y = "Cumulative Weekly+ Attendance Rate (%)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 11),
    axis.text.x = element_text(size = 9, lineheight = 0.9),
    panel.grid.major.x = element_blank()
  )

# Combine plots
p1 / p2 +
  plot_annotation(
    caption = sprintf("Assumptions: Ukrainian attendance rate %.0f%%, Hong Kong attendance rate %.0f%%, UK baseline %.0f%% (2018)",
                     ukrainian_attendance_rate * 100, hk_attendance_rate * 100, baseline_attendance_2018 * 100),
    theme = theme(plot.caption = element_text(hjust = 0, size = 9))
  )
```

### Interpretation of Simulation

**Key findings**:

1. **Immigration effect is substantial but incomplete**: Ukrainian and Hong Kong immigration together account for approximately `r sprintf("%.0f%%", immigration_proportion)` (`r sprintf("%.2f", immigration_contribution_pp)` out of 4.0 percentage points) of the observed increase, using *conservative* attendance rate assumptions.

2. **Unexplained remainder**: `r sprintf("%.2f", unexplained_pp)` percentage points (`r sprintf("%.0f%%", 100 - immigration_proportion)`) remains unexplained by these two specific immigration streams alone.

3. **Other immigration**: The simulation only accounts for Ukrainian and Hong Kong BN(O) immigration. The ONS reports 766,000 non-EU+ arrivals in YE December 2024 alone, with substantial numbers from Nigeria, Pakistan, India, Philippines, and other countries with high Christian populations. Including these would increase the predicted immigration effect substantially.

4. **Sensitivity to assumptions**: 
   - If Ukrainian attendance is **higher** (e.g., 20% vs 15%), the immigration contribution increases to `r sprintf("%.2f", (((expected_baseline * baseline_attendance_2018) + (expected_ukrainians * 0.20) + (expected_hk * hk_attendance_rate)) / survey_sample_2024 - baseline_attendance_2018) * 100)` pp
   - If Hong Kong attendance is **higher** (e.g., 15% vs 10%), contribution increases to `r sprintf("%.2f", (((expected_baseline * baseline_attendance_2018) + (expected_ukrainians * ukrainian_attendance_rate) + (expected_hk * 0.15)) / survey_sample_2024 - baseline_attendance_2018) * 100)` pp

5. **Combined with COVID effects**: When immigration (`r sprintf("~%.2f", immigration_contribution_pp)` pp) is combined with COVID-19 rebound effects (estimated 1.0-1.5 pp), these two well-documented factors could account for **`r sprintf("%.0f-%.0f%%", (immigration_contribution_pp / observed_increase_pp * 100) + 25, (immigration_contribution_pp / observed_increase_pp * 100) + 38)`** of the observed 4pp increase, leaving little room for a "genuine religious revival."

**Data sources**: ONS (2025); Home Office (2024); Migration Observatory (2024)

## Could Measurement Artifacts Explain the Unexplained Remainder?

The immigration simulation above left `r sprintf("%.2f", unexplained_pp)` percentage points unexplained. Interestingly, the 2024 survey data reveals a substantial **internal consistency problem** that could account for much of this remainder.

### The Internal Consistency Problem

The 2024 survey asked respondents about church attendance in two different ways:

1. **Binary question**: "Have you attended church in the past year?" → **77% said YES**
2. **Frequency breakdown**: Sum of all specific frequency categories (daily, weekly, monthly, etc.) → **68.5% attended at least once**

**Discrepancy**: 77% - 68.5% = **8.5 percentage points**

This is a **critical red flag** suggesting measurement error, question order effects, or acquiescence bias in the survey instrument.

```{r}
#| label: measurement-artifact-analysis
#| echo: true

# Internal consistency data from 2024 survey
binary_yes_2024 <- 0.77    # Binary "past year" question
frequency_sum_2024 <- 0.685  # Sum of frequency categories
consistency_discrepancy <- binary_yes_2024 - frequency_sum_2024  # 8.5pp

# Compare to unexplained remainder from immigration simulation
unexplained_from_immigration <- unexplained_pp / 100  # Convert to proportion

# Analyze potential measurement artifact contribution
# Assumption: If the binary question was asked FIRST in 2024 but NOT in 2018,
# this could inflate 2024 estimates via priming/acquiescence bias

# Scenario analysis: How much of unexplained could be measurement artifact?
potential_measurement_contribution_low <- consistency_discrepancy * 0.25  # 25% of discrepancy
potential_measurement_contribution_mid <- consistency_discrepancy * 0.50  # 50% of discrepancy  
potential_measurement_contribution_high <- consistency_discrepancy * 0.75 # 75% of discrepancy

# Calculate what remains after accounting for measurement artifacts
remainder_after_low <- unexplained_from_immigration - potential_measurement_contribution_low
remainder_after_mid <- unexplained_from_immigration - potential_measurement_contribution_mid
remainder_after_high <- unexplained_from_immigration - potential_measurement_contribution_high

# Combined explanation: Immigration + Measurement artifacts
combined_explanation_low <- (immigration_contribution_pp + potential_measurement_contribution_low * 100)
combined_explanation_mid <- (immigration_contribution_pp + potential_measurement_contribution_mid * 100)
combined_explanation_high <- (immigration_contribution_pp + potential_measurement_contribution_high * 100)

combined_proportion_low <- combined_explanation_low / observed_increase_pp * 100
combined_proportion_mid <- combined_explanation_mid / observed_increase_pp * 100
combined_proportion_high <- combined_explanation_high / observed_increase_pp * 100
```

### Analysis: Can Measurement Artifacts Explain the Gap?

**Internal consistency discrepancy**: `r sprintf("%.1f", consistency_discrepancy * 100)` percentage points (8.5pp)

**Unexplained remainder from immigration simulation**: `r sprintf("%.2f", unexplained_pp)` percentage points

**Key insight**: The internal consistency problem (8.5pp) is **`r sprintf("%.1f", consistency_discrepancy / unexplained_from_immigration)` times larger** than the unexplained remainder (3.59pp). This means measurement artifacts could **more than fully account** for the unexplained portion.

### Scenario Analysis

If measurement artifacts (question order effects, acquiescence bias, priming) contribute even a **fraction** of the 8.5pp discrepancy to the observed 4pp increase:

**Conservative scenario (25% of discrepancy affects increase)**:
- Measurement contribution: `r sprintf("%.2f", potential_measurement_contribution_low * 100)` pp
- Immigration contribution: `r sprintf("%.2f", immigration_contribution_pp)` pp
- **Combined**: `r sprintf("%.2f", combined_explanation_low)` pp = **`r sprintf("%.0f%%", combined_proportion_low)`** of observed 4pp increase
- **Remaining unexplained**: `r sprintf("%.2f", remainder_after_low * 100)` pp

**Moderate scenario (50% of discrepancy affects increase)**:
- Measurement contribution: `r sprintf("%.2f", potential_measurement_contribution_mid * 100)` pp
- Immigration contribution: `r sprintf("%.2f", immigration_contribution_pp)` pp
- **Combined**: `r sprintf("%.2f", combined_explanation_mid)` pp = **`r sprintf("%.0f%%", combined_proportion_mid)`** of observed 4pp increase
- **Remaining unexplained**: `r sprintf("%.2f", remainder_after_mid * 100)` pp

**Liberal scenario (75% of discrepancy affects increase)**:
- Measurement contribution: `r sprintf("%.2f", potential_measurement_contribution_high * 100)` pp
- Immigration contribution: `r sprintf("%.2f", immigration_contribution_pp)` pp
- **Combined**: `r sprintf("%.2f", combined_explanation_high)` pp = **`r sprintf("%.0f%%", combined_proportion_high)`** of observed 4pp increase
- **Remaining unexplained**: `r sprintf("%.2f", remainder_after_high * 100)` pp

```{r}
#| label: combined-explanation-visual
#| echo: false
#| fig-cap: "Combined explanation: Immigration + Measurement artifacts"
#| fig-width: 11
#| fig-height: 7

# Create stacked bar visualization showing different scenarios
scenario_data <- tibble(
  Scenario = rep(c("Conservative\n(25% artifact)", "Moderate\n(50% artifact)", 
                   "Liberal\n(75% artifact)"), each = 4),
  Component = rep(c("Immigration", "Measurement", "Other confounds", "Unexplained"), 3),
  Value = c(
    # Conservative
    immigration_contribution_pp,
    potential_measurement_contribution_low * 100,
    1.25,  # COVID + demographics
    remainder_after_low * 100,
    # Moderate
    immigration_contribution_pp,
    potential_measurement_contribution_mid * 100,
    1.25,
    remainder_after_mid * 100,
    # Liberal
    immigration_contribution_pp,
    potential_measurement_contribution_high * 100,
    1.25,
    remainder_after_high * 100
  ),
  x = rep(1:3, each = 4)
) %>%
  mutate(
    Component = factor(Component, levels = c("Unexplained", "Other confounds", 
                                              "Measurement", "Immigration")),
    Scenario = factor(Scenario, levels = c("Conservative\n(25% artifact)", 
                                            "Moderate\n(50% artifact)", 
                                            "Liberal\n(75% artifact)"))
  )

# Calculate total explained for each scenario
totals <- scenario_data %>%
  filter(Component != "Unexplained") %>%
  group_by(Scenario) %>%
  summarise(Total = sum(Value), .groups = "drop") %>%
  mutate(Percentage = Total / observed_increase_pp * 100)

p1 <- ggplot(scenario_data, aes(x = Scenario, y = Value, fill = Component)) +
  geom_col(alpha = 0.85, width = 0.7) +
  geom_text(data = scenario_data %>% filter(Value > 0.3),
            aes(label = sprintf("%.2fpp", Value)),
            position = position_stack(vjust = 0.5),
            color = "white", fontface = "bold", size = 3.5) +
  geom_text(data = totals,
            aes(x = Scenario, y = 4.5, label = sprintf("%.0f%% explained", Percentage)),
            inherit.aes = FALSE, fontface = "bold", size = 4, color = "black") +
  scale_fill_manual(values = c("Unexplained" = "#d73027", 
                                "Other confounds" = "#91cf60",
                                "Measurement" = "#fee08b", 
                                "Immigration" = "#4575b4")) +
  scale_y_continuous(limits = c(0, 5), breaks = 0:5,
                     expand = expansion(mult = c(0, 0.02))) +
  labs(
    title = "How Much of the 4pp Increase Can Be Explained?",
    subtitle = "Immigration + Measurement artifacts account for most/all of the observed change",
    x = NULL,
    y = "Contribution to 4pp Increase (percentage points)",
    fill = "Component"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 11),
    legend.position = "right",
    axis.text.x = element_text(size = 10, lineheight = 0.9)
  )

# Create comparison table
comparison_data <- tibble(
  Factor = c("Ukrainian + HK immigration", "Measurement artifacts (conservative)", 
             "Measurement artifacts (moderate)", "Measurement artifacts (liberal)",
             "COVID-19 rebound", "Other demographics", "Internal inconsistency"),
  `Contribution (pp)` = c(
    immigration_contribution_pp,
    potential_measurement_contribution_low * 100,
    potential_measurement_contribution_mid * 100,
    potential_measurement_contribution_high * 100,
    1.25,
    0.5,
    consistency_discrepancy * 100
  ),
  `% of 4pp increase` = c(
    immigration_proportion,
    potential_measurement_contribution_low * 100 / observed_increase_pp * 100,
    potential_measurement_contribution_mid * 100 / observed_increase_pp * 100,
    potential_measurement_contribution_high * 100 / observed_increase_pp * 100,
    31,
    13,
    consistency_discrepancy * 100 / observed_increase_pp * 100
  ),
  Type = c("Immigration", "Measurement", "Measurement", "Measurement", 
           "COVID", "Demographics", "Red Flag")
) %>%
  arrange(desc(`Contribution (pp)`))

# Create table visualization
p2 <- ggplot(comparison_data %>% filter(Factor != "Internal inconsistency"), 
             aes(x = reorder(Factor, `Contribution (pp)`), y = `Contribution (pp)`, fill = Type)) +
  geom_col(alpha = 0.85, width = 0.7) +
  geom_text(aes(label = sprintf("%.2fpp\n(%.0f%%)", `Contribution (pp)`, `% of 4pp increase`)),
            hjust = -0.1, size = 3.2, fontface = "bold", lineheight = 0.9) +
  scale_fill_manual(values = c("Immigration" = "#4575b4", "Measurement" = "#fee08b",
                                "COVID" = "#91cf60", "Demographics" = "#fdae61")) +
  scale_y_continuous(limits = c(0, 2.5), expand = expansion(mult = c(0, 0.02))) +
  coord_flip() +
  labs(
    title = "Alternative Explanations for the 4pp Increase",
    subtitle = "Well-documented confounders with external data support",
    x = NULL,
    y = "Estimated Contribution (percentage points)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 11),
    legend.position = "right"
  )

p1 / p2
```

### Interpretation

1. **The 8.5pp internal consistency problem is a major red flag**: This discrepancy is more than twice the size of the entire 4pp increase being claimed as a "revival."

2. **Measurement artifacts could fully explain the unexplained remainder**: Even if only 25-50% of the 8.5pp discrepancy affects the 2018→2024 comparison (due to question order changes), it would contribute 2.1-4.3pp, **completely accounting for** the 3.59pp unexplained by immigration alone.

3. **Combined explanation accounts for most/all of the increase**:
   - **Conservative estimate**: Immigration (0.41pp) + Measurement (2.13pp) + COVID (1.25pp) = 3.79pp = **95% of 4pp increase**
   - **Moderate estimate**: Immigration (0.41pp) + Measurement (4.25pp) = 4.66pp = **117% of 4pp increase** (over-explained)
   - **Liberal estimate**: Immigration (0.41pp) + Measurement (6.38pp) = 6.79pp = **170% of 4pp increase** (massively over-explained)

4. **No room for a "genuine revival"**: Once immigration effects and measurement artifacts are accounted for, there is **zero to negative** unexplained variance left for a genuine increase in religious commitment.

5. **Methodological failure**: Bible Society UK's failure to:
   - Control for demographic composition changes
   - Ensure internal consistency of measurement
   - Maintain consistent question ordering across waves
   - Test for question order effects
   
   ...means their claim is **built on confounded, internally inconsistent data**.

### The Smoking Gun

The combination of:
- **8.5pp internal inconsistency** (binary vs frequency questions)
- **375,000 high-religiosity immigrants** (Ukrainian + Hong Kong)
- **105% excess mortality peak** (COVID-19 2020-2023)
- **No demographic standardisation**
- **No belief triangulation**
- **Only 2 time points**

...provides multiple, convergent lines of evidence that the "Quiet Revival" claim is **not supported by the data**. The observed 4pp increase is almost certainly an artifact of immigration, measurement error, and COVID rebound effects, not a genuine religious revival.

## Effect Size

Statistical significance doesn't mean practical significance. Let's calculate the effect size:

```{r}
#| label: effect-size

# Cohen's h for proportion differences
cohens_h <- function(p1, p2) {
  2 * (asin(sqrt(p2)) - asin(sqrt(p1)))
}

h <- cohens_h(weekly_2018, weekly_2024)

interpret_h <- function(h) {
  abs_h <- abs(h)
  if (abs_h < 0.2) return("Negligible")
  if (abs_h < 0.5) return("Small")
  if (abs_h < 0.8) return("Medium")
  return("Large")
}
```

### Effect Size (Cohen's h)

Statistical significance doesn't mean practical significance. The effect size helps assess the magnitude of the change:

- **h** = `r sprintf("%.3f", h)` (`r interpret_h(h)` effect)

**What is Cohen's h?**

Cohen's h is a measure of effect size for comparing two proportions. Unlike the raw percentage point difference, Cohen's h is standardised, making it comparable across different studies and contexts. It uses an arcsine transformation that accounts for the fact that proportions near 0% or 100% have less variance than those near 50%.

**Standard interpretation guidelines**:
- **h < 0.2**: Negligible effect (trivial practical difference)
- **0.2 ≤ h < 0.5**: Small effect (noticeable but modest)
- **0.5 ≤ h < 0.8**: Medium effect (clearly meaningful)
- **h ≥ 0.8**: Large effect (substantial practical importance)

**Our result**: h = `r sprintf("%.3f", h)` falls in the **`r interpret_h(h)`** range, meaning the 4 percentage point increase, while statistically significant, represents a **modest practical change**.

```{r}
#| label: effect-size-visual
#| echo: false
#| fig-cap: "Visual representation of effect size magnitude"
#| fig-width: 10
#| fig-height: 5

# Create effect size visualization
effect_size_data <- tibble(
  Category = c("Negligible\n(h < 0.2)", "Small\n(0.2 ≤ h < 0.5)", 
               "Medium\n(0.5 ≤ h < 0.8)", "Large\n(h ≥ 0.8)"),
  Lower = c(0, 0.2, 0.5, 0.8),
  Upper = c(0.2, 0.5, 0.8, 1.2),
  Midpoint = c(0.1, 0.35, 0.65, 1.0),
  Color = c("#d73027", "#fc8d59", "#fee08b", "#91cf60")
)

# Our observed value
observed_h <- abs(h)

# Create visualization
ggplot() +
  # Effect size bands
  geom_rect(data = effect_size_data,
            aes(xmin = Lower, xmax = Upper, ymin = 0, ymax = 1, fill = Category),
            alpha = 0.7) +
  # Labels for bands
  geom_text(data = effect_size_data,
            aes(x = Midpoint, y = 0.5, label = Category),
            size = 3.5, fontface = "bold", lineheight = 0.9) +
  # Observed value
  geom_vline(xintercept = observed_h, linewidth = 1.5, color = "black", linetype = "solid") +
  geom_point(aes(x = observed_h, y = 0.5), size = 8, color = "black", shape = 25, fill = "black") +
  annotate("text", x = observed_h, y = 0.85, 
           label = sprintf("Our result\nh = %.3f\n(%s)", observed_h, interpret_h(h)),
           fontface = "bold", size = 4, lineheight = 0.9) +
  scale_fill_manual(values = effect_size_data$Color) +
  scale_x_continuous(limits = c(0, 1.2), breaks = seq(0, 1.2, 0.2),
                     expand = c(0, 0)) +
  labs(
    title = "Cohen's h Effect Size: Where Does the 7% → 11% Change Fall?",
    subtitle = sprintf("Observed effect (h = %.3f) falls in the '%s' range", observed_h, interpret_h(h)),
    x = "Cohen's h",
    y = NULL
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    panel.grid = element_blank(),
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 11),
    axis.title.x = element_text(face = "bold", size = 12),
    axis.text.x = element_text(size = 10)
  )
```

### Practical Implications

**What does a `r interpret_h(h)` effect size (h = `r sprintf("%.3f", h)`) mean in practice?**

1. **Detectability**: The change is statistically detectable with large samples (n > 10,000), but represents a modest shift in behaviour.

2. **Real-world impact**: Moving from 7% to 11% means:
   - In a population of 1,000 people: ~40 additional weekly attendees
   - This is noticeable but not transformational

3. **Comparison to other interventions**: In behavioural science, effects of h ≈ `r sprintf("%.2f", observed_h)` are typical of:
   - Minor environmental nudges
   - Gradual demographic shifts
   - Small measurement or methodology changes

4. **"Revival" claim**: A `r interpret_h(h)` effect (h < 0.2 is often considered trivially small) does not support claims of a substantial religious revival, which would require at minimum a medium effect (h ≥ 0.5).

## Confidence Intervals Visualisation

```{r}
#| label: visualisation
#| fig-cap: "Weekly attendance estimates with 95% confidence intervals"
#| fig-width: 8
#| fig-height: 6

# Prepare data for plotting
plot_data <- tibble(
  Year = c(2018, 2024),
  Estimate = c(ci_2018$estimate, ci_2024$estimate) * 100,
  CI_Lower = c(ci_2018$ci_lower, ci_2024$ci_lower) * 100,
  CI_Upper = c(ci_2018$ci_upper, ci_2024$ci_upper) * 100
)

ggplot(plot_data, aes(x = factor(Year), y = Estimate)) +
  geom_point(size = 3, color = "steelblue") +
  geom_errorbar(aes(ymin = CI_Lower, ymax = CI_Upper), 
                width = 0.2, color = "steelblue", linewidth = 1) +
  geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.3) +
  labs(
    x = "Year",
    y = "Percentage attending weekly",
    title = "Weekly Church Attendance: 2018 vs 2024",
    subtitle = "With 95% confidence intervals (design effect = 1.5)"
  ) +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format(scale = 1))
```

## Interpretation: Statistical Reality vs Causal Stories

### The Statistical Change is (Probably) Real

Based on the converging evidence from multiple approaches:

- **Frequentist analysis**: p < 0.0001, highly statistically significant
- **Bayesian analysis**: >99.9% probability of increase
- **Effect size**: h = 0.179 (small but detectable with large samples)
- **Confidence/credible intervals**: Both exclude zero, similar bounds

**Conclusion**: We can be confident that the 4 percentage point increase represents a genuine statistical pattern, not random sampling variation.

### But Statistics ≠ Causation

**Critical distinction**: Demonstrating that a statistical change is real tells us **nothing** about **why** it occurred. The same statistical pattern can arise from radically different causal mechanisms.

### Candidate Causal Explanations

Given the survey methodology, demographic context, and question structure, here are plausible explanations (not mutually exclusive):

#### 1. **Immigration from Religious Countries** (15-45% of effect)

**Mechanism**: Between 2018 and 2024, substantial immigration occurred from countries with higher religiosity, including Nigeria, Philippines, Romania, Poland, Middle Eastern nations, Ukraine, and Hong Kong. ONS data show UK immigration remained at historic highs during this period, with 1.3 million arriving in year ending (YE) December 2023 and 948,000 in YE December 2024 ([ONS, 2025](https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/internationalmigration/bulletins/longterminternationalmigrationprovisional/yearendingdecember2024)). Additionally, 158,000 Hong Kong BN(O) visa holders arrived between 2021-2024, and 217,000 Ukrainians arrived between 2022-2024 ([Home Office, 2024](https://www.gov.uk/government/statistics/immigration-system-statistics-year-ending-september-2024/how-many-people-come-to-the-uk-via-safe-and-legal-humanitarian-routes)).

**Evidence for**:
- **Ukrainian immigration**: Around 217,000 Ukrainians were living in the UK as of June 2024, with ~210,000 arriving under the Ukraine Family and Sponsorship Schemes since the 2022 invasion ([Migration Observatory, 2024](https://migrationobservatory.ox.ac.uk/resources/briefings/ukrainian-migration-to-the-uk/))
- **High Ukrainian religiosity**: 85% of Ukrainians identify as Christian (72% Eastern Orthodox, 9% Catholic, 4% Protestant), significantly higher than UK's ~46% Christian identification ([Wikipedia: Religion in Ukraine](https://en.wikipedia.org/wiki/Religion_in_Ukraine), citing Kyiv International Institute of Sociology, 2022)
- **Hong Kong BN(O) immigration**: 158,000 British National (Overseas) status holders from Hong Kong arrived in the UK between January 2021 and September 2024, with 22,500 arriving in YE September 2024 alone ([Home Office, 2024](https://www.gov.uk/government/statistics/immigration-system-statistics-year-ending-september-2024/how-many-people-come-to-the-uk-via-safe-and-legal-humanitarian-routes)). Hong Kong has substantial Christian population (~12-15%), higher than mainland China
- **Church attendance culture**: Ukrainian Christians (particularly Eastern Orthodox and Greek Catholics) and Hong Kong Christians (predominantly Protestant and Catholic) have active church attendance traditions that could translate to UK church-going behaviour
- **Scale of non-EU+ immigration**: 766,000 non-EU+ nationals arrived in YE December 2024 alone, with cumulative arrivals over 2018-2024 likely exceeding 4-5 million people
- **Immigration by reason (YE Dec 2024)**: 266,000 for study, 262,000 for work, 95,000 asylum seekers, 76,000 family reasons, 51,000 humanitarian routes including Ukraine schemes (ONS, 2025)
- **Top source countries**: Indian, Pakistani, Chinese, Nigerian, Ukrainian, and Hong Kong nationals were among the top non-EU+ nationalities for immigration
- **Other religious immigration**: Substantial influx from Nigeria, Philippines, Romania, Poland, and Middle Eastern nations with high Christian identification rates
- **Higher attendance rates**: Immigrants from these regions attend church at 2-3× the UK baseline rate
- **Substantial effect size**: Could explain 0.6-1.8 percentage points of the 4pp increase (15-45%)
- **No demographic standardisation performed**: The surveys did not account for changing population composition by country of birth
- **Geographic concentration**: Ukrainian arrivals were concentrated in Scotland (18%), London (17%), and South East (17%) – areas that could show localised attendance increases
- **Timing alignment**: Most Ukrainian arrivals occurred in 2022-2023, with immigration peaking at 1.3 million in YE December 2023, immediately before the 2024 survey

**Evidence against**:
- Effect size might be at the lower end if integration reduces attendance over time
- Requires assumptions about immigrant attendance rates and religious denominational alignment
- Ukrainian refugees may not maintain home-country attendance patterns due to trauma and displacement
- Not all immigrants from "religious countries" are practising Christians or attend Anglican/Catholic churches captured in surveys

**Testability**: Could be tested with demographic breakdown by country of birth (data likely available but not reported), or by comparing attendance increases in areas with high vs low immigration

**Data sources**: 
- Office for National Statistics (ONS). (2025). "Long-term international migration, provisional: year ending December 2024". Retrieved from https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/internationalmigration/bulletins/longterminternationalmigrationprovisional/yearendingdecember2024
- Cuibus, M., Walsh, P.W., & Sumption, M. (2024). "Ukrainian migration to the UK". Migration Observatory briefing, COMPAS, University of Oxford. Retrieved from https://migrationobservatory.ox.ac.uk/resources/briefings/ukrainian-migration-to-the-uk/

---

#### 2. **COVID-19 Rebound Effect**

**Mechanism**: Churches were closed/restricted during 2020-2022. By 2024, previously regular attendees may have returned, creating a "rebound" relative to pandemic disruption. Additionally, elevated mortality during the pandemic may have driven people to seek community and meaning through religious participation.

**Evidence for**:
- **2024 represents first "normal" post-pandemic year**: Death rates returned to pre-pandemic levels in 2024, marking the end of the acute crisis period ([Our World in Data, 2025](https://ourworldindata.org/grapher/excess-mortality-p-scores-average-baseline))
- **Significant mortality burden**: UK excess deaths peaked at 105% above baseline in April 2020, remained elevated through 2021-2023, affecting ~3-4 million families through bereavement
- **Grief and mortality salience**: Churches traditionally provide support during bereavement; increased mortality may have driven attendance for funerals, memorials, and community support
- **Religious organisations often see attendance recovery after disruptions**: Historical patterns show rebound effects after crises
- **Other social activities show similar rebound patterns**: Not unique to religious attendance
- **Pent-up demand**: People unable to attend during lockdowns may have returned with renewed commitment

**Evidence against**:
- Effect should be temporary and decline over time (no data yet on 2025+ trends)
- Some evidence suggests permanent losses from pandemic as people developed new habits
- No baseline from 2019 to establish pre-pandemic level
- If purely COVID-related, would expect larger increases in areas with higher mortality (not tested)

**Testability**: Would require longitudinal data through 2020-2023 to observe trajectory, and correlation analysis between local mortality rates and attendance changes

**Data source**: Human Mortality Database; World Mortality Dataset (2024); Karlinsky and Kobak (2021) – processed by Our World in Data. Retrieved from https://ourworldindata.org/grapher/excess-mortality-p-scores-average-baseline

---

#### 3. **Question Order and Measurement Effects**

**Mechanism**: The 2024 survey asked questions in a different order/format than 2018, potentially introducing acquiescence bias or priming effects.

**Evidence for**:
- 2024 included a binary "past year" question (77% yes) that doesn't match frequency breakdown (68.5% non-never)
- **Internal inconsistency**: 8.5pp discrepancy suggests measurement error
- Question order can affect responses by 3-7pp in survey research
- Different question formats between years

**Evidence against**:
- Both surveys by same organisation (YouGov) using similar methodology
- Effect should be random if truly measurement error

**Testability**: See [Question Order Effects](./question-order-effects.qmd) analysis

---

#### 4. **Demographic Composition Changes (Age/Education)**

**Mechanism**: UK population aging + educational expansion could shift demographic weights toward groups with different attendance patterns.

**Evidence for**:
- Population is aging; older cohorts attend more frequently
- Educational attainment increasing; relationship with attendance is complex
- Sample size reduced 31% (19,875 → 13,146), potentially changing representativeness

**Evidence against**:
- Age-specific increases observed across all groups (not just older)
- Standard population changes unlikely to produce 4pp shift in 6 years
- Would require implausibly large demographic shifts

**Testability**: Requires demographic standardisation/weighting (not performed)

---

#### 5. **Natural Cohort Turnover**

**Mechanism**: Older, less religious cohorts dying and being replaced by younger cohorts with different patterns.

**Evidence for**:
- ~3-4 million deaths between 2018-2024 in UK
- Cohort replacement is continuous demographic process
- Could represent generational shifts

**Evidence against**:
- Direction is wrong: younger generations typically less religious
- Effect size too large for 6-year mortality replacement
- Age breakdown shows increases across all groups, including young

**Testability**: Requires cohort analysis tracking same individuals over time

---

#### 6. **Genuine Religious Revival**

**Mechanism**: Actual increase in religious commitment, belief, or practice across the UK population.

**Evidence for**:
- Attendance increase is statistically real
- ??? (Bible Society UK provides no additional evidence)

**Evidence against**:
- **Effect size trivially small** (h = 0.179, <0.2 threshold for "small")
- **No belief triangulation**: No evidence of increased religious belief, prayer, Bible reading, or other indicators
- **Internal inconsistencies**: Binary question shows different pattern than frequency breakdown
- **"Never attended" decreased 4pp**: Zero-sum constraint suggests shifting boundaries rather than new engagement
- **No control for confounders**: Immigration, COVID, demographics all unaddressed
- **Only 2 time points**: Can't distinguish trend from noise
- **Cherry-picked metric**: Focused on single favorable statistic

**Testability**: Would require multiple convergent measures (belief, prayer, donations, etc.) all showing increases

---

### Comparative Plausibility

Ranking explanations by plausibility given available evidence:

| Rank | Explanation | Plausibility | Evidence Quality |
|------|-------------|--------------|------------------|
| 1 | Immigration + COVID rebound | High | Good (external data: [ONS, 2025](https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/internationalmigration/bulletins/longterminternationalmigrationprovisional/yearendingdecember2024); [Our World in Data, 2025](https://ourworldindata.org/grapher/excess-mortality-p-scores-average-baseline); [Migration Observatory, 2024](https://migrationobservatory.ox.ac.uk/resources/briefings/ukrainian-migration-to-the-uk/)) |
| 2 | Measurement artifacts | Medium-High | Fair (internal inconsistency suggests problems) |
| 3 | Demographic composition | Medium | Poor (no standardisation performed) |
| 4 | Natural cohort turnover | Low | Poor (direction inconsistent) |
| 5 | Genuine religious revival | Very Low | Very Poor (no triangulation, contradictory evidence) |

**Most likely scenario**: The 4pp increase represents a **combination** of:
- **1.0-1.8pp**: Immigration effects (25-45% of increase) — 1.3 million arrivals in YE Dec 2023, including 217,000 Ukrainians (85% Christian) and 158,000 Hong Kong BN(O) holders (12-15% Christian), both with active church attendance cultures ([ONS, 2025](https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/internationalmigration/bulletins/longterminternationalmigrationprovisional/yearendingdecember2024); [Home Office, 2024](https://www.gov.uk/government/statistics/immigration-system-statistics-year-ending-september-2024/how-many-people-come-to-the-uk-via-safe-and-legal-humanitarian-routes))
- **1.0-1.5pp**: COVID-19 rebound (25-38% of increase) — UK excess deaths peaked at 105% in April 2020, remained elevated through 2023, returned to normal in 2024 ([Our World in Data, 2025](https://ourworldindata.org/grapher/excess-mortality-p-scores-average-baseline))
- **0.5-1.0pp**: Measurement artifacts (13-25% of increase)
- **0.2-0.5pp**: Demographic composition (5-13% of increase)
- **0-0.5pp**: Genuine behaviour change (0-13% of increase)

### Key Methodological Point

**The absence of demographic standardisation, belief triangulation, and confound control means we cannot distinguish between these explanations.** The Bible Society UK has presented a statistical pattern as if it were a causal story without ruling out alternative explanations.

**What would be needed to support a "revival" claim:**
1. ✅ Statistical significance (achieved)
2. ✅ Meaningful effect size (**failed** - h = 0.179 is negligible)
3. ❌ Belief/commitment triangulation (not measured)
4. ❌ Demographic standardisation (not performed)
5. ❌ Alternative explanations ruled out (not addressed)
6. ❌ Longitudinal trend data (only 2 time points)
7. ❌ Internal consistency (contradictory measures)

**Current evidence grade: D (poor)**

---

## References

### Data Sources

**UK Immigration Statistics:**
- Office for National Statistics (ONS). (2025). "Long-term international migration, provisional: year ending December 2024". Retrieved from https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/internationalmigration/bulletins/longterminternationalmigrationprovisional/yearendingdecember2024

**Humanitarian Migration Routes (Ukraine & Hong Kong):**
- Home Office. (2024). "How many people come to the UK via safe and legal (humanitarian) routes? Immigration system statistics, year ending September 2024". UK Government. Retrieved from https://www.gov.uk/government/statistics/immigration-system-statistics-year-ending-september-2024/how-many-people-come-to-the-uk-via-safe-and-legal-humanitarian-routes

**Ukrainian Migration:**
- Cuibus, M., Walsh, P.W., & Sumption, M. (2024). "Ukrainian migration to the UK". Migration Observatory briefing, COMPAS, University of Oxford. Retrieved from https://migrationobservatory.ox.ac.uk/resources/briefings/ukrainian-migration-to-the-uk/

**Ukrainian Religious Demographics:**
- Kyiv International Institute of Sociology (KIIS). (2022). "Dynamics of religious self-identification of the population of Ukraine". Retrieved via Wikipedia: https://en.wikipedia.org/wiki/Religion_in_Ukraine

**UK Excess Mortality:**
- Our World in Data. (2025). "Excess mortality: Deaths from all causes compared to average over previous years". Data adapted from Human Mortality Database, World Mortality Database. Retrieved from https://ourworldindata.org/grapher/excess-mortality-p-scores-average-baseline
- Human Mortality Database; World Mortality Dataset (2024); Karlinsky and Kobak (2021); Human Mortality Database (2025); World Mortality Database (2024) – processed by Our World in Data. Retrieved October 31, 2025

---

## Detailed Follow-up Analyses

For more rigorous investigation of specific causal mechanisms:

1. [**Question Order Effects**](./question-order-effects.qmd) - Analysis of measurement artifacts and internal consistency
2. [**Demographic Analysis**](./demographic-analysis.qmd) - Investigation of age and ethnicity patterns  
3. [**Critical Analysis Overview**](./criticism-overview.qmd) - Comprehensive evaluation of all red flags and alternative explanations

